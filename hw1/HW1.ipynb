{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh4QMDpMlQ9S"
   },
   "source": [
    "<style>\n",
    "@font-face {font-family: \"B Nazanin\"; src: url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.eot\"); src: url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.eot?#iefix\") format(\"embedded-opentype\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.woff2\") format(\"woff2\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.woff\") format(\"woff\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.ttf\") format(\"truetype\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.svg#B Nazanin\") format(\"svg\"); }\n",
    "    </style>\n",
    "<div dir=\"rtl\" align=\"center\" style ='font-family: \"B Nazanin\";'>\n",
    "    <h1>\n",
    "        تمرین اول درس پردازش زبان‌های طبیعی\n",
    "    </h1>\n",
    "    <h3>\n",
    "        گردآورندگان:<br/>\n",
    "        ساحل مس‌فروش، سروش تابش، درنا دهقانی\n",
    "    </h3>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
    "    ما در این تمرین ترک \"استخراج پرسش و پاسخ\" را انتخاب کردیم. در این تمرین قصد داریم از یک جمله فارسی سوالاتی با توجه به روابط علت و معلولی، نقش کلمات در جملات، ارتباط بین واژگان و ... استخراج کنیم. هر سوال به شکل یک دیکشنری پایتون نمایش داده می‌شود که key سوال و value پاسخ به سوال است. گام ابتدایی ما برای پاسخ به این ترک، جستجوی مسائل مشابه بود و از آنجایی که این مسئله هم‌چنان باز است، روش‌های متعددی مبتنی بر Deep Learning یافتیم که چون از مبحث این تمرین خارج بودند، از آنها استفاده نکردیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWTUeohDlQ9b"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "    <h2> 1. تمیز کردن ورودی </h2>\n",
    "    در این بخش، گام‌های ابتدایی برای مراحل آتی را برمی‌داریم. هر جمله که به عنوان ورودی ما داده می‌شود، باید تا حد مناسبی تمیز و ساختاریافته شود تا به عنوان ورودی بخش‌های بعد معتبر باشد. کارهایی مانند نرمال‌سازی و ... در این بخش انجام می‌گردد. از توابع تعریف شده در کتابخانه hazm استفاده می‌کنیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2a4iZZbllQ9e",
    "outputId": "4150c9bc-5c25-433a-c536-3645ff7ced22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hazm\n",
      "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
      "\u001b[K     |████████████████████████████████| 316 kB 17.0 MB/s \n",
      "\u001b[?25hCollecting nltk==3.3\n",
      "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 65.1 MB/s \n",
      "\u001b[?25hCollecting libwapiti>=0.2.1\n",
      "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 55.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
      "Building wheels for collected packages: nltk, libwapiti\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394489 sha256=edbfc0fad24ba8694c5aaf961edd5d382f284756104ec7cfa1da11d22ca8e515\n",
      "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
      "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154939 sha256=03c0f3faba51792e68659206bc0ae7b4743a98cfbfe805d1075302f64ac207f6\n",
      "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
      "Successfully built nltk libwapiti\n",
      "Installing collected packages: nltk, libwapiti, hazm\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n",
      "Collecting camel-tools\n",
      "  Downloading camel_tools-1.3.1-py3-none-any.whl (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 16.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.21.5)\n",
      "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.10.0+cu111)\n",
      "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.5.3)\n",
      "Requirement already satisfied: pyrsistent in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.18.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from camel-tools) (4.64.0)\n",
      "Collecting camel-kenlm\n",
      "  Downloading camel-kenlm-2021.12.27.tar.gz (418 kB)\n",
      "\u001b[K     |████████████████████████████████| 418 kB 60.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from camel-tools) (2.23.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.8.9)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.3.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.0.2)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from camel-tools) (4.2.4)\n",
      "Collecting transformers>=3.0.2\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 60.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.3.4)\n",
      "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.6.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.16.0)\n",
      "Collecting emoji\n",
      "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
      "\u001b[K     |████████████████████████████████| 175 kB 48.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.4.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->camel-tools) (4.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel-tools) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel-tools) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel-tools) (4.11.3)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 51.2 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 6.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel-tools) (21.3)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 57.6 MB/s \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 62.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=3.0.2->camel-tools) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.2->camel-tools) (3.8.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->camel-tools) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->camel-tools) (2.8.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->camel-tools) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->camel-tools) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->camel-tools) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->camel-tools) (2.10)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.2->camel-tools) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.2->camel-tools) (7.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->camel-tools) (3.1.0)\n",
      "Building wheels for collected packages: camel-kenlm, emoji\n",
      "  Building wheel for camel-kenlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for camel-kenlm: filename=camel_kenlm-2021.12.27-cp37-cp37m-linux_x86_64.whl size=2333872 sha256=9cb7840ac4b900faafa7a92328112582de5cf220f92b965d2d6777f5487273f9\n",
      "  Stored in directory: /root/.cache/pip/wheels/db/72/74/982f8c435f15b7feaf6dc8a03e212ff34e93f1f2d747059332\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=433c372c00c78e8ef4f14b360d24323f77e6c1c2829f59c0760e56624fd984a0\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
      "Successfully built camel-kenlm emoji\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, emoji, camel-kenlm, camel-tools\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed camel-kenlm-2021.12.27 camel-tools-1.3.1 emoji-1.7.0 huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n",
      "Collecting Tashaphyne\n",
      "  Downloading Tashaphyne-0.3.6-py3-none-any.whl (251 kB)\n",
      "\u001b[K     |████████████████████████████████| 251 kB 13.2 MB/s \n",
      "\u001b[?25hCollecting pyarabic\n",
      "  Downloading PyArabic-0.6.14-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 74.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic->Tashaphyne) (1.15.0)\n",
      "Installing collected packages: pyarabic, Tashaphyne\n",
      "Successfully installed Tashaphyne-0.3.6 pyarabic-0.6.14\n",
      "Collecting parstdex~=1.1.0\n",
      "  Downloading parstdex-1.1.1-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 928 kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from parstdex~=1.1.0) (1.21.5)\n",
      "Collecting pytextspan==0.5.4\n",
      "  Downloading pytextspan-0.5.4-cp37-cp37m-manylinux2010_x86_64.whl (282 kB)\n",
      "\u001b[K     |████████████████████████████████| 282 kB 21.7 MB/s \n",
      "\u001b[?25hCollecting setuptools~=58.0.4\n",
      "  Downloading setuptools-58.0.4-py3-none-any.whl (816 kB)\n",
      "\u001b[K     |████████████████████████████████| 816 kB 63.7 MB/s \n",
      "\u001b[?25hCollecting pytest~=6.2.5\n",
      "  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 79.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: hazm~=0.7.0 in /usr/local/lib/python3.7/dist-packages (from parstdex~=1.1.0) (0.7.0)\n",
      "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm~=0.7.0->parstdex~=1.1.0) (0.2.1)\n",
      "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm~=0.7.0->parstdex~=1.1.0) (3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm~=0.7.0->parstdex~=1.1.0) (1.15.0)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest~=6.2.5->parstdex~=1.1.0) (1.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest~=6.2.5->parstdex~=1.1.0) (21.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest~=6.2.5->parstdex~=1.1.0) (21.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest~=6.2.5->parstdex~=1.1.0) (4.11.3)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest~=6.2.5->parstdex~=1.1.0) (1.11.0)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest~=6.2.5->parstdex~=1.1.0) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest~=6.2.5->parstdex~=1.1.0) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytest~=6.2.5->parstdex~=1.1.0) (3.0.8)\n",
      "Installing collected packages: toml, pluggy, setuptools, pytextspan, pytest, parstdex\n",
      "  Attempting uninstall: pluggy\n",
      "    Found existing installation: pluggy 0.7.1\n",
      "    Uninstalling pluggy-0.7.1:\n",
      "      Successfully uninstalled pluggy-0.7.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 57.4.0\n",
      "    Uninstalling setuptools-57.4.0:\n",
      "      Successfully uninstalled setuptools-57.4.0\n",
      "  Attempting uninstall: pytest\n",
      "    Found existing installation: pytest 3.6.4\n",
      "    Uninstalling pytest-3.6.4:\n",
      "      Successfully uninstalled pytest-3.6.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed parstdex-1.1.1 pluggy-1.0.0 pytest-6.2.5 pytextspan-0.5.4 setuptools-58.0.4 toml-0.10.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pkg_resources"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zeep\n",
      "  Downloading zeep-4.1.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |███▎                            | 10 kB 23.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 20 kB 28.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 30 kB 33.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 40 kB 18.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 51 kB 14.0 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 61 kB 16.0 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 71 kB 13.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 81 kB 15.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 92 kB 16.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 100 kB 7.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from zeep) (2018.9)\n",
      "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from zeep) (2.23.0)\n",
      "Collecting requests-file>=1.5.1\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Collecting platformdirs>=1.4.0\n",
      "  Downloading platformdirs-2.5.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: attrs>=17.2.0 in /usr/local/lib/python3.7/dist-packages (from zeep) (21.4.0)\n",
      "Requirement already satisfied: cached-property>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from zeep) (1.5.2)\n",
      "Collecting isodate>=0.5.4\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 688 kB/s \n",
      "\u001b[?25hCollecting lxml>=4.6.0\n",
      "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 54.9 MB/s \n",
      "\u001b[?25hCollecting requests-toolbelt>=0.7.1\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 3.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from isodate>=0.5.4->zeep) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->zeep) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->zeep) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->zeep) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->zeep) (1.24.3)\n",
      "Installing collected packages: requests-toolbelt, requests-file, platformdirs, lxml, isodate, zeep\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "Successfully installed isodate-0.6.1 lxml-4.8.0 platformdirs-2.5.1 requests-file-1.5.1 requests-toolbelt-0.9.1 zeep-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install hazm\n",
    "!pip install camel-tools\n",
    "!pip install Tashaphyne\n",
    "!pip install parstdex~=1.1.0\n",
    "\n",
    "#  نصب کتاب‌خانه مورد نیاز برای اتصال به وب‌سرویس فارس‌نت\n",
    "! pip install zeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1q3cjw4fB7iZ"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "from itertools import chain\n",
    "import collections\n",
    "import hazm\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import tqdm\n",
    "import itertools\n",
    "import functools\n",
    "import operator\n",
    "import matplotlib\n",
    "from zeep import Client\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from requests import Session\n",
    "from zeep.transports import Transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Ws8pLkylQ9i",
    "outputId": "3c6f39a8-1894-4283-e9fe-ef7c976d7830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['چون بارون اومده، رنگین کمونه', 'هوا بارونیه', '']\n"
     ]
    }
   ],
   "source": [
    "def sentence_clean(sentence: str):\n",
    "    normalizer = hazm.Normalizer()\n",
    "    sentence = normalizer.normalize(sentence)\n",
    "    return sentence.split('. ')\n",
    "\n",
    "sentence = 'چون بارون اومده  ، رنگین کمونه. هوا بارونیه. '\n",
    "print(sentence_clean(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z3-Yq6-lQ9n"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "    <h2> 2. استخراج ساختار سوالات </h2>\n",
    "    جملاتی که امکان استخراج سوالات از آنها ممکن است، دو نوعند. نوع اول دارای برخی کلمات کلیدی (مانند زیرا، چون و ...) هستند. نوع دوم جملاتی هستند که فاقد اینگونه کلماتند. مثلاً امروز هوا بارانیست: امروز هوا چگونه است؟ بارانی. در طراح این بخش از ماژول <code>cause_effect_extractions</code> ایده گرفتیم.<br>\n",
    "    <h4> 2.1. استخراج سوال از جملات با کلمات کلیدی </h4>\n",
    "    در این مرحله، به یافتن کلمات کلیدی در جملاتی که امکان استخراج سوالات از آنها وجود دارد پرداختیم. در یک Google Sheet لیست این کلمات، انواع نحوه به کارگیری آنها در جملات، مثال‌هایی از هر یک و هم‌چنین ساختار سوال و جواب و مثال از آنها را مشخص کردیم. \n",
    "    هم‌چنین مثال‌هایی از جملات را به عنوان داده‌ی تست یافتیم و سوال‌هایی از آنها استخراج کردیم.\n",
    "    <a href=\"https://docs.google.com/spreadsheets/d/1qsCfRVr5RgXYW2qEVbrP3dq7-l3wNngjPAsXrHN89DQ/edit#gid=0\" target=\"_top\">فهرست کلمات کلیدی و جملات تست</a><br/>\n",
    "    سپس در تابع <code>extract_cause_effect</code> از جمله‌ای که به عنوان ورودی داده می‌شود، با توجه به ساختار جمله که ورودی دیگر این تابع و از انواع پرسش و پاسخ است، رابطه‌ی علت و معلولی که ممکن است در جمله باشد، استخراج می‌گردد.<br>\n",
    "    در دیکشنری <code>all_regexes</code> نوع و ساختار جملاتی که قابلیت طرح سوال از آنها وجود دارد توسط regex طراحی شده است. هم‌چنین ساختار پرسش و پاسخ آنها نیز وجود دارد.<br>\n",
    "    اگر ساختار regex در جمله موجود بود، بسته به اینکه کدام بخش جمله در سوال و کدام بخش آن در جواب استفاده شود، سوال و جواب از جمله ساخته شده و در دیکشنری خروجی تابع قرار می‌گیرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WdMAWdz2lQ9q"
   },
   "outputs": [],
   "source": [
    "all_regexes = {\n",
    "  \"چرایی\": {\"regex\": r\"\"\"(?P<effect>.*)[،|؛|](?P<reason> زیرا| چون| به‌دلیل| بدلیل|چون\\sکه | به\\sدلیل\\sاینکه)(?P<cause>.*)|چون(?P<cause2>.*)(،|\\s،)(?P<effect2>.*)\"\"\", \"question\": \"چرا {effect} ؟\", \"answer\": \"زیرا {cause}\"}, \n",
    "  \"سببی\": {\"regex\": r\"(?P<effect>.*) (?P<reason> مسبب|دلیل|مسبّب) (?P<cause>.*) [است|شد]|(?P<reason2>مسبب|دلیل) (?P<effect2>.*)[،|؛] (?P<cause2>) است.\", \"question\": \"{effect} باعث چه می شود؟ \", \"answer\": \"باعث {cause}\"},\n",
    "  \"موجب\": {\"regex\":r\"(?P<effect>.*) موجب (?P<cause>.*) می‌شود.*|(?P<effect2>.*) موجبات (?P<cause2>.*) فراهم می‌کند\", \"question\": \"چه موجب {effect} می‌شود؟\", \"answer\": \"{cause}\"},\n",
    "  \"ترین\": {\"regex\":r\"(?P<tarin>.*ترین) (?P<cause>.*)[،|؛](?P<effect>.*) است\", \"question\": \"{tarin}ترین {cause} چیست؟\", \"answer\": \"{effect}\"},\n",
    "  \"خاطر\": {\"regex\": r\"\"\"(?P<reason> بخاطر|به خاطر) (?P<cause>.*)[،|] (?P<effect>.*)|(?P<effect2>.*) (?P<reason2> بخاطر|به خاطر) (?P<cause2>.*)\"\"\", \"question\": \"چرا {effect} ؟\", \"answer\": \"به خاطر {cause}\"},\n",
    "  \"منجر\": {\"regex\": r\"(?P<cause>.*)(?P<reason> منجر به)(?P<effect>.*)می شود.|(?P<reason2>مسبب|دلیل) (?P<effect2>.*)[،|؛] (?P<cause2>) است.\", \"question\": \"علت {effect} چیست؟\", \"answer\": \"{cause}\"},\n",
    "   \"هدف\": {\"regex\":r\"هدف (?P<effect>.*) (?P<reason>این\\sاست\\sکه|این\\sاست) (?P<cause>.*)\", \"question\": \"هدف {effect} چیست؟\", \"answer\": \"{cause}\"},\n",
    "  #  \"\": {\"regex\":r\"\", \"question\": \"\", \"answer\": \"\"},\n",
    "}\n",
    "\n",
    "def extract_cause_effects(text: str, key: str):\n",
    "    \"\"\"\n",
    "    extracting cause and effect parts from text based on key regex. creating a Q&A based on key question format and answer format\n",
    "    Parameters\n",
    "    ---------\n",
    "    text: str\n",
    "        sentence query used to extract question and answers.\n",
    "    key: str\n",
    "        key should be one of all_regexes.keys(). sentence format used to extract Q&A\n",
    "  \n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    result: dict\n",
    "        includes question and answer sentences.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    key_information = all_regexes.get(key, None)\n",
    "    if not key_information:\n",
    "        print(\"you should specify current key information in all_regexes dict\")\n",
    "        return\n",
    "    regex = key_information.get(\"regex\")\n",
    "    first_reg = re.compile(regex)\n",
    "    x = re.search(first_reg, text)\n",
    "    if x is not None:\n",
    "        cause = x.group(\"cause\")\n",
    "        effect = x.group(\"effect\")\n",
    "        if not cause:\n",
    "        # text is not in the format of first part of regex. checking for second part\n",
    "            cause = x.group(\"cause2\")\n",
    "            effect = x.group(\"effect2\")\n",
    "            if not cause or not effect:\n",
    "                # cause and effects are empty! this shouldn't happen!!!\n",
    "                print(\"bad input\")\n",
    "                return None\n",
    "    else:\n",
    "        # regex didn't found the structure. \n",
    "        return None\n",
    "    print(\"in func for: \", key)\n",
    "    q_format = key_information.get(\"question\")\n",
    "    a_format = key_information.get(\"answer\")  \n",
    "    result = {\"question\": sentence_clean(q_format.format(effect=effect)), \"answer\": sentence_clean(a_format.format(cause=cause))}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXDV-Y20lQ9w"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "    در تابع <code>extract_question</code> ابتدا روی تمامی ساختارهای موجود که امکان طرح سوال از آنها وجود دارد، پیمایشی انجام می‌گیرد. در هر پیمایش، هر ساختار از <code>all_regexes</code> در جمله‌ی ورودی توسط تابع <code>extract_cause_effects</code> بررسی می‌گردد و در صورت داشتن خروجی معتبر، پرسش و پاسخ مربوطه‌ی آن نمایش داده می‌شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVyBNIhRlQ9z",
    "outputId": "d0bd9ee3-7165-4f58-cd8d-e726ff89eebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in func for:  چرایی\n",
      "{'question': ['چرا رنگین کمونه؟'], 'answer': ['زیرا بارون اومده']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': ['زیرا بارون اومده'], 'question': ['چرا رنگین کمونه؟']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_questions(text: str):\n",
    "    \"\"\"\n",
    "    checking all different sentence formats on text. if one is applied ignore others and return\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        input sentence(s)\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    result: dict\n",
    "      question and answer sentences.\n",
    "    \"\"\"\n",
    "    text = sentence_clean(text)\n",
    "    for t in text:\n",
    "      if len(t) > 1:\n",
    "        for key, value in all_regexes.items():\n",
    "            result = extract_cause_effects(t, key)\n",
    "            if result:\n",
    "                print(result)\n",
    "                return result\n",
    "    \n",
    "sentence = 'رنگین کمونه؛ چون بارون اومده. چون بارون اومده؛ رنگین کمونه.'\n",
    "extract_questions(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL3qPcRdlQ92"
   },
   "source": [
    "<div dir='rtl' style ='font-family: \"B Nazanin\";'>\n",
    "    <h4>2.2. استخراج سوال از جملات بدون کلمات کلیدی</h4>\n",
    "    عملکرد کلی در این بخش بدین صورت است که امکان پرسش با حذف بخشی از جمله ممکن است و به جای بخش حذف شده، ضمیر پرسشی مربوطه جایگزین آن می‌گردد و سوال تشکیل می‌شود. در نتیجه بخش حذف شده از جمله، پاسخ به آن پرسش است.<br>\n",
    "    مثلاً در جمله‌ی \"او کتاب را برداشت.\"، با حذف \"او\" که اشاره به فرد دارد و جایگزین کردن \"چه کسی\" یک سوال ساخته می‌شود. هم‌چنین با حذف \"کتاب\" که اشاره به شیء دارد و جایگزین کردن \"چه چیزی\" می‌توان سوال دیگری ساخت.<br>\n",
    "    چالشی که در این بخش با آن مواجه بودیم، نحوه برخورد با گروه‌های اسمی بود که با حرف اضافه شروع می‌شدند. مثلاً در جمله‌ی \"او با آرامش راه رفت.\" تشخیص اینکه \"با\" حرف ربط یا حرف اضافه است برای ما مسئله بود. در چنین شرایطی تصمیم گرفتیم به کلمه‌ی پیش از این حرف نگاه کنیم و اگر فعل بود، آن را حرف ربط و در غیر اینصورت حرف اضافه در نظر بگیریم. در این صورت کلمه‌ی پرسشی مناسب برای گروه اسمی \"با آرامش\"، \"چگونه\" است. <br>\n",
    "    برای استفاده از تابع <code>POSTagger</code> از کتابخانه‌ی hazm، به دلیل مشکلاتی که در استفاده‌ی مستقیم از کتابخانه‌ی آن پیش می‌آمد، مجبور شدم از محتوای این تابع به شکلی دستی استفاده کنم در فولدر resources قرار دارد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "R21VvZmo8mIK"
   },
   "outputs": [],
   "source": [
    "# download \"resources\" from here: https://github.com/sobhe/hazm/releases/download/v0.5/resources-0.5.zip\n",
    "tagger = hazm.POSTagger(model='/content/resources/postagger.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCNqUZurIgL4"
   },
   "source": [
    "<div dir='rtl' style ='font-family: \"B Nazanin\";'>\n",
    "  بخش‌های قابل پرسش در جمله به چهار گروه متممی، مفعولی، نهادی و قیدی تقسیم می‌شوند. در تابع <code>extract_structure</code> برای هر یک از این ساختارها، regex مربوطه نوشته شده و به کمک تابع <code>POSTagger</code> کتابخانه‌ی hazm، درخت روابط واژگانی جمله نمایش داده می‌شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNVnaHHrILNC",
    "outputId": "329be43e-e55d-4902-f101-d8ec295a0631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('S', [Tree('NAHADI', [('مجلس', 'Ne')]), Tree('NAHADI', [('اولویتی', 'N')]), Tree('MOTAMEMI', [('برای', 'Pe'), ('کاهش', 'Ne'), ('هزینه', 'Ne'), ('اجرایی', 'AJe'), ('کشور', 'N'), ('که', 'CONJ'), ('عامل', 'Ne'), ('تورم', 'N')]), Tree('MOTAMEMI', [('در', 'P'), ('کشور', 'N')]), ('است', 'V'), ('،', 'PUNC'), ('ندارند', 'V'), ('.', 'PUNC')]),\n",
       " Tree('NAHADI', [('مجلس', 'Ne')]),\n",
       " Tree('NAHADI', [('اولویتی', 'N')]),\n",
       " Tree('MOTAMEMI', [('برای', 'Pe'), ('کاهش', 'Ne'), ('هزینه', 'Ne'), ('اجرایی', 'AJe'), ('کشور', 'N'), ('که', 'CONJ'), ('عامل', 'Ne'), ('تورم', 'N')]),\n",
       " Tree('MOTAMEMI', [('در', 'P'), ('کشور', 'N')])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionable_poses = ['MOTAMEMI', 'MAFOULI', 'NAHADI', 'GHEIDI']\n",
    "\n",
    "\n",
    "def extract_structures(sentence):\n",
    "    neutral_words = r\"N|Ne|PRO|PROe\"\n",
    "    grammar = r\"\"\"\n",
    "      MOTAMEMI:  {<P|Pe><N|Ne>(<CONJ>?<N|Ne|AJ|AJe>)*}\n",
    "      MAFOULI: {<N|Ne><POSTP>}\n",
    "      NAHADI:  {<DET>?<NW>((<CONJ><NW>)|<AJe|AJ>)*}\n",
    "      GHEIDI:  {<ADV>+}\n",
    "    \"\"\"\n",
    "    grammar = grammar.replace('NW', neutral_words)\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    return cp.parse(sentence)\n",
    "\n",
    "tree = extract_structures(tagger.tag(hazm.word_tokenize('مجلس اولویتی برای کاهش هزینه اجرایی کشور که عامل تورم در کشور است، ندارند.')))\n",
    "list(tree.subtrees())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v89HU8ivO8eo"
   },
   "source": [
    "<div dir='rtl' style ='font-family: \"B Nazanin\";'>\n",
    "  برای تشخیص اسنادی بودن یا نبودن یک جمله از تابع <code>is_linking_centence</code> استفاده می‌کنیم و بررسی اسنادی بودن فعل جمله توسط تابع <code>is_linking_verb</code> انجام می‌گردد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHJzUJMvOgUk",
    "outputId": "ad13350d-c278-41e9-8012-ea46cdf3d9f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LINKING_VERBS = {'است', 'بود', 'شد', 'گشت', 'گردید', 'هست'}\n",
    "\n",
    "\n",
    "def is_linking_verb(verb):\n",
    "    verb = set(hazm.Lemmatizer().lemmatize(verb).split('#'))\n",
    "    return bool(LINKING_VERBS.intersection(verb))\n",
    "\n",
    "\n",
    "def is_linking_sentence(sentence_tokens):\n",
    "    words = tagger.tag(sentence_tokens)\n",
    "    verb_types = map(is_linking_verb, map(lambda x: x[0], filter(lambda x: x[1] == 'V', words)))\n",
    "    return functools.reduce(operator.or_, verb_types, False)\n",
    "\n",
    "is_linking_sentence(hazm.word_tokenize('این خانه زیبا است.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glpS5McQUNJW"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "  برای تشخیص نوع بخش حذف شده از جمله و جایگزینی ضمیر پرسشی مناسب، از کتابخانه‌ی wordnet فارسی یا فارس‌نت استفاده کردیم. ابتدا ثبت نام کرده و مراحل لازم برای اتصال به آن را انجام دادیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "H-KbAXGxU7Wj",
    "outputId": "e660c32e-d8a5-4895-ba65-4eb0ee5ef545"
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 159\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 168\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fda57fb7f10>: Failed to establish a new connection: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='nlp.sbu.ac.ir', port=8180): Max retries exceeded with url: /WebAPI/services/SenseService?WSDL (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fda57fb7f10>: Failed to establish a new connection: [Errno 110] Connection timed out'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4bd797a53b94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHTTPBasicAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mclient_sense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwsdl_sense_service\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTransport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mclient_synset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwsdl_synset_service\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTransport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zeep/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wsdl, wsse, transport, service_name, port_name, plugins, settings)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mtransport\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtransport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_transport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         )\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwsdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwsdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwsse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwsse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugins\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mplugins\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zeep/wsdl/wsdl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, location, transport, base, settings)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         )\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zeep/wsdl/wsdl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_xml_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mroot_definitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefinition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zeep/wsdl/wsdl.py\u001b[0m in \u001b[0;36m_get_xml_document\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"\n\u001b[1;32m    155\u001b[0m         return load_external(\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         )\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zeep/loader.py\u001b[0m in \u001b[0;36mload_external\u001b[0;34m(url, transport, base_url, settings)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabsolute_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparse_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zeep/transports.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_remote_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zeep/transports.py\u001b[0m in \u001b[0;36m_load_remote_data\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_remote_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading remote data from: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='nlp.sbu.ac.ir', port=8180): Max retries exceeded with url: /WebAPI/services/SenseService?WSDL (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fda57fb7f10>: Failed to establish a new connection: [Errno 110] Connection timed out'))"
     ]
    }
   ],
   "source": [
    "# address of FarsNet's web services\n",
    "wsdl_sense_service = 'http://nlp.sbu.ac.ir:8180/WebAPI/services/SenseService?WSDL'\n",
    "wsdl_synset_service = 'http://nlp.sbu.ac.ir:8180/WebAPI/services/SynsetService?WSDL'\n",
    "\n",
    "\n",
    "# username and token needed for authentication. You can get this token by signing up on http://farsnet.nlp.sbu.ac.ir\n",
    "# users = [{\"username\": \"\"}, {\"username\"}]\n",
    "username = 'SahelMesforoush'\n",
    "token = 'd428e755-3b91-11eb-8a1e-080027d731c1'\n",
    "\n",
    "# connecting client\n",
    "session = Session()\n",
    "session.auth = HTTPBasicAuth(username, token)\n",
    "client_sense = Client(wsdl_sense_service, transport=Transport(session=session))\n",
    "client_synset = Client(wsdl_synset_service, transport=Transport(session=session))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t042HNp2VBjN"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "  برای انتخاب ضمیر پرسشی مناسب، لازم است نوع واژه را از نظر اشاره داشتن به فرد، مکان، زمان و یا حالت بدانیم. به کمک تابع <code>getSensesByWord</code> می‌توان درباره‌ی هر واژه اطلاعاتی به دست آورد. فیلد nounCategory اطلاعاتی در مورد خاص یا غیر خاص بودن اسم  می‌دهد. مثلاً برای نام \"فاطمه\" این فیلد برابر با <code>Specific</code> و برای \"درخت\" برابر با <code>None</code> است. فیلد می‌تواند در مورد نوع نام، مانند انسان بودن اطلاعاتی به ما دهد.<br>\n",
    "  به کمک تابع <code>getSynsetsByWord</code> و فیلد semanticCategory از آن نیز می‌توان در مورد نوع قیود از نظر زمانی و مکانی و غیره بودن را تشخیص داد. مثال‌هایی از این دو تابع را می‌توان مشاهده کرد:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiRBlYOPa_Qz"
   },
   "outputs": [],
   "source": [
    "request = {\"searchKeyword\": \"درخت\", \"userKey\": \"d428e755-3b91-11eb-8a1e-080027d731c1\", \"searchStyle\": \"EXACT\"}\n",
    "sense = client_sense.service.getSensesByWord(**request)\n",
    "print(sense)\n",
    "\n",
    "request = {\"searchKeyword\": \"فاطمه\", \"userKey\": \"d428e755-3b91-11eb-8a1e-080027d731c1\", \"searchStyle\": \"EXACT\"}\n",
    "sense = client_sense.service.getSensesByWord(**request)\n",
    "print(sense)\n",
    "\n",
    "request = {\"searchKeyword\": \"دیروز\", \"userKey\": \"d428e755-3b91-11eb-8a1e-080027d731c1\", \"searchStyle\": \"EXACT\"}\n",
    "sense = client_synset.service.getSynsetsByWord(**request)\n",
    "print(sense)\n",
    "\n",
    "request = {\"searchKeyword\": \"آنجا\", \"userKey\": \"d428e755-3b91-11eb-8a1e-080027d731c1\", \"searchStyle\": \"EXACT\"}\n",
    "sense = client_synset.service.getSynsetsByWord(**request)\n",
    "print(sense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "بدین ترتیب به کمک این توابع می‌توان نوع بسیاری از واژگان یا گروه‌های اسمی را تشخیص داد و متناسب اسم خاص یا غیرخاص، انسان یا غیر انسان، حالت، ارتباط، مکان ، زمان و ...، ضمیر پرسشی مناسب تعیین کرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_TqaX53lQ94"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "    <h2> 3. صحت‌سنجی </h2>\n",
    "    ابتدا در فایل <code>question_generator.json</code> تعدادی مثال و خروجی‌های مورد توقع از آنها برای پرسش و پاسخ نوشته شد. سپس توسط کلاس <code>BaseTest</code> توابعی برای صحت‌سنجی عملکرد بخش‌های پیشین در یافتن و استخراج پرسش و پاسخ از جملات نوشته شد. این کلاس و دو تابع <code>get_testcases</code> و <code>run_test</code> از کتابخانه‌ی parsi.io گرفته شده‌اند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEgNh-1JlQ95",
    "outputId": "31a134b0-9ef6-4cbe-b704-96cebfe05464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in func for:  چرایی\n",
      "{'question': ['چرا شما با ذکرهای زیر به خوبی آشنایید؟'], 'answer': ['زیرا در هر نماز آنها را تکرار میکنید']}\n",
      "Testing 1: \n",
      "input:  شما با ذکرهای زیر به خوبی آشنایید؛ زیرا در هر نماز آنها را تکرار میکنید\n",
      "correct answer:  {'question': 'چرا شما با ذکرهای زیر به خوبی آشنایید?', 'answer': 'زیرا در هر نماز آنها را تکرار میکنید'}\n",
      "method answer:  {'question': ['چرا شما با ذکرهای زیر به خوبی آشنایید؟'], 'answer': ['زیرا در هر نماز آنها را تکرار میکنید']}\n",
      "***********************************\n",
      "in func for:  چرایی\n",
      "{'question': ['چرا رنگین کمونه؟'], 'answer': ['زیرا بارون اومده.']}\n",
      "Testing 2: \n",
      "input:  رنگین کمونه؛ چون بارون اومده.\n",
      "correct answer:  {'question': 'چرا رنگین کمونه؟', 'answer': 'چون بارون اومده'}\n",
      "method answer:  {'question': ['چرا رنگین کمونه؟'], 'answer': ['زیرا بارون اومده.']}\n",
      "***********************************\n",
      "Testing 3: \n",
      "input:  بی احتیاطی مسبّب تصادف شد.\n",
      "correct answer:  {'question': 'مسبّب تصادف چیست؟', 'answer': 'بی احتیاطی'}\n",
      "method answer:  None\n",
      "***********************************\n",
      "in func for:  سببی\n",
      "{'question': ['پشتکار زیاد باعث چه می\\u200cشود؟ '], 'answer': ['باعث موفقیت']}\n",
      "Testing 4: \n",
      "input:  پشتکار زیاد دلیل موفقیت اوست.\n",
      "correct answer:  {'question': 'دلیل موفقیت او چیست؟', 'answer': 'پشتکار زیاد'}\n",
      "method answer:  {'question': ['پشتکار زیاد باعث چه می\\u200cشود؟ '], 'answer': ['باعث موفقیت']}\n",
      "***********************************\n",
      "in func for:  هدف\n",
      "{'question': ['هدف ما در نهی از منکر چیست؟'], 'answer': ['انسان خطاکار به اشتباهاتش ادامه ندهد']}\n",
      "Testing 5: \n",
      "input:  هدف ما در نهی از منکر این است که انسان خطاکار به اشتباهاتش ادامه ندهد\n",
      "correct answer:  {'question': 'هدف ما در نهی از منکر چیست؟', 'answer': ' که انسان خطاکار به اشتباهاتش ادامه ندهد'}\n",
      "method answer:  {'question': ['هدف ما در نهی از منکر چیست؟'], 'answer': ['انسان خطاکار به اشتباهاتش ادامه ندهد']}\n",
      "***********************************\n"
     ]
    }
   ],
   "source": [
    "class BaseTest:\n",
    "\n",
    "    def get_testcases(self, addr):\n",
    "        f = open(os.getcwd()+addr, 'r')\n",
    "        test_cases = json.load(f)\n",
    "        f.close()\n",
    "        return test_cases\n",
    "\n",
    "    def run_test(self, obj, addr):\n",
    "        errors = []\n",
    "        test_cases = self.get_testcases(addr)\n",
    "        for i in test_cases:\n",
    "            your_answer = obj.run(i['input'])\n",
    "            correct_answer = i['outputs']\n",
    "            d = {k: (your_answer[k], correct_answer[k]) for k in your_answer if k in correct_answer and your_answer[k] != correct_answer[k]}\n",
    "            for j in d:\n",
    "                errors.append('Input {0}: your answer is {1} correct answer is {2}'.format(i['id'], d[j][0], d[j][1]))\n",
    "        assert not errors, 'errors occured:\\n{}'.format('\\n'.join(errors))\n",
    "\n",
    "    def test_json(self):\n",
    "        test_cases = self.get_testcases('/question_generator.json')\n",
    "        for i in test_cases:\n",
    "            your_answer = extract_questions(i.get('input'))\n",
    "            correct_answer = i.get('output')\n",
    "            print(\"Testing {0}: \".format(str(i['id']) ))\n",
    "            print(\"input: \", i.get(\"input\"))\n",
    "            print(\"correct answer: \", correct_answer)\n",
    "            print(\"method answer: \", your_answer)\n",
    "            print(\"***********************************\")\n",
    "\n",
    "tester = BaseTest()\n",
    "tester.test_json()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
