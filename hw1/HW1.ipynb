{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh4QMDpMlQ9S"
   },
   "source": [
    "<style>\n",
    "@font-face {font-family: \"B Nazanin\"; src: url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.eot\"); src: url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.eot?#iefix\") format(\"embedded-opentype\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.woff2\") format(\"woff2\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.woff\") format(\"woff\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.ttf\") format(\"truetype\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.svg#B Nazanin\") format(\"svg\"); }\n",
    "    </style>\n",
    "<div dir=\"rtl\" align=\"center\" style ='font-family: \"B Nazanin\";'>\n",
    "    <h1>\n",
    "        تمرین اول درس پردازش زبان‌های طبیعی\n",
    "    </h1>\n",
    "    <h3>\n",
    "        گردآورندگان:<br/>\n",
    "        ساحل مس‌فروش، سروش تابش، درنا دهقانی\n",
    "    </h3>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
    "    ما در این تمرین ترک \"استخراج پرسش و پاسخ\" را انتخاب کردیم. در این تمرین قصد داریم از یک جمله فارسی سوالاتی با توجه به روابط علت و معلولی، نقش کلمات در جملات، ارتباط بین واژگان و ... استخراج کنیم. هر سوال به شکل یک دیکشنری پایتون نمایش داده می‌شود که key سوال و value پاسخ به سوال است. گام ابتدایی ما برای پاسخ به این ترک، جستجوی مسائل مشابه بود و از آنجایی که این مسئله هم‌چنان باز است، روش‌های متعددی مبتنی بر Deep Learning یافتیم که چون از مبحث این تمرین خارج بودند، از آنها استفاده نکردیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWTUeohDlQ9b"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "    <h2> 1. تمیز کردن ورودی </h2>\n",
    "    در این بخش، گام‌های ابتدایی برای مراحل آتی را برمی‌داریم. هر جمله که به عنوان ورودی ما داده می‌شود، باید تا حد مناسبی تمیز و ساختاریافته شود تا به عنوان ورودی بخش‌های بعد معتبر باشد. کارهایی مانند نرمال‌سازی و ... در این بخش انجام می‌گردد. از توابع تعریف شده در کتابخانه hazm استفاده می‌کنیم.\n",
    "\n",
    "    دقت کنید از آن‌جایی که در مواردی مانند کتابخانه  hazm به خوبی عمل نمی‌کند، بهتر است جمله‌ی ورودی تا جای ممکن نرمالایز شده باشد و تا جای ممکن از چنین مشکلاتی دوری شود.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2a4iZZbllQ9e",
    "outputId": "4150c9bc-5c25-433a-c536-3645ff7ced22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hazm in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (0.7.0)\n",
      "Requirement already satisfied: nltk==3.3 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from hazm) (3.3)\n",
      "Requirement already satisfied: libwapiti>=0.2.1; platform_system != \"Windows\" in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from hazm) (0.2.1)\n",
      "Requirement already satisfied: six in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from nltk==3.3->hazm) (1.16.0)\n",
      "Collecting camel-tools\n",
      "  Downloading camel_tools-1.3.1-py3-none-any.whl (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 401 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting cachetools\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting camel-kenlm\n",
      "  Downloading camel-kenlm-2021.12.27.tar.gz (418 kB)\n",
      "\u001b[K     |████████████████████████████████| 418 kB 487 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting transformers>=3.0.2\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 447 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from camel-tools) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from camel-tools) (1.22.2)\n",
      "Requirement already satisfied: pyrsistent in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from camel-tools) (0.18.1)\n",
      "Requirement already satisfied: requests in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from camel-tools) (2.27.1)\n",
      "Collecting torch>=1.3\n",
      "  Using cached torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
      "Requirement already satisfied: pandas in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from camel-tools) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from camel-tools) (4.62.3)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 433 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from camel-tools) (1.8.0)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "Collecting emoji\n",
      "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
      "\u001b[K     |████████████████████████████████| 175 kB 411 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from camel-tools) (1.0.2)\n",
      "Collecting editdistance\n",
      "  Downloading editdistance-0.6.0-cp38-cp38-manylinux2010_x86_64.whl (286 kB)\n",
      "\u001b[K     |████████████████████████████████| 286 kB 498 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from transformers>=3.0.2->camel-tools) (21.3)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 246 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.4.24-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[K     |████████████████████████████████| 764 kB 160 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Using cached filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 106 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 49 kB/s eta 0:00:012\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from requests->camel-tools) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from requests->camel-tools) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from requests->camel-tools) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from requests->camel-tools) (3.3)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from pandas->camel-tools) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from pandas->camel-tools) (2.8.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from scikit-learn->camel-tools) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from scikit-learn->camel-tools) (3.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from packaging>=20.0->transformers>=3.0.2->camel-tools) (3.0.8)\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 173 kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt, camel-kenlm, future, emoji, sacremoses\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-2x_ozd0p/docopt/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-2x_ozd0p/docopt/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-ukkr1rax\n",
      "       cwd: /tmp/pip-install-2x_ozd0p/docopt/\n",
      "  Complete output (6 lines):\n",
      "  usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: setup.py --help [cmd1 cmd2 ...]\n",
      "     or: setup.py --help-commands\n",
      "     or: setup.py cmd --help\n",
      "  \n",
      "  error: invalid command 'bdist_wheel'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for docopt\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for docopt\n",
      "  Building wheel for camel-kenlm (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-2x_ozd0p/camel-kenlm/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-2x_ozd0p/camel-kenlm/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-llr820fg\n",
      "       cwd: /tmp/pip-install-2x_ozd0p/camel-kenlm/\n",
      "  Complete output (6 lines):\n",
      "  usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: setup.py --help [cmd1 cmd2 ...]\n",
      "     or: setup.py --help-commands\n",
      "     or: setup.py cmd --help\n",
      "  \n",
      "  error: invalid command 'bdist_wheel'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for camel-kenlm\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for camel-kenlm\n",
      "  Building wheel for future (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-2x_ozd0p/future/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-2x_ozd0p/future/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-q38labph\n",
      "       cwd: /tmp/pip-install-2x_ozd0p/future/\n",
      "  Complete output (6 lines):\n",
      "  usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: setup.py --help [cmd1 cmd2 ...]\n",
      "     or: setup.py --help-commands\n",
      "     or: setup.py cmd --help\n",
      "  \n",
      "  error: invalid command 'bdist_wheel'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for future\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for future\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-2x_ozd0p/emoji/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-2x_ozd0p/emoji/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-rgdzx9a4\n",
      "       cwd: /tmp/pip-install-2x_ozd0p/emoji/\n",
      "  Complete output (6 lines):\n",
      "  usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: setup.py --help [cmd1 cmd2 ...]\n",
      "     or: setup.py --help-commands\n",
      "     or: setup.py cmd --help\n",
      "  \n",
      "  error: invalid command 'bdist_wheel'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for emoji\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for emoji\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-2x_ozd0p/sacremoses/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-2x_ozd0p/sacremoses/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-rxhau4g6\n",
      "       cwd: /tmp/pip-install-2x_ozd0p/sacremoses/\n",
      "  Complete output (6 lines):\n",
      "  usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: setup.py --help [cmd1 cmd2 ...]\n",
      "     or: setup.py --help-commands\n",
      "     or: setup.py cmd --help\n",
      "  \n",
      "  error: invalid command 'bdist_wheel'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for sacremoses\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for sacremoses\n",
      "Failed to build docopt camel-kenlm future emoji sacremoses\n",
      "Installing collected packages: docopt, cachetools, tabulate, camel-kenlm, tokenizers, regex, filelock, typing-extensions, pyyaml, huggingface-hub, click, sacremoses, transformers, torch, dill, future, emoji, editdistance, camel-tools\n",
      "    Running setup.py install for docopt ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for camel-kenlm ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for sacremoses ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for future ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for emoji ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed cachetools-5.0.0 camel-kenlm-2021.12.27 camel-tools-1.3.1 click-8.1.3 dill-0.3.4 docopt-0.6.2 editdistance-0.6.0 emoji-1.7.0 filelock-3.6.0 future-0.18.2 huggingface-hub-0.6.0 pyyaml-6.0 regex-2022.4.24 sacremoses-0.0.53 tabulate-0.8.9 tokenizers-0.12.1 torch-1.11.0 transformers-4.18.0 typing-extensions-4.2.0\n",
      "Collecting Tashaphyne\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f6251e14670>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /packages/ae/00/e7a413e76c2a9ef2361809f27df6f355fc848c71dbbea78e3633e1d46523/Tashaphyne-0.3.6-py3-none-any.whl\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f6251ac65b0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /packages/ae/00/e7a413e76c2a9ef2361809f27df6f355fc848c71dbbea78e3633e1d46523/Tashaphyne-0.3.6-py3-none-any.whl\u001b[0m\n",
      "  Downloading Tashaphyne-0.3.6-py3-none-any.whl (251 kB)\n",
      "\u001b[K     |████████████████████████████████| 251 kB 29 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarabic\n",
      "  Downloading PyArabic-0.6.14-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 29 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from pyarabic->Tashaphyne) (1.16.0)\n",
      "Installing collected packages: pyarabic, Tashaphyne\n",
      "Successfully installed Tashaphyne-0.3.6 pyarabic-0.6.14\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f9b4a180250>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/parstdex/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f9b4a180d00>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/parstdex/\u001b[0m\n",
      "Collecting parstdex~=1.1.0\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f9b4a4d3730>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /packages/88/48/2d36557da2b512dfb154d078399dba447cac95c09e0c615c0d0462650890/parstdex-1.1.5-py3-none-any.whl\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f9b4a4d37c0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /packages/88/48/2d36557da2b512dfb154d078399dba447cac95c09e0c615c0d0462650890/parstdex-1.1.5-py3-none-any.whl\u001b[0m\n",
      "  Downloading parstdex-1.1.5-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 379 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from parstdex~=1.1.0) (1.22.2)\n",
      "Collecting pytextspan~=0.5.0\n",
      "  Downloading pytextspan-0.5.4-cp38-cp38-manylinux2010_x86_64.whl (282 kB)\n",
      "\u001b[K     |████████████████████████████████| 282 kB 113 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pytextspan, parstdex\n",
      "Successfully installed parstdex-1.1.5 pytextspan-0.5.4\n",
      "Requirement already satisfied: zeep in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (4.1.0)\n",
      "Requirement already satisfied: isodate>=0.5.4 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from zeep) (0.6.1)\n",
      "Requirement already satisfied: pytz in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from zeep) (2021.3)\n",
      "Requirement already satisfied: attrs>=17.2.0 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from zeep) (21.4.0)\n",
      "Requirement already satisfied: platformdirs>=1.4.0 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from zeep) (2.5.1)\n",
      "Requirement already satisfied: lxml>=4.6.0 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from zeep) (4.8.0)\n",
      "Requirement already satisfied: requests-file>=1.5.1 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from zeep) (1.5.1)\n",
      "Requirement already satisfied: requests-toolbelt>=0.7.1 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from zeep) (0.9.1)\n",
      "Requirement already satisfied: cached-property>=1.3.0 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from zeep) (1.5.2)\n",
      "Requirement already satisfied: requests>=2.7.0 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from zeep) (2.27.1)\n",
      "Requirement already satisfied: six in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from isodate>=0.5.4->zeep) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from requests>=2.7.0->zeep) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from requests>=2.7.0->zeep) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from requests>=2.7.0->zeep) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sahel/university/NLP/course-nlp-ir-1-text-exploring/.venv/lib/python3.8/site-packages (from requests>=2.7.0->zeep) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install hazm\n",
    "!pip install camel-tools\n",
    "!pip install Tashaphyne\n",
    "!pip install parstdex~=1.1.0\n",
    "\n",
    "#  نصب کتاب‌خانه مورد نیاز برای اتصال به وب‌سرویس فارس‌نت\n",
    "! pip install zeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1q3cjw4fB7iZ"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "from itertools import chain\n",
    "import collections\n",
    "import hazm\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import tqdm\n",
    "import itertools\n",
    "import functools\n",
    "import operator\n",
    "import matplotlib\n",
    "from zeep import Client\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from requests import Session\n",
    "from zeep.transports import Transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Ws8pLkylQ9i",
    "outputId": "3c6f39a8-1894-4283-e9fe-ef7c976d7830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['چون بارون اومده، رنگین کمونه', 'هوا بارونیه', '']\n"
     ]
    }
   ],
   "source": [
    "def sentence_clean(sentence: str):\n",
    "    normalizer = hazm.Normalizer()\n",
    "    sentence = normalizer.normalize(sentence)\n",
    "    return sentence.split('. ')\n",
    "\n",
    "sentence = 'چون بارون اومده  ، رنگین کمونه. هوا بارونیه. '\n",
    "print(sentence_clean(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z3-Yq6-lQ9n"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "    <h2> 2. استخراج ساختار سوالات </h2>\n",
    "    جملاتی که امکان استخراج سوالات از آنها ممکن است، دو نوعند. نوع اول دارای برخی کلمات کلیدی (مانند زیرا، چون و ...) هستند. نوع دوم جملاتی هستند که فاقد اینگونه کلماتند. مثلاً امروز هوا بارانیست: امروز هوا چگونه است؟ بارانی. در طراح این بخش از ماژول <code>cause_effect_extractions</code> ایده گرفتیم.<br>\n",
    "    <h4> 2.1. استخراج سوال از جملات با کلمات کلیدی </h4>\n",
    "    در این مرحله، به یافتن کلمات کلیدی در جملاتی که امکان استخراج سوالات از آنها وجود دارد پرداختیم. در یک Google Sheet لیست این کلمات، انواع نحوه به کارگیری آنها در جملات، مثال‌هایی از هر یک و هم‌چنین ساختار سوال و جواب و مثال از آنها را مشخص کردیم. \n",
    "    هم‌چنین مثال‌هایی از جملات را به عنوان داده‌ی تست یافتیم و سوال‌هایی از آنها استخراج کردیم.\n",
    "    <a href=\"https://docs.google.com/spreadsheets/d/1qsCfRVr5RgXYW2qEVbrP3dq7-l3wNngjPAsXrHN89DQ/edit#gid=0\" target=\"_top\">فهرست کلمات کلیدی و جملات تست</a><br/>\n",
    "    سپس در تابع <code>extract_cause_effect</code> از جمله‌ای که به عنوان ورودی داده می‌شود، با توجه به ساختار جمله که ورودی دیگر این تابع و از انواع پرسش و پاسخ است، رابطه‌ی علت و معلولی که ممکن است در جمله باشد، استخراج می‌گردد.<br>\n",
    "    در دیکشنری <code>all_regexes</code> نوع و ساختار جملاتی که قابلیت طرح سوال از آنها وجود دارد توسط regex طراحی شده است. هم‌چنین ساختار پرسش و پاسخ آنها نیز وجود دارد.<br>\n",
    "    اگر ساختار regex در جمله موجود بود، بسته به اینکه کدام بخش جمله در سوال و کدام بخش آن در جواب استفاده شود، سوال و جواب از جمله ساخته شده و در دیکشنری خروجی تابع قرار می‌گیرد.\n",
    "    همچنین برای ساختار جملاتی که از تا به عنوان حرف ربط استفاده کرده اند برای بررسی اینکه آیا تا حرف ربط است یا خیر از کلاس\n",
    "    CauseEffectExtraction\n",
    "    کتابخانه‌ی \n",
    "    parsi.io\n",
    "     کمک گرفته شد. بدین ترتیب که در صورتی که ساختار پیدا شده مربوط به حروف ربط باشد به کمک این کلاس بررسی میکنیم که آیا حروف پیدا شده حرف ربط هستند یا حرف اضافه و در صورتی که این کلاس بتواند ساختار \n",
    "     cause and effect\n",
    "     تشخیص دهد به استخراج سوال می‌پردازیم. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WdMAWdz2lQ9q"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from cause_effect_extractions import CauseEffectExtraction\n",
    "all_regexes = {\n",
    "  \"چرایی\": {\"regex\": r\"\"\"(?P<effect>.*)[،|؛|](?P<reason> زیرا| چون| به‌دلیل| بدلیل|چون\\sکه | به\\sدلیل\\sاینکه)(?P<cause>.*)|چون(?P<cause2>.*)(،|\\s،|؛)(?P<effect2>.*)\"\"\", \"q_as\": [{\"question\": \"چرا {effect} ؟\", \"answer\": \"زیرا {cause}\"}]}, \n",
    "  \"سببی\": {\"regex\": r\"(?P<effect>.*) (?P<reason>مسبب|دلیل|مسبّب) (?P<cause>.*) [است|شد|شدند]|(?P<reason2>مسبب|دلیل) (?P<effect2>.*)[،|؛] (?P<cause2>) است.\", \"q_as\": [{\"question\": \"{effect} باعث چه می شود؟ \", \"answer\": \"باعث {cause}\"}, {\"question\": \"چه باعث  {cause} می‌شود?\", \"answer\": \"{effect}\"}]},\n",
    "  \"موجب\": {\"regex\":r\"(?P<effect>.*) موجب (?P<cause>.*) می‌شود.*|(?P<effect2>.*) موجبات (?P<cause2>.*) فراهم می‌کند\",\"q_as\": [{ \"question\": \"چه موجب {effect} می‌شود؟\", \"answer\": \"{cause}\"}, {\"question\": \"{cause} موچب چه می‌شود؟\", \"answer\": \"موجب {effect}\"}]},\n",
    "  \"ترین\": {\"regex\":r\"(?P<tarin>.*ترین) (?P<cause>.*)[،|؛](?P<effect>.*) است\", \"q_as\": [{\"question\": \"{tarin} {cause} چیست؟\", \"answer\": \"{effect}\"}]},\n",
    "  \"خاطر\": {\"regex\": r\"\"\"(?P<reason> بخاطر|به خاطر) (?P<cause>.*)[،|] (?P<effect>.*)|(?P<effect2>.*) (?P<reason2> بخاطر|به خاطر) (?P<cause2>.*)\"\"\",\"q_as\": [{ \"question\": \"چرا {effect} ؟\", \"answer\": \"به خاطر {cause}\"}]},\n",
    "  \"منجر\": {\"regex\": r\"(?P<cause>.*)(?P<reason> منجر به)(?P<effect>.*)می شود.|(?P<reason2>مسبب|دلیل) (?P<effect2>.*)[،|؛] (?P<cause2>) است.\", \"q_as\": [{\"question\": \"علت {effect} چیست؟\", \"answer\": \"{cause}\"}]},\n",
    "   \"هدف\": {\"regex\":r\"هدف (?P<effect>.*) (?P<reason>این\\sاست\\sکه|این\\sاست) (?P<cause>.*)\", \"q_as\": [{\"question\": \"هدف {effect} چیست؟\", \"answer\": \"{cause}\"}]},\n",
    "   \"تا\": {\"regex\":r\"(?P<effect>.*) (?P<reason>تا) (?P<cause>.*)\", \"q_as\": [{ \"question\": \"چرا {effect} ?\", \"answer\": \"{cause}\"}]},\n",
    "   \"علت\": {\"regex\": r\"(?P<reason>علت) (?P<effect>.*)[،|؛] (?P<cause>.*) است\", \"q_as\": [{ \"question\": \"علت {effect} چیست؟\", \"answer\": \"{cause}\"}]},\n",
    "   \"نتیجه\": {\"regex\": r\"(?P<effect>.*) (?P<reason>نتیجه‌ی|نتیجه\\sی) (?P<cause>.*) [است|هستند]\", \"q_as\": [{ \"question\": \"{effect} نتیجه‌ی چیست؟\", \"answer\": \"{cause}\"}]}\n",
    "}\n",
    "\n",
    "cause_effect_extractor_keys = [\"تا\", ]\n",
    "\n",
    "def validate_ta_regex(text, key):\n",
    "  effect_extractor = CauseEffectExtraction()\n",
    "  result = effect_extractor.run(text)\n",
    "  if not result[1] is None:\n",
    "    return result[1] == key\n",
    "  return False\n",
    "\n",
    "def get_all_not_none_groups(x):\n",
    "  group_dicts = x.groupdict()\n",
    "  groups = {}\n",
    "  for key, value in group_dicts.items():\n",
    "    if value:\n",
    "      if key == \"cause2\" or key == \"effect2\" or key == \"reason2\":\n",
    "        groups[key[:-1]] = value\n",
    "      else:\n",
    "        groups[key] = value\n",
    "  if (not \"cause\" in groups.keys()) or (not \"effect\" in groups.keys()):\n",
    "    print(\"bad input\")\n",
    "    return None # cause and effect shouldn't be empty\n",
    "  return groups\n",
    "\n",
    "def extract_cause_effects(text: str, key: str):\n",
    "  \"\"\"extracting cause and effect parts from text based on key regex. creating a Q&A based on key question format and answer format\n",
    "  Parameters\n",
    "  ---------\n",
    "  text: str\n",
    "    sentence query used to extract question and answers.\n",
    "  key: str\n",
    "    key should be one of all_regexes.keys(). sentence format used to extract Q&A\n",
    "  \n",
    "  \n",
    "  Returns\n",
    "  -------\n",
    "  result: dict\n",
    "    includes question and answer sentences.\n",
    "    \"\"\"\n",
    "\n",
    "  key_information = all_regexes.get(key, None)\n",
    "  if not key_information:\n",
    "    print(\"you should specify current key information in all_regexes dict\")\n",
    "    return\n",
    "  regex = key_information.get(\"regex\")\n",
    "  first_reg = re.compile(regex)\n",
    "  x = re.search(first_reg, text)\n",
    "  if x is not None:\n",
    "    regex_groups = get_all_not_none_groups(x)\n",
    "    if regex_groups is None:\n",
    "      return\n",
    "  else:\n",
    "    # regex didn't found the structure. \n",
    "    return None\n",
    "  if key in cause_effect_extractor_keys:\n",
    "    if not validate_ta_regex(text, key):\n",
    "      print(\"regex not validated with cause effect extractor\")\n",
    "      return None\n",
    "  results = []\n",
    "  q_as = key_information.get(\"q_as\")\n",
    "  for q_a in q_as:\n",
    "    q_format = q_a.get(\"question\")\n",
    "    a_format = q_a.get(\"answer\")  \n",
    "    result = {\"question\": q_format.format(**regex_groups), \"answer\": a_format.format(**regex_groups)}\n",
    "    results.append(result)\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXDV-Y20lQ9w"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "    در تابع <code>extract_question</code> ابتدا روی تمامی ساختارهای موجود که امکان طرح سوال از آنها وجود دارد، پیمایشی انجام می‌گیرد. در هر پیمایش، هر ساختار از <code>all_regexes</code> در جمله‌ی ورودی توسط تابع <code>extract_cause_effects</code> بررسی می‌گردد و در صورت داشتن خروجی معتبر، پرسش و پاسخ مربوطه‌ی آن نمایش داده می‌شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVyBNIhRlQ9z",
    "outputId": "d0bd9ee3-7165-4f58-cd8d-e726ff89eebe"
   },
   "outputs": [],
   "source": [
    "def extract_questions(text: str):\n",
    "    \"\"\"\n",
    "    checking all different sentence formats on text. if one is applied ignore others and return\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        input sentence(s)\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    result: dict\n",
    "      question and answer sentences.\n",
    "    \"\"\"\n",
    "    text = sentence_clean(text)\n",
    "    for t in text:\n",
    "      if len(t) > 1:\n",
    "        for key, value in all_regexes.items():\n",
    "            result = extract_cause_effects(t, key)\n",
    "            if result:\n",
    "                print(result)\n",
    "                return result\n",
    "    \n",
    "sentence = 'بارون موجب رنگین کمون می‌‌شود'\n",
    "extract_questions(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL3qPcRdlQ92"
   },
   "source": [
    "<div dir='rtl' style ='font-family: \"B Nazanin\";'>\n",
    "    <h4>2.2. استخراج سوال از جملات بدون کلمات کلیدی</h4>\n",
    "    عملکرد کلی در این بخش بدین صورت است که امکان پرسش با حذف بخشی از جمله ممکن است و به جای بخش حذف شده، ضمیر پرسشی مربوطه جایگزین آن می‌گردد و سوال تشکیل می‌شود. در نتیجه بخش حذف شده از جمله، پاسخ به آن پرسش است.<br>\n",
    "    مثلاً در جمله‌ی \"او کتاب را برداشت.\"، با حذف \"او\" که اشاره به فرد دارد و جایگزین کردن \"چه کسی\" یک سوال ساخته می‌شود. هم‌چنین با حذف \"کتاب\" که اشاره به شیء دارد و جایگزین کردن \"چه چیزی\" می‌توان سوال دیگری ساخت.<br>\n",
    "    چالشی که در این بخش با آن مواجه بودیم، نحوه برخورد با گروه‌های اسمی بود که با حرف اضافه شروع می‌شدند. مثلاً در جمله‌ی \"او با آرامش راه رفت.\" تشخیص اینکه \"با\" حرف ربط یا حرف اضافه است برای ما مسئله بود. در چنین شرایطی تصمیم گرفتیم به کلمه‌ی پیش از این حرف نگاه کنیم و اگر فعل بود، آن را حرف ربط و در غیر اینصورت حرف اضافه در نظر بگیریم. در این صورت کلمه‌ی پرسشی مناسب برای گروه اسمی \"با آرامش\"، \"چگونه\" است. <br>\n",
    "    برای استفاده از تابع <code>POSTagger</code> از کتابخانه‌ی hazm، به دلیل مشکلاتی که در استفاده‌ی مستقیم از کتابخانه‌ی آن پیش می‌آمد، مجبور شدم از محتوای این تابع به شکلی دستی استفاده کنم در فولدر resources قرار دارد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "R21VvZmo8mIK"
   },
   "outputs": [],
   "source": [
    "# download \"resources\" from here: https://github.com/sobhe/hazm/releases/download/v0.5/resources-0.5.zip\n",
    "tagger = hazm.POSTagger(model='./resources/postagger.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCNqUZurIgL4"
   },
   "source": [
    "<div dir='rtl' style ='font-family: \"B Nazanin\";'>\n",
    "  بخش‌های قابل پرسش در جمله به چهار گروه متممی، مفعولی، نهادی و قیدی تقسیم می‌شوند. در تابع <code>extract_structure</code> برای هر یک از این ساختارها، regex مربوطه نوشته شده و به کمک تابع <code>POSTagger</code> کتابخانه‌ی hazm، درخت روابط واژگانی جمله نمایش داده می‌شود.\n",
    "  دقت کنید که این\n",
    "  POSTagger\n",
    "  نیز چالش‌های زیادی دارد که بر دقت کد تاثیر می‌گذارند. به طور مثال عدد سه می‌تواند به عنوان صفت و یا اسم در نظر گرفته بشود و گاهی جایگاه آن اشتباه تشخیص داده ‌می‌شود.\n",
    "  \n",
    "  با تقسیم جمله به گروه‌های اسمی مختلف و تشخیص نوع این گروه‌ها به کمک \n",
    "  FarsiNet\n",
    "  می‌توان هرکدام از آن‌ها را با ضمیر پرسشی مناسب جایگزین کرد\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNVnaHHrILNC",
    "outputId": "329be43e-e55d-4902-f101-d8ec295a0631"
   },
   "outputs": [],
   "source": [
    "questionable_poses = {\n",
    "    'MOTAMEMI': {'pos_hint_word': 'Noun', 'pos_hint_expression': ['N', 'Ne', 'AJ', 'AJe']},\n",
    "    'MAFOULI': {'pos_hint_word': 'Noun', 'pos_hint_expression': ['N', 'Ne']},\n",
    "    'NAHADI': {'pos_hint_word': 'Noun', 'pos_hint_expression': ['N', 'Ne']},\n",
    "    'GHEIDI': {'pos_hint_word': 'Adverb', 'pos_hint_expression': ['ADV']},\n",
    "    'ADAD': {'pos_hint_expression': ['NUM']},\n",
    "}\n",
    "\n",
    "\n",
    "def extract_structures(sentence):\n",
    "    neutral_words = r\"N|Ne|PRO|PROe\"\n",
    "    grammar = r\"\"\"\n",
    "      MOTAMEMI:  {<P|Pe><N|Ne>(<CONJ>?<N|Ne|AJ|AJe>)*}\n",
    "      MAFOULI:   {<N|Ne><POSTP>}\n",
    "      NAHADI:    {<DET>?<NW>((<CONJ><NW>)|<AJe|AJ>)*}\n",
    "      GHEIDI:    {<ADV>+}\n",
    "      ADAD:      {<NUM>+}\n",
    "    \"\"\"\n",
    "    grammar = grammar.replace('NW', neutral_words)\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    return cp.parse(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree('S', [Tree('NAHADI', [('کد', 'Ne'), ('زیبای', 'AJe')]), Tree('NAHADI', [('ما', 'PRO')]), Tree('GHEIDI', [('خیلی', 'ADV'), ('سریع', 'ADV')]), Tree('MAFOULI', [('سوال\\u200cها', 'N'), ('را', 'POSTP')]), ('جواب\\u200cداد', 'V'), ('.', 'PUNC')])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = extract_structures(tagger.tag(hazm.word_tokenize('کد زیبای ما خیلی سریع سوال‌ها را جواب‌داد.')))\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree('S', [Tree('NAHADI', [('میزان', 'Ne')]), Tree('NAHADI', [('این', 'DET'), ('تورم', 'N')]), Tree('MOTAMEMI', [('به', 'P'), ('سیاست\\u200cها', 'N'), ('و', 'CONJ'), ('نگرش\\u200cها', 'N')]), ('بستگی\\u200cدارد', 'V'), ('.', 'PUNC')])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = extract_structures(tagger.tag(hazm.word_tokenize('میزان این تورم به سیاست‌ها و نگرش‌ها بستگی‌دارد.')))\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v89HU8ivO8eo"
   },
   "source": [
    "<div dir='rtl' style ='font-family: \"B Nazanin\";'>\n",
    "  برای تشخیص اسنادی بودن یا نبودن یک جمله از تابع <code>is_linking_centence</code> استفاده می‌کنیم و بررسی اسنادی بودن فعل جمله توسط تابع <code>is_linking_verb</code> انجام می‌گردد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHJzUJMvOgUk",
    "outputId": "ad13350d-c278-41e9-8012-ea46cdf3d9f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LINKING_VERBS = {'است', 'بود', 'شد', 'گشت', 'گردید', 'هست'}\n",
    "\n",
    "\n",
    "def is_linking_verb(verb):\n",
    "    verb = set(hazm.Lemmatizer().lemmatize(verb).split('#'))\n",
    "    return bool(LINKING_VERBS.intersection(verb))\n",
    "\n",
    "\n",
    "def is_linking_sentence(sentence_tokens):\n",
    "    words = tagger.tag(sentence_tokens)\n",
    "    verb_types = map(is_linking_verb, map(lambda x: x[0], filter(lambda x: x[1] == 'V', words)))\n",
    "    return functools.reduce(operator.or_, verb_types, False)\n",
    "\n",
    "is_linking_sentence(hazm.word_tokenize('این خانه زیبا است.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glpS5McQUNJW"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "  برای تشخیص نوع بخش حذف شده از جمله و جایگزینی ضمیر پرسشی مناسب، از کتابخانه‌ی wordnet فارسی یا فارس‌نت استفاده کردیم. ابتدا ثبت نام کرده و مراحل لازم برای اتصال به آن را انجام دادیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "H-KbAXGxU7Wj",
    "outputId": "e660c32e-d8a5-4895-ba65-4eb0ee5ef545"
   },
   "outputs": [],
   "source": [
    "# address of FarsNet's web services\n",
    "wsdl_sense_service = 'http://nlp.sbu.ac.ir:8180/WebAPI/services/SenseService?WSDL'\n",
    "wsdl_synset_service = 'http://nlp.sbu.ac.ir:8180/WebAPI/services/SynsetService?WSDL'\n",
    "\n",
    "\n",
    "# username and token needed for authentication. You can get this token by signing up on http://farsnet.nlp.sbu.ac.ir\n",
    "# users = [{\"username\": \"\"}, {\"username\"}]\n",
    "username = 'USERNAME'\n",
    "token = 'TOKEN'\n",
    "\n",
    "# connecting client\n",
    "session = Session()\n",
    "session.auth = HTTPBasicAuth(username, token)\n",
    "client_sense = Client(wsdl_sense_service, transport=Transport(session=session))\n",
    "client_synset = Client(wsdl_synset_service, transport=Transport(session=session))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t042HNp2VBjN"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "  برای انتخاب ضمیر پرسشی مناسب، لازم است نوع واژه را از نظر اشاره داشتن به فرد، مکان، زمان و یا حالت بدانیم. به کمک تابع <code>getSensesByWord</code> می‌توان درباره‌ی هر واژه اطلاعاتی به دست آورد. فیلد nounCategory اطلاعاتی در مورد خاص یا غیر خاص بودن اسم  می‌دهد. مثلاً برای نام \"فاطمه\" این فیلد برابر با <code>Specific</code> و برای \"درخت\" برابر با <code>None</code> است. فیلد می‌تواند در مورد نوع نام، مانند انسان بودن اطلاعاتی به ما دهد.<br>\n",
    "  به کمک تابع <code>getSynsetsByWord</code> و فیلد semanticCategory از آن نیز می‌توان در مورد نوع قیود از نظر زمانی و مکانی و غیره بودن را تشخیص داد. مثال‌هایی از این دو تابع را می‌توان مشاهده کرد:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eiRBlYOPa_Qz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "    'adjectiveType1': None,\n",
      "    'adjectiveType2': None,\n",
      "    'adverbType1': None,\n",
      "    'adverbType2': None,\n",
      "    'id': 30551,\n",
      "    'isAbbreviation': False,\n",
      "    'isCausative': False,\n",
      "    'isColloquial': False,\n",
      "    'isIdiomatic': False,\n",
      "    'nounCategory': 'General',\n",
      "    'nounNumeralType': None,\n",
      "    'nounPluralType': None,\n",
      "    'nounSpecifityType': None,\n",
      "    'nounType': 'Simple',\n",
      "    'preNounAdjectiveType': None,\n",
      "    'pronoun': None,\n",
      "    'seqId': '0',\n",
      "    'synsetId': '12142',\n",
      "    'transitiveType': None,\n",
      "    'value': 'درخت',\n",
      "    'verbActivePassive': None,\n",
      "    'verbPastStem': None,\n",
      "    'verbPresentStem': None,\n",
      "    'verbTransitivity': None,\n",
      "    'verbType': None,\n",
      "    'word': {\n",
      "        'defaultPhonetic': 'deraxt',\n",
      "        'defaultValue': 'درخت',\n",
      "        'id': 21951,\n",
      "        'pos': 'Noun'\n",
      "    }\n",
      "}]\n",
      "[{\n",
      "    'adjectiveType1': None,\n",
      "    'adjectiveType2': None,\n",
      "    'adverbType1': None,\n",
      "    'adverbType2': None,\n",
      "    'id': 40372,\n",
      "    'isAbbreviation': False,\n",
      "    'isCausative': False,\n",
      "    'isColloquial': False,\n",
      "    'isIdiomatic': False,\n",
      "    'nounCategory': 'Specific',\n",
      "    'nounNumeralType': None,\n",
      "    'nounPluralType': None,\n",
      "    'nounSpecifityType': 'Human',\n",
      "    'nounType': 'Simple',\n",
      "    'preNounAdjectiveType': None,\n",
      "    'pronoun': None,\n",
      "    'seqId': '1',\n",
      "    'synsetId': '44924',\n",
      "    'transitiveType': None,\n",
      "    'value': 'فاطمه',\n",
      "    'verbActivePassive': None,\n",
      "    'verbPastStem': None,\n",
      "    'verbPresentStem': None,\n",
      "    'verbTransitivity': None,\n",
      "    'verbType': None,\n",
      "    'word': {\n",
      "        'defaultPhonetic': 'fAteme',\n",
      "        'defaultValue': 'فاطمه',\n",
      "        'id': 28906,\n",
      "        'pos': 'Noun'\n",
      "    }\n",
      "}]\n",
      "[{\n",
      "    'id': 10367,\n",
      "    'noMapping': '0',\n",
      "    'nofather': '0',\n",
      "    'pos': 'Noun',\n",
      "    'semanticCategory': 'TIME'\n",
      "}, {\n",
      "    'id': 10368,\n",
      "    'noMapping': '0',\n",
      "    'nofather': '0',\n",
      "    'pos': 'Noun',\n",
      "    'semanticCategory': 'TIME'\n",
      "}, {\n",
      "    'id': 22021,\n",
      "    'noMapping': '0',\n",
      "    'nofather': '0',\n",
      "    'pos': 'Adverb',\n",
      "    'semanticCategory': 'زمان'\n",
      "}]\n",
      "[{\n",
      "    'id': 15232,\n",
      "    'noMapping': '0',\n",
      "    'nofather': '0',\n",
      "    'pos': 'Adverb',\n",
      "    'semanticCategory': 'مکان'\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "request = {\"searchKeyword\": \"درخت\", \"userKey\": \"d428e755-3b91-11eb-8a1e-080027d731c1\", \"searchStyle\": \"EXACT\"}\n",
    "sense = client_sense.service.getSensesByWord(**request)\n",
    "print(sense)\n",
    "\n",
    "request = {\"searchKeyword\": \"فاطمه\", \"userKey\": \"d428e755-3b91-11eb-8a1e-080027d731c1\", \"searchStyle\": \"EXACT\"}\n",
    "sense = client_sense.service.getSensesByWord(**request)\n",
    "print(sense)\n",
    "\n",
    "request = {\"searchKeyword\": \"دیروز\", \"userKey\": \"d428e755-3b91-11eb-8a1e-080027d731c1\", \"searchStyle\": \"EXACT\"}\n",
    "sense = client_synset.service.getSynsetsByWord(**request)\n",
    "print(sense)\n",
    "\n",
    "request = {\"searchKeyword\": \"آنجا\", \"userKey\": \"d428e755-3b91-11eb-8a1e-080027d731c1\", \"searchStyle\": \"EXACT\"}\n",
    "sense = client_synset.service.getSynsetsByWord(**request)\n",
    "print(sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address of FarsNet's web services\n",
    "wsdl_sense_service = 'http://nlp.sbu.ac.ir:8180/WebAPI/services/SenseService?WSDL'\n",
    "wsdl_synset_service = 'http://nlp.sbu.ac.ir:8180/WebAPI/services/SynsetService?WSDL'\n",
    "\n",
    "# username and token needed for authentication. You can get this token by signing up on http://farsnet.nlp.sbu.ac.ir\n",
    "# users = [{\"username\": \"\"}, {\"username\"}]\n",
    "username = 'SahelMesforoush'\n",
    "token = 'd428e755-3b91-11eb-8a1e-080027d731c1'\n",
    "\n",
    "# connecting client\n",
    "session = Session()\n",
    "session.auth = HTTPBasicAuth(username, token)\n",
    "client_sense = Client(wsdl_sense_service, transport=Transport(session=session))\n",
    "client_synset = Client(wsdl_synset_service, transport=Transport(session=session))\n",
    "\n",
    "\n",
    "def get_sense(word):\n",
    "    word = hazm.Lemmatizer().lemmatize(word)\n",
    "    request = {\"searchKeyword\": word, \"userKey\": token, \"searchStyle\": \"EXACT\"}\n",
    "    sense = client_sense.service.getSensesByWord(**request)\n",
    "    return sense\n",
    "\n",
    "\n",
    "def get_synset(word):\n",
    "    word = hazm.Lemmatizer().lemmatize(word)\n",
    "    request = {\"searchKeyword\": word, \"userKey\": token, \"searchStyle\": \"EXACT\"}\n",
    "    sense = client_synset.service.getSynsetsByWord(**request)\n",
    "    return sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "بدین ترتیب به کمک این توابع می‌توان نوع بسیاری از واژگان یا گروه‌های اسمی را تشخیص داد و متناسب اسم خاص یا غیرخاص، انسان یا غیر انسان، حالت، ارتباط، مکان ، زمان و ...، ضمیر پرسشی مناسب تعیین کرد.\n",
    "این کار را در تابع\n",
    "<code>get_question_word</code>\n",
    "پیاده سازی کرده‌ایم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_word(expression, pos_hint_word=[], pos_hint_expression=[]):\n",
    "    expression = hazm.Normalizer().normalize(expression)\n",
    "    words = hazm.word_tokenize(expression)\n",
    "    if len(words) == 1:\n",
    "        word = words[0]\n",
    "\n",
    "        if 'NUM' in pos_hint_expression:\n",
    "            return 'چند'\n",
    "\n",
    "        # extracting sense and pos\n",
    "        senses = get_sense(word)\n",
    "        if not senses:\n",
    "            return 'چه'\n",
    "        if pos_hint_word:\n",
    "            senses_f = list(filter(lambda sense: sense['word']['pos'] == pos_hint_word, senses))\n",
    "            if senses_f:\n",
    "                senses = senses_f\n",
    "        poses = list(map(lambda sense: sense['word']['pos'], senses))\n",
    "        sense = senses[0]\n",
    "        pos = sense['word']['pos']\n",
    "\n",
    "        # extracting semantics and synset\n",
    "        synsets = get_synset(word)\n",
    "        if not synsets:\n",
    "            return 'چه'\n",
    "        if pos_hint_expression:\n",
    "            synsets_f = list(filter(lambda synset: synset['pos'] == pos_hint_word, synsets))\n",
    "            if synsets_f:\n",
    "                synsets = synsets_f\n",
    "        semantics = list(map(lambda synset: synset['pos'], synsets))\n",
    "        synset = synsets[0]\n",
    "        semantic = synset['semanticCategory']\n",
    "\n",
    "        # decide how to generate qusition word based on its POS\n",
    "        if pos == 'Adverb':\n",
    "            if semantic in ['TIME', 'زمان']:\n",
    "                return 'چه زمانی'\n",
    "            return 'چگونه'\n",
    "        elif pos == 'Noun':\n",
    "            noun_specifity_type = sense['nounSpecifityType']\n",
    "            if noun_specifity_type == 'Human':\n",
    "                return 'چه کسی'\n",
    "            elif noun_specifity_type == 'Animal':\n",
    "                return 'چه جانوری'\n",
    "            elif noun_specifity_type == 'Place':\n",
    "                return 'کجا'\n",
    "            elif noun_specifity_type == 'Time' or semantic in ['TIME', 'زمان']:\n",
    "                return 'چه زمانی'\n",
    "            else:\n",
    "                return 'چه چیز'\n",
    "        elif pos == 'Adjective':\n",
    "            if 'QUANTITY' in semantics:\n",
    "                return 'چند'\n",
    "            return 'چگونه'\n",
    "        else:\n",
    "            return 'چه'\n",
    "\n",
    "    elif len(words) > 1 and pos_hint_expression:\n",
    "        words = list(filter(lambda word: word[1] in pos_hint_expression, tagger.tag(words)))\n",
    "        if not words:\n",
    "            return 'چه'\n",
    "        return get_question_word(words[0][0], pos_hint_word=pos_hint_word)\n",
    "    else:\n",
    "        return 'چه'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "در انتها به کمک تابع\n",
    "<code>generate_qa_by_substitution</code>\n",
    "ابتدا \n",
    "normalize \n",
    "کرده و با بدست اوردن کلمات و استفاده از \n",
    "postagger\n",
    "موقعیت هرکدام را پیدا میکنیم. پس از به دست اوردن ساختار جمله با بررسی اینکه ایا جمله از نوع هایی که قابل پرسش هستند ضمیر پرسشی معادل را در جمله جایگزین کرده و سوال و جواب را طراحی می‌کنیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_to_string(subtree):\n",
    "    ' '.join(map(lambda leaf: leaf[0], subtree.leaves()))\n",
    "\n",
    "\n",
    "def generate_qa_by_substitution(sentence):\n",
    "    results = []\n",
    "    sentence = hazm.Normalizer().normalize(sentence)\n",
    "    words = hazm.word_tokenize(sentence)\n",
    "    structure_tree = extract_structures(tagger.tag(words))\n",
    "    subtrees = list(structure_tree.subtrees())[1:]\n",
    "    for index, subtree in enumerate(subtrees):\n",
    "        if subtree.label() in questionable_poses:\n",
    "            answer = ' '.join(map(lambda leaf: leaf[0], subtree.leaves()))\n",
    "            question_word = get_question_word(answer, **questionable_poses[subtree.label()])\n",
    "            if subtree.label() == 'MOTAMEMI':\n",
    "                question_word = list(subtree.leaves())[0][0] + ' ' + question_word\n",
    "            elif subtree.label() == 'MAFOULI':\n",
    "                question_word = question_word + ' ' + list(subtree.leaves())[-1][0]\n",
    "            # print(question_word)\n",
    "            question = sentence.replace(answer, question_word).replace('.', '?')\n",
    "            results.append({\"Question\": question, \"Answer\": answer})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Question': 'چه کسی دیروز سه کتاب را برای درس برد?', 'Answer': 'علی'},\n",
       " {'Question': 'علی چه زمانی سه کتاب را برای درس برد?', 'Answer': 'دیروز'},\n",
       " {'Question': 'علی دیروز چند کتاب را برای درس برد?', 'Answer': 'سه'},\n",
       " {'Question': 'علی دیروز سه چه چیز را برای درس برد?', 'Answer': 'کتاب را'},\n",
       " {'Question': 'علی دیروز سه کتاب را برای چه چیز برد?', 'Answer': 'برای درس'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_qa_by_substitution('علی دیروز سه کتاب را برای درس برد.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_TqaX53lQ94"
   },
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "    <h2> 3. صحت‌سنجی </h2>\n",
    "    ابتدا در فایل <code>question_generator.json</code> تعدادی مثال و خروجی‌های مورد توقع از آنها برای پرسش و پاسخ نوشته شد. سپس توسط کلاس \n",
    "    <code>BaseTest</code> \n",
    "    توابعی برای صحت‌سنجی عملکرد بخش‌های پیشین در یافتن و استخراج پرسش و پاسخ از جملات نوشته شد. قابل ذکر است که این کلاس و دو تابع\n",
    "     <code>get_testcases</code>\n",
    "      و\n",
    "       <code>run_test</code> \n",
    "     از کتابخانه‌ی parsi.io گرفته شده‌اند. \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEgNh-1JlQ95",
    "outputId": "31a134b0-9ef6-4cbe-b704-96cebfe05464"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sahel/university/NLP/hws/hw1/HW1.ipynb Cell 29'\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=28'>29</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m***********************************\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=30'>31</a>\u001b[0m tester \u001b[39m=\u001b[39m BaseTest()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=31'>32</a>\u001b[0m tester\u001b[39m.\u001b[39mtest_json()\n",
      "\u001b[1;32m/home/sahel/university/NLP/hws/hw1/HW1.ipynb Cell 29'\u001b[0m in \u001b[0;36mBaseTest.test_json\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_json\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=20'>21</a>\u001b[0m     test_cases \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_testcases(\u001b[39m'\u001b[39;49m\u001b[39m/question_generator.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=21'>22</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m test_cases:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=22'>23</a>\u001b[0m         your_answer \u001b[39m=\u001b[39m extract_questions(i\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32m/home/sahel/university/NLP/hws/hw1/HW1.ipynb Cell 29'\u001b[0m in \u001b[0;36mBaseTest.get_testcases\u001b[0;34m(self, addr)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_testcases\u001b[39m(\u001b[39mself\u001b[39m, addr):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=3'>4</a>\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mgetcwd()\u001b[39m+\u001b[39maddr, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=4'>5</a>\u001b[0m     test_cases \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=5'>6</a>\u001b[0m     f\u001b[39m.\u001b[39mclose()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sahel/university/NLP/hws/hw1/HW1.ipynb#ch0000028?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m test_cases\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "class BaseTest:\n",
    "\n",
    "    def get_testcases(self, addr):\n",
    "        f = open(os.getcwd()+addr, 'r')\n",
    "        test_cases = json.load(f)\n",
    "        f.close()\n",
    "        return test_cases\n",
    "\n",
    "    def run_test(self, obj, addr):\n",
    "        errors = []\n",
    "        test_cases = self.get_testcases(addr)\n",
    "        for i in test_cases:\n",
    "            your_answer = obj.run(i['input'])\n",
    "            correct_answer = i['outputs']\n",
    "            d = {k: (your_answer[k], correct_answer[k]) for k in your_answer if k in correct_answer and your_answer[k] != correct_answer[k]}\n",
    "            for j in d:\n",
    "                errors.append('Input {0}: your answer is {1} correct answer is {2}'.format(i['id'], d[j][0], d[j][1]))\n",
    "        assert not errors, 'errors occured:\\n{}'.format('\\n'.join(errors))\n",
    "\n",
    "    def test_json(self):\n",
    "        test_cases = self.get_testcases('/question_generator.json')\n",
    "        for i in test_cases:\n",
    "            your_answer = extract_questions(i.get('input'))\n",
    "            correct_answer = i.get('output')\n",
    "            print(\"Testing {0}: \".format(str(i['id']) ))\n",
    "            print(\"input: \", i.get(\"input\"))\n",
    "            print(\"correct answer: \", correct_answer)\n",
    "            print(\"method answer: \", your_answer)\n",
    "            print(\"***********************************\")\n",
    "\n",
    "tester = BaseTest()\n",
    "tester.test_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style ='font-family: \"B Nazanin\";'>\n",
    "    <h2> 4. جمع‌بندی </h2>\n",
    "    بنابراین با اجرای تابع\n",
    "    <code>extract_questions</code>\n",
    "    و دادن جمله‌ی ورودی به عنوان یک متن پس از اجرای \n",
    "    <code>sentence_cleaning</code>\n",
    "    بر روی هرکدام از جملات غیر تهی توابع استخراج سوال \n",
    "    <code>extract_cause_effects</code>\n",
    "    و \n",
    "    <code>generate_qa_by_substitution</code>\n",
    "    را اجرا و در صورت داشتن خروجی آن‌ها را نمایش می‌دهد. \n",
    "    در پایان یک آرایه شامل تمام سوال‌های طرح شده توسط این تابع خروجی داده می‌شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Question': 'رنگین کمونه؛ چون چه چیز اومده', 'Answer': 'بارون'},\n",
       " {'question': 'چرا رنگین کمونه ؟', 'answer': 'زیرا  بارون اومده'},\n",
       " {'Question': ' چون چه چیز اومده؛ رنگین کمونه', 'Answer': 'بارون'},\n",
       " {'Question': ' چون بارون اومده؛ رنگین چه چیز', 'Answer': 'کمونه'},\n",
       " {'question': 'چرا  رنگین کمونه ؟', 'answer': 'زیرا  بارون اومده'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_questions(text: str):\n",
    "    \"\"\"\n",
    "    checking all different sentence formats on text. if one is applied ignore others and return\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        input sentence(s)\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    result: dict\n",
    "      question and answer sentences.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    text = sentence_clean(text)\n",
    "    for t in text:\n",
    "      substition_questions = generate_qa_by_substitution(t)\n",
    "      all_results += substition_questions\n",
    "      if len(t) > 1:\n",
    "        for key, value in all_regexes.items():\n",
    "            result = extract_cause_effects(t, key)\n",
    "            if result:\n",
    "                all_results += result\n",
    "                break\n",
    "    return all_results\n",
    "    \n",
    "sentence = 'رنگین کمونه؛ چون بارون اومده. چون بارون اومده؛ رنگین کمونه.'\n",
    "extract_questions(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "34d4e06b41f1b5694cba5296405e982f656f471d454e7abdd2a0fc7df2b7a17b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
