{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS4ZKRc0M72-"
      },
      "source": [
        "<style>\n",
        "@font-face {font-family: \"B Nazanin\"; src: url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.eot\"); src: url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.eot?#iefix\") format(\"embedded-opentype\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.woff2\") format(\"woff2\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.woff\") format(\"woff\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.ttf\") format(\"truetype\"), url(\"//db.onlinewebfonts.com/t/3671adca6f650c92b83f906e49656986.svg#B Nazanin\") format(\"svg\"); }\n",
        "    </style>\n",
        "<div dir=\"rtl\" align=\"center\" style ='font-family: \"B Nazanin\";'>\n",
        "    <h1>\n",
        "        تمرین سوم درس پردازش زبان‌های طبیعی\n",
        "    </h1>\n",
        "    <h3>\n",
        "        گردآورندگان:<br/>\n",
        "        ساحل مس‌فروش، سروش تابش، درنا دهقانی\n",
        "    </h3>\n",
        "    \n",
        "</div>\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "\n",
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "    ما در این تمرین ترک \"تکمیل مصراع دوم با رعایت وزن شعر\" را انتخاب کردیم. در این تمرین قصد داریم به کمک مدل‌های زبانی مناسب، چند کلمه به عنوان یک مصرع از بیت را به عنوان ورودی بگیریم و چند کلمه به عنوان مصرع دوم این بیت را خروجی دهیم. در این تمرین ما از وبسایت گنجور برای جمع‌آوری داده کمک گرفتیم و از چندین قالب شعری استفاده کردیم، زیرا قافیه داشتن یا نداشتن به عنوان ورودی داده می‌شود. اگر نیاز به هم‌قافیه بودن دو مصراع بود، از قالب مثنوی نظیر شاهنامه‌ی فردوسی کمک می‌گیریم و اگر نیاز به هم‌قافیه بودن دو مصراع نبود می‌توانیم از قالب غزل نظیر اشعار حافظ استفاده کنیم. <br>\n",
        "    برای ساخت چنین سیستمی از چند مدل زبانی استفاده می‌کنیم: مدل n-gram، مدل encoder-decoder با یک شبکه LSTM به عنوان encoder، و مدلی پیرو مکانیسم توجه.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbRSi4pJM73p",
        "outputId": "a62ecd89-1d2d-49f0-8623-62b9da331798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 13.2 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 66.9 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394487 sha256=83f9fb7c7c82fd27f58b62f76e39986a2c49d02bf4f7016db347014f05caac7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=153858 sha256=84f28949d5f95f2385c48f838258f35cd0ab77a29dba92319cb7f11b39e7a51b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 14.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 59.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement codec (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for codec\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.17-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 13.3 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 64.7 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 65.2 MB/s \n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.5.18.1)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=5050ffc15d2c1125d5e44a1d800c7defad35e48cd73323b8f6e6a0e02fe380c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.17\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 12.4 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.5\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.7.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 69.9 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 70.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 86.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 53.6 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 58.9 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 70.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 62.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, dill, aiohttp, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.13\n",
            "    Uninstalling multiprocess-0.70.13:\n",
            "      Successfully uninstalled multiprocess-0.70.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.2 dill-0.3.4 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 multiprocess-0.70.12.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "! pip install pandas\n",
        "! pip install hazm\n",
        "! pip install transformers\n",
        "! pip install torch\n",
        "! pip install nltk\n",
        "! pip install numpy\n",
        "! pip install codec\n",
        "! pip install wandb\n",
        "! pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BHsgv30-M73w"
      },
      "outputs": [],
      "source": [
        "import random \n",
        "import numpy as np\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import codecs\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "from __future__ import unicode_literals\n",
        "from hazm import *\n",
        "from nltk import FreqDist\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import torch\n",
        "import wandb\n",
        "import time\n",
        "import copy\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmvI4S4AM73y"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "    <h3> 1. دوباره‌نویسی داده </h3>\n",
        "    از آنجایی که در داده‌ی گرفته شده، ابتدا و انتهای ابیات و مصراع‌ها مشخص نبود، به کمک کد زیر این داده را بازنویسی کردیم. ابتدای هر مصرع جدید با __BOM__ و پایان بیت با __EOM__ مشخص گردید.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJFgOnmUM730"
      },
      "outputs": [],
      "source": [
        "path = 'all_norm.txt'\n",
        "beyt_file = ''\n",
        "with open(path, 'r', encoding=\"utf-8\") as fp:\n",
        "    lines = fp.readlines()\n",
        "    for i in range(0, len(lines) - 1, 2):\n",
        "        mesra1 = '__BOM__ ' + lines[i].strip()\n",
        "        mesra2 = '__BOM__ ' + lines[i + 1].strip()\n",
        "        b = mesra1.strip() + ' ' + mesra2.strip() + ' __EOM__\\n'\n",
        "        beyt_file += b\n",
        "        \n",
        "with open('all_beyt.txt', 'w', encoding=\"utf-8\") as fp:\n",
        "    fp.write(beyt_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDA1FO14M732"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "    <h3> 2. مدل n-gram </h3>\n",
        "    برای ساخت این مدل از کلاس Ngram استفاده کردیم که به کمک مطالب گفته شده در کلاس نوشته شده است. <br> در این مدل، دیتای لازم برای train، مقدار مورد استفاده برای laplace smoothing و n به عنوان ورودی گرفته می‌شوند و بر اساس آنها مدل ساخته می‌شود. هنگام train کردن، اگر با token مواجه شدیم که تکرار آن در کل دیتا بیش از 1 نبود از عبارت __UNK__ به جای آن استفاده می‌کنیم. سپس احتمال هر n-gram متناسب با تعداد آن در کل و تعداد (n_1)-gram ها محاسبه شده و laplace smoothing روی آن انجام می‌گیرد. نهایتاً n-gramها با توجه به احتمالشان به طور کاهشی مرتب می‌شوند، تا سرعت یافتن مصراع دوم بالاتر رود.<br> سپس یک مصراع به عنوان ورودی گرفته می‌شود. با توجه به n، n_1 token پایانی مصراع ورودی پیش پردازش می‌شود و بین n-gramهای موجود که شروعشان با آن n_1 token باشد، n-gram با بیشترین احتمال انتخاب شده و token پایانی آن به عنوان کلمه خروجی داده می‌شود. به همین ترتیب token تولید می‌شود تا به __EOM__ برخورد کنیم.<br>این مدل unigram را نیز اجرا می‌کند و بدین صورت عمل می‌کند که به تعداد کلمات معمول یک مصراع شاهنامه، یعنی 6، متناسب با احتمال هر unigram آنها را تولید می‌کند. واضحاً چون با این روش هر کلمه مستقل از دیگری تولید می‌شود، نتیجه قابل قبول نیست.<br>یک boolean به عنوان ورودی تابع generate_mesra برای رعایت یا عدم رعایت قافیه در نظر گرفته می‌شود. متناسب با مقدار این boolean پس از ساخت مصراع دوم، کلمه‌ی آخر آن بررسی می‌گردد؛ به طور مثال اگر این boolean مقدار True داشت و دو مصراع هم‌قافیه نبودند، کلمه‌ی آخر مصراع ساخته شده به تعداد بار محدودی مجدداً ساخته می‌شود پس از هر بار ساخت مجدداً هم‌قافیه بودن بررسی می‌گردد. در صورتی‌که پس از این تعداد بار محدود هم‌چنان دو مصراع به شرط قافیه‌ی گفته شده نرسیده بودند، دیگر به این شرط توجهی نمی‌شود و شعر ساخته شده‌ی نهایی فارغ از هم‌قافیه بودن یا نبودن خروجی داده می‌شود.<br>بررسی هم‌قافیه بودن با مقایسه‌ی 2 حرف آخر دو کلمه انجام می‌گیرد. اگر دو حرف آخر دو کلمه یکسان بودند هم‌قافیه‌اند.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk6DhWdFM735"
      },
      "outputs": [],
      "source": [
        "class Ngram(object):\n",
        "    \n",
        "    UNK = '__UNK__'\n",
        "    BOM = '__BOM__'\n",
        "    EOM = '__EOM__'\n",
        "    \n",
        "    def __init__(self, data, n, laplace=1):\n",
        "        self.vocab = dict()\n",
        "        self.n = n\n",
        "        self.laplace = laplace\n",
        "        self.tokens = self.preprocess(data)\n",
        "        self.vocab = nltk.FreqDist(self.tokens)\n",
        "        self.model = self.create_model()\n",
        "    \n",
        "    def preprocess(self, data):\n",
        "        tokens = data.strip().split()\n",
        "        if not len(self.vocab):\n",
        "            self.vocab = nltk.FreqDist(tokens)\n",
        "        return [token if self.vocab[token] > 1 else Ngram.UNK for token in tokens]\n",
        "    \n",
        "    def create_model(self):\n",
        "        num_tokens = len(self.tokens)\n",
        "        if self.n == 1:\n",
        "            model = { (unigram,): count / num_tokens for unigram, count in self.vocab.items() }\n",
        "        else:\n",
        "            model = self.smooth()\n",
        "        return dict(sorted(model.items(), key=lambda x: x[1], reverse=True))\n",
        "    \n",
        "    def smooth(self):\n",
        "        vocab_len = len(self.vocab)\n",
        "        n_grams = nltk.ngrams(self.tokens, self.n)\n",
        "        n_vocab = nltk.FreqDist(n_grams)\n",
        "        m_grams = nltk.ngrams(self.tokens, self.n - 1)\n",
        "        m_vocab = nltk.FreqDist(m_grams)\n",
        "        \n",
        "        def counted_smoothing(n_gram, n_count):\n",
        "            m_gram = n_gram[:-1]\n",
        "            m_count = m_vocab[m_gram]\n",
        "            return (n_count + self.laplace) / (m_count + self.laplace * vocab_len)\n",
        "        \n",
        "        return { n_gram: counted_smoothing(n_gram, count) for n_gram, count in n_vocab.items() }\n",
        "    \n",
        "    def check_ghafie(self, ghafie1, ghafie2):\n",
        "        margin = 3\n",
        "        ham_ghafie = False\n",
        "        if len(ghafie1) > 1 and len(ghafie2) > 1:\n",
        "            for i in range(-1, -margin-1, -1):\n",
        "                if ghafie1[i] != ghafie2[i]:\n",
        "                    break\n",
        "                else:\n",
        "                    ham_ghafie = True\n",
        "        return ham_ghafie\n",
        "        \n",
        "    \n",
        "    def get_candidates(self, beginning_of_ngram, last_word, ghafie, ghafie_repeat, mesra1_ghafie):\n",
        "        counter = 0\n",
        "        best = None\n",
        "        for ng in self.model.items():\n",
        "            for i in range(self.n - 1):\n",
        "                if ng[0][i] != beginning_of_ngram[i]:\n",
        "                    break\n",
        "            else:\n",
        "                if ng[0][-1] != self.BOM and ng[0][-1] != self.UNK:\n",
        "                    if not last_word:\n",
        "                        return ng[0][-1]\n",
        "                    if counter == 0:\n",
        "                        best = ng[0][-1]\n",
        "                    if ((ghafie and not self.check_ghafie(mesra1_ghafie, ng[0][-1])) or (not ghafie and self.check_ghafie(mesra1_ghafie, ng[0][-1]))) and counter < ghafie_repeat:\n",
        "                        counter += 1\n",
        "                    else:\n",
        "                        if counter < ghafie_repeat:\n",
        "                            return ng[0][-1]\n",
        "        if best:\n",
        "            return best\n",
        "        return self.UNK\n",
        "    \n",
        "    def generate_mesra(self, first_mesra, ghafie):\n",
        "        first_mesra = self.BOM + ' ' + first_mesra + ' ' + self.BOM\n",
        "        first_mesra_tokens = self.preprocess(first_mesra)\n",
        "        next_mesra = []\n",
        "        ghafie_repeat = 5\n",
        "        mesra1_ghafie = first_mesra_tokens[-2]\n",
        "                \n",
        "        if self.n == 1:\n",
        "            vocab_list = [x[0] for x in self.model]\n",
        "            vocab_probs = list(self.model.values())\n",
        "            next_mesra = list(np.random.choice(vocab_list, p=vocab_probs, size=8, replace=False))\n",
        "            \n",
        "            if ghafie:\n",
        "                if not self.check_ghafie(first_mesra_tokens[-2], next_mesra[-1]):\n",
        "                    for i in range(ghafie_repeat):\n",
        "                        next_mesra[-1] = np.random.choice(vocab_list, p=vocab_probs)\n",
        "                        if self.check_ghafie(first_mesra_tokens[-2], next_mesra[-1]):\n",
        "                            break\n",
        "            else:\n",
        "                if self.check_ghafie(first_mesra_tokens[-2], next_mesra[-1]):\n",
        "                    for i in range(ghafie_repeat):\n",
        "                        next_mesra[-1] = np.random.choice(vocab_list, p=vocab_probs)\n",
        "                        if not self.check_ghafie(first_mesra_tokens[-2], next_mesra[-1]):\n",
        "                            break\n",
        "                \n",
        "        \n",
        "        else:\n",
        "            beginning_of_ngram = tuple(first_mesra_tokens[-self.n + 1:])\n",
        "            last_word = False\n",
        "            while True:\n",
        "                next_word = self.get_candidates(beginning_of_ngram, last_word, ghafie, ghafie_repeat, mesra1_ghafie)\n",
        "                \n",
        "                if next_word == self.EOM:\n",
        "                    last_word = True\n",
        "                    next_mesra[-1] = self.get_candidates(temp_beginning_of_ngram, last_word, ghafie, ghafie_repeat, mesra1_ghafie)\n",
        "                    break\n",
        "        \n",
        "                next_mesra.append(next_word)\n",
        "                temp_beginning_of_ngram = beginning_of_ngram\n",
        "                beginning_of_ngram = (*beginning_of_ngram[1:], next_word)\n",
        "                \n",
        "        while self.EOM in next_mesra:\n",
        "            next_mesra.remove(self.EOM)\n",
        "        while self.BOM in next_mesra:\n",
        "            next_mesra.remove(self.BOM)\n",
        "        while self.UNK in next_mesra:\n",
        "            next_mesra.remove(self.UNK)\n",
        "        return(' '.join(next_mesra))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG3s_L-TM73-"
      },
      "outputs": [],
      "source": [
        "gram5 = Ngram(beyt_file, 5)\n",
        "gram4 = Ngram(beyt_file, 4)\n",
        "gram3 = Ngram(beyt_file, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LsN3lAnM74A",
        "outputId": "cf2c32d0-acad-45c7-f780-31d61c272a8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ز دینار وز گوهر نابسود'"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mesra1 = 'به گرد اندر آرد بهنگام کار'\n",
        "gram4.generate_mesra(mesra1, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SVOH37pM74C",
        "outputId": "04b20054-e9d5-45c3-e22d-e475c89dd86f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ز دینار وز گوهر شاهوار'"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gram4.generate_mesra(mesra1, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_0ZCckAM74E",
        "outputId": "b19a8582-b46c-479b-b06f-170b97fc6400"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'سپردار و جوشنوران صد هزار'"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mesra1 = 'سپاه اندر آمد به پیش سوار'\n",
        "gram4.generate_mesra(mesra1, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQGN56EHM74H",
        "outputId": "5febcaca-eaf6-461e-8fb7-f01ac58a3abb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'سپردار و جوشنوران صد هزار'"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gram4.generate_mesra(mesra1, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHyNeOO8M74K",
        "outputId": "41fcbc98-3f2d-423d-ee3d-253ba1caa1ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'همی رفت پویان به کردار مست'"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mesra1 = 'بران تیغ زهر آب داده به دست'\n",
        "gram5.generate_mesra(mesra1, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-a023N7M74N",
        "outputId": "e6370c21-d015-47d2-96fb-32d1e58aba66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'گفت ببخشند گنه می بنوش'"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mesra1 = 'هاتفی از گوشه میخانه دوش'\n",
        "gram5.generate_mesra(mesra1, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9n_MD-6M74O",
        "outputId": "a2e2eafc-330d-4eea-8c48-48254a09cb53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ز هر سو که بد مهتری با گهر'"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mesra1 = 'هزار دشمنم ار می کنند قصد هلاک'\n",
        "gram3.generate_mesra(mesra1, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xBzeup-M74Q",
        "outputId": "21b015b7-a978-499d-ac19-b158e3d4b135"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'بدان تا شود نزد سالار توران سپاه'"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mesra1 = 'سلامی چو بوی خوش آشنایی'\n",
        "gram3.generate_mesra(mesra1, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkRZvszYM74U"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "    <h3> 3. مدل بر پایه LSTM </h3>\n",
        "    ابتدا بررسی می‌کنیم که سیستم قابلیت استفاده از cuda را دارد یا نه.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar1z2v-kM74V",
        "outputId": "b5c8a5fe-7db7-49ec-cd01-308d325107c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Persian_poems_corpus'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Total 159 (delta 0), reused 0 (delta 0), pack-reused 159\u001b[K\n",
            "Receiving objects: 100% (159/159), 45.21 MiB | 19.40 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Checking out files: 100% (148/148), done.\n",
            "cp: target 'Persian_poems_corpus/normalized/moulavi_norm.txt' is not a directory\n",
            "cpu\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "! pip install -q wandb\n",
        "! git clone \"https://github.com/amnghd/Persian_poems_corpus.git\"\n",
        "! mkdir \"corpus\"\n",
        "! cp \"Persian_poems_corpus/normalized/ferdousi_norm.txt\" \"Persian_poems_corpus/normalized/hafez_norm.txt\" \"Persian_poems_corpus/normalized/moulavi_norm.txt\"\n",
        "\"./corpus/\"\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# for accessing the files in google drive from google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iu42AaBM74Y"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "    برای مانیتور کردن پارامترها و تغییرات مدل هنگام train شدن می‌توانیم از wandb استفاده کنیم. هم‌چنین امکان ذخیره‌ی پارامترها برای استفاده‌ی مجدد نیز وجود دارد. \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qnr-r-lSM74a",
        "outputId": "6adc1742-7d1d-4ac2-e96e-81dce509b796",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Currently logged in as: thedrna (nlp400). Use `wandb login --relogin` to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.17"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>F:\\Documents\\NLP\\HW 3\\wandb\\run-20220605_134248-1tw9umfa</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/nlp400/ferdousi-generator/runs/1tw9umfa\" target=\"_blank\">valiant-waterfall-2</a></strong> to <a href=\"https://wandb.ai/nlp400/ferdousi-generator\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/nlp400/ferdousi-generator/runs/1tw9umfa?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x1c07627ed90>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(project=\"ferdousi-generator\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcmGR6KoM74d"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    pass\n",
        "\n",
        "\n",
        "wandb_active = False\n",
        "project_name = 'poem_generator'\n",
        "run_name = 'all_poem_train'\n",
        "checkpoints_dir = '../data/checkpoints/'\n",
        "corpus_dir = '../data/poems/'\n",
        "vocab_path = '../data/vocabulary.txt'\n",
        "\n",
        "if wandb_active:\n",
        "    wandb.init(project=project_name, name=run_name)\n",
        "    config = wandb.config\n",
        "else:\n",
        "    config = Config()\n",
        "config.batch_size = 256\n",
        "config.embedding_size = 512\n",
        "config.lstm_num_layers = 3\n",
        "config.lstm_hidden_size = 512\n",
        "config.sequence_length = 10\n",
        "config.log_interval = 10\n",
        "config.learning_rate = 0.001\n",
        "config.vocab_size = 38590\n",
        "config.lstm_dropout = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JU3e_YbM74e"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "    در کلاس PoemDataset به خواندن و ایندکس کردن دیتا می‌پردازیم. هم‌چنین کلمات یکتای دیتا برای تشکیل vocabulary استخراج می‌گردند. برای هر کلمه‌ی یکتا، ایندکسی در نظر گرفته می‌شود و توسط تابع __getitem__ داده‌ای مناسب ورودی دادن به مدل گرفته می‌شود. از index_to_word و word_to_index در انکد و دیکد کردن استفاده می‌شود.<br>به کمک این کلاس می‌توان از میان داده‌های موجود، ابتدا به کمک تمامی اشعار  مجموعه‌ی واژگان کاملی ساخت و مدل را به کمک آن train کرد، سپس بر حسب هر شاعر آن را fine tune کرد. هم‌چنین برای پیش‌پردازش اشعار، ابتدا و انتهای مصراع‌ها و ابیات به همراه نام شاعر مشخص می‌گردد.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ_aYCW6nNsG",
        "outputId": "41b92b0b-041e-4abf-bbe4-144e74e36730"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([    1,  2444, 38083,  3899,  2667,  1267, 35473, 32103, 29073,     1]), tensor([ 2444, 38083,  3899,  2667,  1267, 35473, 32103, 29073,     1, 36588]))\n",
            "(tensor([ 2444, 38083,  3899,  2667,  1267, 35473, 32103, 29073,     1, 36588]), tensor([38083,  3899,  2667,  1267, 35473, 32103, 29073,     1, 36588, 22622]))\n",
            "(tensor([38083,  3899,  2667,  1267, 35473, 32103, 29073,     1, 36588, 22622]), tensor([ 3899,  2667,  1267, 35473, 32103, 29073,     1, 36588, 22622,   317]))\n",
            "(tensor([ 3899,  2667,  1267, 35473, 32103, 29073,     1, 36588, 22622,   317]), tensor([ 2667,  1267, 35473, 32103, 29073,     1, 36588, 22622,   317, 30370]))\n",
            "(tensor([ 2667,  1267, 35473, 32103, 29073,     1, 36588, 22622,   317, 30370]), tensor([ 1267, 35473, 32103, 29073,     1, 36588, 22622,   317, 30370,  3614]))\n",
            "(tensor([ 1267, 35473, 32103, 29073,     1, 36588, 22622,   317, 30370,  3614]), tensor([35473, 32103, 29073,     1, 36588, 22622,   317, 30370,  3614, 32966]))\n",
            "(tensor([35473, 32103, 29073,     1, 36588, 22622,   317, 30370,  3614, 32966]), tensor([32103, 29073,     1, 36588, 22622,   317, 30370,  3614, 32966,  2170]))\n",
            "(tensor([32103, 29073,     1, 36588, 22622,   317, 30370,  3614, 32966,  2170]), tensor([29073,     1, 36588, 22622,   317, 30370,  3614, 32966,  2170, 26845]))\n",
            "(tensor([29073,     1, 36588, 22622,   317, 30370,  3614, 32966,  2170, 26845]), tensor([    1, 36588, 22622,   317, 30370,  3614, 32966,  2170, 26845, 31439]))\n",
            "(tensor([    1, 36588, 22622,   317, 30370,  3614, 32966,  2170, 26845, 31439]), tensor([36588, 22622,   317, 30370,  3614, 32966,  2170, 26845, 31439,     3]))\n"
          ]
        }
      ],
      "source": [
        "class PoemDataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            device=torch.device('cpu'),\n",
        "            poet='ferdousi',\n",
        "            corpus_dir='./Persian_poems_corpus/normalized',\n",
        "            vocab_path='./vocabulary.txt'\n",
        "    ):\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "        self.corpus_dir = corpus_dir\n",
        "        self.vocab_path = vocab_path\n",
        "\n",
        "        self.words_by_poet = self.load_words(corpus_dir)\n",
        "        self.vocabulary = self.load_vocabulary()\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.vocabulary)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.vocabulary)}\n",
        "        self.poet = poet\n",
        "\n",
        "    def preprocess_lines(self, lines, mask_key):\n",
        "        lines = [line.strip() for line in lines]\n",
        "        lines = filter(lambda line: len(line) > 0, lines)\n",
        "        lines = map(lambda line: line.replace('\\n', ''), lines)\n",
        "        lines = map(lambda line: line.replace('\\t', ''), lines)\n",
        "        lines = map(lambda line: line.replace('\\r', ''), lines)\n",
        "        lines = map(\n",
        "            lambda index_line:\n",
        "            f'[BOM_{mask_key}] ' + index_line[1] + ' [EOS]' if index_line[0] % 2 == 1\n",
        "            else f'[BOM_{mask_key}] ' + index_line[1],\n",
        "            enumerate(lines)\n",
        "        )\n",
        "        words = itertools.chain.from_iterable(map(lambda line: line.split(' '), lines))\n",
        "        words = filter(lambda word: len(word) > 0, words)\n",
        "        words = list(words)\n",
        "        return words\n",
        "\n",
        "    def load_words(self, corpus_dir):\n",
        "        words_by_poet = {}\n",
        "        for filename in os.listdir(corpus_dir):\n",
        "            with open(os.path.join(corpus_dir, filename)) as f:\n",
        "                poet_name = filename.split('_')[0]\n",
        "                lines = f.readlines()\n",
        "                words_by_poet[poet_name] = self.preprocess_lines(lines, poet_name)\n",
        "        return words_by_poet\n",
        "\n",
        "    def load_vocabulary(self):\n",
        "        with open(self.vocab_path) as f:\n",
        "            vocabulary = f.readlines()\n",
        "        vocabulary = [word.strip() for word in vocabulary]\n",
        "        return vocabulary\n",
        "\n",
        "    @property\n",
        "    def all_poets(self):\n",
        "        return self.words_by_poet.keys()\n",
        "\n",
        "    @property\n",
        "    def poet(self):\n",
        "        return self._poet\n",
        "\n",
        "    @poet.setter\n",
        "    def poet(self, poet):\n",
        "        self._poet = poet\n",
        "        if poet == 'all':\n",
        "            self.words = list(itertools.chain.from_iterable(self.words_by_poet.values()))\n",
        "        else:\n",
        "            self.words = self.words_by_poet[poet]\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.config.sequence_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        tensors = (\n",
        "            torch.tensor(self.words_indexes[index:index + self.config.sequence_length]).to(self.device),\n",
        "            torch.tensor(self.words_indexes[index + 1:index + self.config.sequence_length + 1]).to(self.device),\n",
        "        )\n",
        "        return tensors\n",
        "\n",
        "\n",
        "dataset = PoemDataset(config, device=torch.device('cpu'), poet='all', corpus_dir=corpus_dir, vocab_path=vocab_path)\n",
        "\n",
        "for i in range(10):\n",
        "    print(dataset[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A532FGpAM74i"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "    در کلاس Model مدل این بخش ساخته می‌شود که شامل سه بخش embedding، lstm و یک تابع خطی برای تبدیل خروجی lstm به vocab است. لایه‌های هر بخش توسط pytorch ساخته می‌شوند و مقادیر ابتدایی برابر با صفر است.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITpvYYtFM74j"
      },
      "outputs": [],
      "source": [
        "from torch import nn, optim\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, config, device=torch.device('cpu')):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = config.embedding_size\n",
        "        self.lstm_hidden_size = config.lstm_hidden_size\n",
        "        self.lstm_dropout = 0.2\n",
        "        self.embedding_dim = config.embedding_size\n",
        "        self.num_layers = config.lstm_num_layers\n",
        "        self.device = device\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=self.vocab_size,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_hidden_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=self.lstm_dropout,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, self.vocab_size)\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self.device),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self.device))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zcf2fxYM74l"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "    نهایتاً یک تابع کلاسیک برای train داده‌ها استفاده می‌شود. در این تابع از optimizer جنریک Adam استفاده شده و loss به روش cross entropy محاسبه شده است. \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqnfJbptjllX"
      },
      "outputs": [],
      "source": [
        "# run this cell to generate new vocabulary\n",
        "\n",
        "all_words = list(itertools.chain.from_iterable(dataset.words_by_poet.values()))\n",
        "word_counts = Counter(all_words)\n",
        "vocab = sorted(list(word_counts))\n",
        "with open(vocab_path, 'w') as f:\n",
        "    for word in vocab:\n",
        "        f.write(word + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uds74KajM74m"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train(dataset, model, config, checkpoint_path='../data/checkpoints', max_epochs=10, ):\n",
        "    if wandb_active:\n",
        "        wandb.watch(model)\n",
        "    model.train()\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=config.batch_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "    print({'batch_count': len(dataloader), 'epoch_count': max_epochs})\n",
        "    for epoch in range(max_epochs):\n",
        "        state_h, state_c = model.init_state(config.sequence_length)\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print({'epoch': epoch, 'batch': batch, 'loss': loss.item()})\n",
        "            if wandb_active and batch % config.log_interval == 0:\n",
        "                wandb.log({\"loss\": loss})\n",
        "        try:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "            }, os.path.join(checkpoint_path, f'{run_name}_checkpoint_{epoch}_{time.time()}.pt'))\n",
        "        except Exception as e:\n",
        "            print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3V9rRJiM74n"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "    از تابع predict برای حدس ادامه‌ی بیت استفاده می‌گردد.<br> دیکودر مدل در این بخش قرار دارد، بطوریکه وزن‌های لازم برای انتخاب کلمه‌ی بعد از اعمال softmax روی hidden state آخرین مرحله حاصل می‌گردند. \n",
        "    همچنین برای پیدا کردن مصراعی که قافیه داشتن یا نداشتن آن با فرض اولیه ی ما همخونی دارد به این صورت عمل می‌کنیم که به تعداد کمتر از \n",
        "    maximum try\n",
        "    هر بار با ساخت یک مصراع و بررسی قافیه ی آن نسبت به فرض اولیه در صورتی که تناقض وجود داشت دوباره کل مصراع را تولید می‌کنیم. در غیر اینصورت مصراع را به عنوان خروجی می‌دهیم. \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQX_0yH9M74o"
      },
      "outputs": [],
      "source": [
        "def does_ryhme(first_mesra, sec_mesra):\n",
        "    first_ghafie = [x for x in filter(lambda x: len(x)>0, first_mesra.split(\" \"))][-1]\n",
        "    second_ghafie = [x for x in filter(lambda x: len(x)>0, sec_mesra.split(\" \"))][-1]\n",
        "    min_len = min(len(first_ghafie), len(second_ghafie))\n",
        "\n",
        "    for level in range(-1, -min_len-1, -1):\n",
        "        if not first_ghafie[level:] == second_ghafie[level:]:\n",
        "            break\n",
        "        if level < -1:\n",
        "            break\n",
        "    return level!=-1\n",
        "\n",
        "def predict(dataset, model, text, max_predict_length=12, have_ryhme=True):\n",
        "    max_try = 10\n",
        "    if have_ryhme:\n",
        "        mesra_diff = \"[BOM_ferdousi]\"\n",
        "    else:\n",
        "        mesra_diff = \"[BOM_hafez]\"\n",
        "    model.eval()\n",
        "\n",
        "    words = text.split(' ')\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "    mesras = text.split(\"[BOM]\")\n",
        "    first_mesra = list(sorted(mesras, key= lambda x: len(x), reverse=True))[0]\n",
        "\n",
        "    stop = False\n",
        "    tries = 0\n",
        "    while not stop and tries < max_try:\n",
        "        tries += 1\n",
        "        i = 0\n",
        "        words = text.split(' ')\n",
        "        while words[-1] != '[EOS]' and i < max_predict_length:\n",
        "            x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]]).to(device)\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "            last_word_logits = y_pred[0][-1]\n",
        "            p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "            word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "            words.append(dataset.index_to_word[word_index])\n",
        "            if words[-1] == '[EOS]':\n",
        "                ryhmes = does_ryhme(first_mesra, \" \".join(words[:-1]))\n",
        "                if have_ryhme == ryhmes:\n",
        "                    print(\"ryhmes match!!\")\n",
        "                    stop = True\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"ryhmes font match :( starting again\")\n",
        "            i += 1\n",
        "    return words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "برای ترین مدل از ابتدا خطوط زیر باید اجرا شوند. در غیر این صورت از مدل آماده موجود در این <a href=\"https://drive.google.com/drive/folders/10dOPSBW6oOljcQ4sZSAqEqV7W7IcNd8e?usp=sharing\">لینک</a> استفاده کنید. \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjGn0U9HonSR"
      },
      "outputs": [],
      "source": [
        "model = Model(config, device)\n",
        "dataset = PoemDataset(config, device=device, poet='all', corpus_dir=corpus_dir, vocab_path=vocab_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B6wwEsXhM74r"
      },
      "outputs": [],
      "source": [
        "# train on generic dataset\n",
        "train(dataset, model, config, checkpoint_path=checkpoints_dir, max_epochs=10)\n",
        "if wandb_active:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "589e730800904ac9a88600d469450b33",
            "32809f097ec240eda71a685f0b70d0e2",
            "9dbd2eae998f42a09173c9243bead780",
            "ccda4c0702bb41dda2f279ef1c439b14",
            "a4f4c05297644cdea716b0bcaae4412a",
            "6e55cc1325af43a8aee308cd9bf5fe75",
            "1f0ca84dc1394e148571916b174b9c2e",
            "c97adf813b0e4dcab2440446e126e863"
          ]
        },
        "id": "VMy3pz3Ut5Vs",
        "outputId": "57faa540-6e95-4e6e-d7ff-259f7b4c595e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:2i2ajvce) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "589e730800904ac9a88600d469450b33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">all_poem_train</strong>: <a href=\"https://wandb.ai/soroushtabesh/poem_generator/runs/2i2ajvce\" target=\"_blank\">https://wandb.ai/soroushtabesh/poem_generator/runs/2i2ajvce</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220607_104035-2i2ajvce/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:2i2ajvce). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.17"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220607_104444-1ee3xof2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/soroushtabesh/poem_generator/runs/1ee3xof2\" target=\"_blank\">ferdousi_fine_tune</a></strong> to <a href=\"https://wandb.ai/soroushtabesh/poem_generator\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_count': 2803, 'epoch_count': 3}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:762: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:926.)\n",
            "  self.dropout, self.training, self.bidirectional, self.batch_first)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'batch': 0, 'loss': 6.889185905456543}\n",
            "{'epoch': 0, 'batch': 1, 'loss': 6.5529656410217285}\n",
            "{'epoch': 0, 'batch': 2, 'loss': 6.2994842529296875}\n",
            "{'epoch': 0, 'batch': 3, 'loss': 5.536078929901123}\n",
            "{'epoch': 0, 'batch': 4, 'loss': 5.52945613861084}\n",
            "{'epoch': 0, 'batch': 5, 'loss': 5.632105827331543}\n",
            "{'epoch': 0, 'batch': 6, 'loss': 5.0263776779174805}\n",
            "{'epoch': 0, 'batch': 7, 'loss': 4.857870578765869}\n",
            "{'epoch': 0, 'batch': 8, 'loss': 4.451596260070801}\n",
            "{'epoch': 0, 'batch': 9, 'loss': 4.313296794891357}\n",
            "{'epoch': 0, 'batch': 10, 'loss': 4.216029167175293}\n",
            "{'epoch': 0, 'batch': 11, 'loss': 4.048924922943115}\n",
            "{'epoch': 0, 'batch': 12, 'loss': 4.257582664489746}\n",
            "{'epoch': 0, 'batch': 13, 'loss': 4.120383262634277}\n",
            "{'epoch': 0, 'batch': 14, 'loss': 4.034390449523926}\n",
            "{'epoch': 0, 'batch': 15, 'loss': 4.085867404937744}\n",
            "{'epoch': 0, 'batch': 16, 'loss': 4.050901889801025}\n",
            "{'epoch': 0, 'batch': 17, 'loss': 3.917092800140381}\n",
            "{'epoch': 0, 'batch': 18, 'loss': 4.214128017425537}\n",
            "{'epoch': 0, 'batch': 19, 'loss': 3.876066207885742}\n",
            "{'epoch': 0, 'batch': 20, 'loss': 3.6457927227020264}\n",
            "{'epoch': 0, 'batch': 21, 'loss': 3.9207305908203125}\n",
            "{'epoch': 0, 'batch': 22, 'loss': 3.8752071857452393}\n",
            "{'epoch': 0, 'batch': 23, 'loss': 3.7653021812438965}\n",
            "{'epoch': 0, 'batch': 24, 'loss': 3.778409957885742}\n",
            "{'epoch': 0, 'batch': 25, 'loss': 3.246899366378784}\n",
            "{'epoch': 0, 'batch': 26, 'loss': 3.724834442138672}\n",
            "{'epoch': 0, 'batch': 27, 'loss': 3.8192152976989746}\n",
            "{'epoch': 0, 'batch': 28, 'loss': 3.2930614948272705}\n",
            "{'epoch': 0, 'batch': 29, 'loss': 3.7543513774871826}\n",
            "{'epoch': 0, 'batch': 30, 'loss': 3.413148880004883}\n",
            "{'epoch': 0, 'batch': 31, 'loss': 3.123340606689453}\n",
            "{'epoch': 0, 'batch': 32, 'loss': 3.5129857063293457}\n",
            "{'epoch': 0, 'batch': 33, 'loss': 3.2383205890655518}\n",
            "{'epoch': 0, 'batch': 34, 'loss': 3.7442779541015625}\n",
            "{'epoch': 0, 'batch': 35, 'loss': 3.301952362060547}\n",
            "{'epoch': 0, 'batch': 36, 'loss': 3.443358898162842}\n",
            "{'epoch': 0, 'batch': 37, 'loss': 3.0953354835510254}\n",
            "{'epoch': 0, 'batch': 38, 'loss': 3.244001865386963}\n",
            "{'epoch': 0, 'batch': 39, 'loss': 3.573533535003662}\n",
            "{'epoch': 0, 'batch': 40, 'loss': 3.443572998046875}\n",
            "{'epoch': 0, 'batch': 41, 'loss': 3.194288730621338}\n",
            "{'epoch': 0, 'batch': 42, 'loss': 3.2890541553497314}\n",
            "{'epoch': 0, 'batch': 43, 'loss': 3.358546018600464}\n",
            "{'epoch': 0, 'batch': 44, 'loss': 3.4008803367614746}\n",
            "{'epoch': 0, 'batch': 45, 'loss': 3.3707070350646973}\n",
            "{'epoch': 0, 'batch': 46, 'loss': 3.4560294151306152}\n",
            "{'epoch': 0, 'batch': 47, 'loss': 3.35546875}\n",
            "{'epoch': 0, 'batch': 48, 'loss': 3.290417194366455}\n",
            "{'epoch': 0, 'batch': 49, 'loss': 3.3851523399353027}\n",
            "{'epoch': 0, 'batch': 50, 'loss': 3.684669017791748}\n",
            "{'epoch': 0, 'batch': 51, 'loss': 3.5164198875427246}\n",
            "{'epoch': 0, 'batch': 52, 'loss': 3.555293560028076}\n",
            "{'epoch': 0, 'batch': 53, 'loss': 3.1180052757263184}\n",
            "{'epoch': 0, 'batch': 54, 'loss': 3.299900770187378}\n",
            "{'epoch': 0, 'batch': 55, 'loss': 3.4556736946105957}\n",
            "{'epoch': 0, 'batch': 56, 'loss': 3.2904975414276123}\n",
            "{'epoch': 0, 'batch': 57, 'loss': 3.151280641555786}\n",
            "{'epoch': 0, 'batch': 58, 'loss': 3.2850260734558105}\n",
            "{'epoch': 0, 'batch': 59, 'loss': 3.3109333515167236}\n",
            "{'epoch': 0, 'batch': 60, 'loss': 3.271679639816284}\n",
            "{'epoch': 0, 'batch': 61, 'loss': 3.2142906188964844}\n",
            "{'epoch': 0, 'batch': 62, 'loss': 3.259131669998169}\n",
            "{'epoch': 0, 'batch': 63, 'loss': 3.406895875930786}\n",
            "{'epoch': 0, 'batch': 64, 'loss': 3.391035556793213}\n",
            "{'epoch': 0, 'batch': 65, 'loss': 3.190242052078247}\n",
            "{'epoch': 0, 'batch': 66, 'loss': 3.284435272216797}\n",
            "{'epoch': 0, 'batch': 67, 'loss': 3.360816478729248}\n",
            "{'epoch': 0, 'batch': 68, 'loss': 3.5703468322753906}\n",
            "{'epoch': 0, 'batch': 69, 'loss': 3.3590328693389893}\n",
            "{'epoch': 0, 'batch': 70, 'loss': 3.3858304023742676}\n",
            "{'epoch': 0, 'batch': 71, 'loss': 3.177328586578369}\n",
            "{'epoch': 0, 'batch': 72, 'loss': 3.524216890335083}\n",
            "{'epoch': 0, 'batch': 73, 'loss': 2.9789984226226807}\n",
            "{'epoch': 0, 'batch': 74, 'loss': 3.455900192260742}\n",
            "{'epoch': 0, 'batch': 75, 'loss': 3.1909525394439697}\n",
            "{'epoch': 0, 'batch': 76, 'loss': 3.295056104660034}\n",
            "{'epoch': 0, 'batch': 77, 'loss': 3.381326198577881}\n",
            "{'epoch': 0, 'batch': 78, 'loss': 3.3699936866760254}\n",
            "{'epoch': 0, 'batch': 79, 'loss': 3.3009696006774902}\n",
            "{'epoch': 0, 'batch': 80, 'loss': 3.2378811836242676}\n",
            "{'epoch': 0, 'batch': 81, 'loss': 3.3056721687316895}\n",
            "{'epoch': 0, 'batch': 82, 'loss': 3.458885908126831}\n",
            "{'epoch': 0, 'batch': 83, 'loss': 3.391892910003662}\n",
            "{'epoch': 0, 'batch': 84, 'loss': 3.459254741668701}\n",
            "{'epoch': 0, 'batch': 85, 'loss': 3.3171114921569824}\n",
            "{'epoch': 0, 'batch': 86, 'loss': 3.1901917457580566}\n",
            "{'epoch': 0, 'batch': 87, 'loss': 3.352649211883545}\n",
            "{'epoch': 0, 'batch': 88, 'loss': 3.031127452850342}\n",
            "{'epoch': 0, 'batch': 89, 'loss': 3.346855640411377}\n",
            "{'epoch': 0, 'batch': 90, 'loss': 2.7688088417053223}\n",
            "{'epoch': 0, 'batch': 91, 'loss': 3.2667076587677}\n",
            "{'epoch': 0, 'batch': 92, 'loss': 3.069669723510742}\n",
            "{'epoch': 0, 'batch': 93, 'loss': 3.267531156539917}\n",
            "{'epoch': 0, 'batch': 94, 'loss': 3.0685038566589355}\n",
            "{'epoch': 0, 'batch': 95, 'loss': 3.283020496368408}\n",
            "{'epoch': 0, 'batch': 96, 'loss': 3.1955103874206543}\n",
            "{'epoch': 0, 'batch': 97, 'loss': 3.217442750930786}\n",
            "{'epoch': 0, 'batch': 98, 'loss': 3.1519503593444824}\n",
            "{'epoch': 0, 'batch': 99, 'loss': 3.083991527557373}\n",
            "{'epoch': 0, 'batch': 100, 'loss': 3.1202499866485596}\n",
            "{'epoch': 0, 'batch': 101, 'loss': 3.1532046794891357}\n",
            "{'epoch': 0, 'batch': 102, 'loss': 3.2184531688690186}\n",
            "{'epoch': 0, 'batch': 103, 'loss': 3.394920825958252}\n",
            "{'epoch': 0, 'batch': 104, 'loss': 3.2239933013916016}\n",
            "{'epoch': 0, 'batch': 105, 'loss': 3.3369719982147217}\n",
            "{'epoch': 0, 'batch': 106, 'loss': 3.3599090576171875}\n",
            "{'epoch': 0, 'batch': 107, 'loss': 3.3425698280334473}\n",
            "{'epoch': 0, 'batch': 108, 'loss': 2.8782103061676025}\n",
            "{'epoch': 0, 'batch': 109, 'loss': 2.837562322616577}\n",
            "{'epoch': 0, 'batch': 110, 'loss': 3.2592456340789795}\n",
            "{'epoch': 0, 'batch': 111, 'loss': 3.23553729057312}\n",
            "{'epoch': 0, 'batch': 112, 'loss': 3.2901320457458496}\n",
            "{'epoch': 0, 'batch': 113, 'loss': 3.217599868774414}\n",
            "{'epoch': 0, 'batch': 114, 'loss': 3.5282580852508545}\n",
            "{'epoch': 0, 'batch': 115, 'loss': 3.3198089599609375}\n",
            "{'epoch': 0, 'batch': 116, 'loss': 3.377000331878662}\n",
            "{'epoch': 0, 'batch': 117, 'loss': 3.3482983112335205}\n",
            "{'epoch': 0, 'batch': 118, 'loss': 3.516491651535034}\n",
            "{'epoch': 0, 'batch': 119, 'loss': 3.0012054443359375}\n",
            "{'epoch': 0, 'batch': 120, 'loss': 3.177407741546631}\n",
            "{'epoch': 0, 'batch': 121, 'loss': 3.3678016662597656}\n",
            "{'epoch': 0, 'batch': 122, 'loss': 2.9383695125579834}\n",
            "{'epoch': 0, 'batch': 123, 'loss': 2.9367892742156982}\n",
            "{'epoch': 0, 'batch': 124, 'loss': 3.3011162281036377}\n",
            "{'epoch': 0, 'batch': 125, 'loss': 3.0149877071380615}\n",
            "{'epoch': 0, 'batch': 126, 'loss': 2.9866678714752197}\n",
            "{'epoch': 0, 'batch': 127, 'loss': 3.0075888633728027}\n",
            "{'epoch': 0, 'batch': 128, 'loss': 3.0500435829162598}\n",
            "{'epoch': 0, 'batch': 129, 'loss': 3.199315071105957}\n",
            "{'epoch': 0, 'batch': 130, 'loss': 3.2678539752960205}\n",
            "{'epoch': 0, 'batch': 131, 'loss': 3.266353130340576}\n",
            "{'epoch': 0, 'batch': 132, 'loss': 3.387564182281494}\n",
            "{'epoch': 0, 'batch': 133, 'loss': 3.268735885620117}\n",
            "{'epoch': 0, 'batch': 134, 'loss': 3.6392903327941895}\n",
            "{'epoch': 0, 'batch': 135, 'loss': 3.6825003623962402}\n",
            "{'epoch': 0, 'batch': 136, 'loss': 3.4439597129821777}\n",
            "{'epoch': 0, 'batch': 137, 'loss': 3.0770516395568848}\n",
            "{'epoch': 0, 'batch': 138, 'loss': 3.489534378051758}\n",
            "{'epoch': 0, 'batch': 139, 'loss': 3.5988030433654785}\n",
            "{'epoch': 0, 'batch': 140, 'loss': 2.962334394454956}\n",
            "{'epoch': 0, 'batch': 141, 'loss': 3.472693681716919}\n",
            "{'epoch': 0, 'batch': 142, 'loss': 3.2796318531036377}\n",
            "{'epoch': 0, 'batch': 143, 'loss': 2.8629889488220215}\n",
            "{'epoch': 0, 'batch': 144, 'loss': 3.524534225463867}\n",
            "{'epoch': 0, 'batch': 145, 'loss': 3.5802719593048096}\n",
            "{'epoch': 0, 'batch': 146, 'loss': 3.186619997024536}\n",
            "{'epoch': 0, 'batch': 147, 'loss': 3.4567267894744873}\n",
            "{'epoch': 0, 'batch': 148, 'loss': 3.347973585128784}\n",
            "{'epoch': 0, 'batch': 149, 'loss': 3.292001247406006}\n",
            "{'epoch': 0, 'batch': 150, 'loss': 3.3688769340515137}\n",
            "{'epoch': 0, 'batch': 151, 'loss': 3.054861545562744}\n",
            "{'epoch': 0, 'batch': 152, 'loss': 3.4323253631591797}\n",
            "{'epoch': 0, 'batch': 153, 'loss': 3.3873660564422607}\n",
            "{'epoch': 0, 'batch': 154, 'loss': 3.296398162841797}\n",
            "{'epoch': 0, 'batch': 155, 'loss': 3.2148616313934326}\n",
            "{'epoch': 0, 'batch': 156, 'loss': 3.3185226917266846}\n",
            "{'epoch': 0, 'batch': 157, 'loss': 3.2827773094177246}\n",
            "{'epoch': 0, 'batch': 158, 'loss': 3.2264652252197266}\n",
            "{'epoch': 0, 'batch': 159, 'loss': 3.231908082962036}\n",
            "{'epoch': 0, 'batch': 160, 'loss': 2.8962647914886475}\n",
            "{'epoch': 0, 'batch': 161, 'loss': 2.879538059234619}\n",
            "{'epoch': 0, 'batch': 162, 'loss': 3.295886278152466}\n",
            "{'epoch': 0, 'batch': 163, 'loss': 3.2546916007995605}\n",
            "{'epoch': 0, 'batch': 164, 'loss': 2.8253302574157715}\n",
            "{'epoch': 0, 'batch': 165, 'loss': 3.220024585723877}\n",
            "{'epoch': 0, 'batch': 166, 'loss': 3.1297686100006104}\n",
            "{'epoch': 0, 'batch': 167, 'loss': 3.1522345542907715}\n",
            "{'epoch': 0, 'batch': 168, 'loss': 3.449277877807617}\n",
            "{'epoch': 0, 'batch': 169, 'loss': 3.332336902618408}\n",
            "{'epoch': 0, 'batch': 170, 'loss': 3.3071906566619873}\n",
            "{'epoch': 0, 'batch': 171, 'loss': 3.1885013580322266}\n",
            "{'epoch': 0, 'batch': 172, 'loss': 3.334095001220703}\n",
            "{'epoch': 0, 'batch': 173, 'loss': 3.326747179031372}\n",
            "{'epoch': 0, 'batch': 174, 'loss': 3.1820006370544434}\n",
            "{'epoch': 0, 'batch': 175, 'loss': 3.339010238647461}\n",
            "{'epoch': 0, 'batch': 176, 'loss': 3.1198315620422363}\n",
            "{'epoch': 0, 'batch': 177, 'loss': 3.2314600944519043}\n",
            "{'epoch': 0, 'batch': 178, 'loss': 3.228388547897339}\n",
            "{'epoch': 0, 'batch': 179, 'loss': 3.046619176864624}\n",
            "{'epoch': 0, 'batch': 180, 'loss': 3.0999596118927}\n",
            "{'epoch': 0, 'batch': 181, 'loss': 3.3017737865448}\n",
            "{'epoch': 0, 'batch': 182, 'loss': 3.6846117973327637}\n",
            "{'epoch': 0, 'batch': 183, 'loss': 3.6990628242492676}\n",
            "{'epoch': 0, 'batch': 184, 'loss': 3.4502060413360596}\n",
            "{'epoch': 0, 'batch': 185, 'loss': 2.9470467567443848}\n",
            "{'epoch': 0, 'batch': 186, 'loss': 3.222382068634033}\n",
            "{'epoch': 0, 'batch': 187, 'loss': 2.827636957168579}\n",
            "{'epoch': 0, 'batch': 188, 'loss': 2.9897258281707764}\n",
            "{'epoch': 0, 'batch': 189, 'loss': 2.8684542179107666}\n",
            "{'epoch': 0, 'batch': 190, 'loss': 2.952078104019165}\n",
            "{'epoch': 0, 'batch': 191, 'loss': 2.780451774597168}\n",
            "{'epoch': 0, 'batch': 192, 'loss': 3.0681495666503906}\n",
            "{'epoch': 0, 'batch': 193, 'loss': 3.1311285495758057}\n",
            "{'epoch': 0, 'batch': 194, 'loss': 3.1379284858703613}\n",
            "{'epoch': 0, 'batch': 195, 'loss': 3.2941582202911377}\n",
            "{'epoch': 0, 'batch': 196, 'loss': 3.285250425338745}\n",
            "{'epoch': 0, 'batch': 197, 'loss': 3.076094150543213}\n",
            "{'epoch': 0, 'batch': 198, 'loss': 3.1651577949523926}\n",
            "{'epoch': 0, 'batch': 199, 'loss': 2.7001569271087646}\n",
            "{'epoch': 0, 'batch': 200, 'loss': 3.2977347373962402}\n",
            "{'epoch': 0, 'batch': 201, 'loss': 3.3316636085510254}\n",
            "{'epoch': 0, 'batch': 202, 'loss': 3.143864870071411}\n",
            "{'epoch': 0, 'batch': 203, 'loss': 3.3290939331054688}\n",
            "{'epoch': 0, 'batch': 204, 'loss': 3.221315860748291}\n",
            "{'epoch': 0, 'batch': 205, 'loss': 3.3686015605926514}\n",
            "{'epoch': 0, 'batch': 206, 'loss': 2.98690128326416}\n",
            "{'epoch': 0, 'batch': 207, 'loss': 3.268749237060547}\n",
            "{'epoch': 0, 'batch': 208, 'loss': 3.1395626068115234}\n",
            "{'epoch': 0, 'batch': 209, 'loss': 3.3653130531311035}\n",
            "{'epoch': 0, 'batch': 210, 'loss': 3.333287000656128}\n",
            "{'epoch': 0, 'batch': 211, 'loss': 2.970341205596924}\n",
            "{'epoch': 0, 'batch': 212, 'loss': 3.1489386558532715}\n",
            "{'epoch': 0, 'batch': 213, 'loss': 3.470660448074341}\n",
            "{'epoch': 0, 'batch': 214, 'loss': 3.2942962646484375}\n",
            "{'epoch': 0, 'batch': 215, 'loss': 3.0065994262695312}\n",
            "{'epoch': 0, 'batch': 216, 'loss': 3.182218074798584}\n",
            "{'epoch': 0, 'batch': 217, 'loss': 3.0456929206848145}\n",
            "{'epoch': 0, 'batch': 218, 'loss': 3.514909029006958}\n",
            "{'epoch': 0, 'batch': 219, 'loss': 2.9329123497009277}\n",
            "{'epoch': 0, 'batch': 220, 'loss': 3.152191162109375}\n",
            "{'epoch': 0, 'batch': 221, 'loss': 3.0631349086761475}\n",
            "{'epoch': 0, 'batch': 222, 'loss': 3.230872631072998}\n",
            "{'epoch': 0, 'batch': 223, 'loss': 3.011685609817505}\n",
            "{'epoch': 0, 'batch': 224, 'loss': 2.8679659366607666}\n",
            "{'epoch': 0, 'batch': 225, 'loss': 3.336139678955078}\n",
            "{'epoch': 0, 'batch': 226, 'loss': 2.9612207412719727}\n",
            "{'epoch': 0, 'batch': 227, 'loss': 2.9669594764709473}\n",
            "{'epoch': 0, 'batch': 228, 'loss': 2.904548406600952}\n",
            "{'epoch': 0, 'batch': 229, 'loss': 3.376039505004883}\n",
            "{'epoch': 0, 'batch': 230, 'loss': 3.195363998413086}\n",
            "{'epoch': 0, 'batch': 231, 'loss': 3.2631583213806152}\n",
            "{'epoch': 0, 'batch': 232, 'loss': 3.0731453895568848}\n",
            "{'epoch': 0, 'batch': 233, 'loss': 3.0089988708496094}\n",
            "{'epoch': 0, 'batch': 234, 'loss': 3.1219558715820312}\n",
            "{'epoch': 0, 'batch': 235, 'loss': 2.966701030731201}\n",
            "{'epoch': 0, 'batch': 236, 'loss': 3.44572114944458}\n",
            "{'epoch': 0, 'batch': 237, 'loss': 3.193404197692871}\n",
            "{'epoch': 0, 'batch': 238, 'loss': 3.234271287918091}\n",
            "{'epoch': 0, 'batch': 239, 'loss': 3.0543627738952637}\n",
            "{'epoch': 0, 'batch': 240, 'loss': 3.0764575004577637}\n",
            "{'epoch': 0, 'batch': 241, 'loss': 3.326997756958008}\n",
            "{'epoch': 0, 'batch': 242, 'loss': 3.4568870067596436}\n",
            "{'epoch': 0, 'batch': 243, 'loss': 3.051056146621704}\n",
            "{'epoch': 0, 'batch': 244, 'loss': 3.2726187705993652}\n",
            "{'epoch': 0, 'batch': 245, 'loss': 3.0953283309936523}\n",
            "{'epoch': 0, 'batch': 246, 'loss': 3.3847389221191406}\n",
            "{'epoch': 0, 'batch': 247, 'loss': 3.1917855739593506}\n",
            "{'epoch': 0, 'batch': 248, 'loss': 3.297151565551758}\n",
            "{'epoch': 0, 'batch': 249, 'loss': 3.0887224674224854}\n",
            "{'epoch': 0, 'batch': 250, 'loss': 2.942284107208252}\n",
            "{'epoch': 0, 'batch': 251, 'loss': 3.15079927444458}\n",
            "{'epoch': 0, 'batch': 252, 'loss': 3.1141891479492188}\n",
            "{'epoch': 0, 'batch': 253, 'loss': 3.0780882835388184}\n",
            "{'epoch': 0, 'batch': 254, 'loss': 3.1328959465026855}\n",
            "{'epoch': 0, 'batch': 255, 'loss': 3.454798936843872}\n",
            "{'epoch': 0, 'batch': 256, 'loss': 3.326524257659912}\n",
            "{'epoch': 0, 'batch': 257, 'loss': 3.2698307037353516}\n",
            "{'epoch': 0, 'batch': 258, 'loss': 3.088829517364502}\n",
            "{'epoch': 0, 'batch': 259, 'loss': 3.0946238040924072}\n",
            "{'epoch': 0, 'batch': 260, 'loss': 3.192253828048706}\n",
            "{'epoch': 0, 'batch': 261, 'loss': 3.3977138996124268}\n",
            "{'epoch': 0, 'batch': 262, 'loss': 3.2024872303009033}\n",
            "{'epoch': 0, 'batch': 263, 'loss': 3.200270891189575}\n",
            "{'epoch': 0, 'batch': 264, 'loss': 3.224393129348755}\n",
            "{'epoch': 0, 'batch': 265, 'loss': 3.09794282913208}\n",
            "{'epoch': 0, 'batch': 266, 'loss': 3.067087411880493}\n",
            "{'epoch': 0, 'batch': 267, 'loss': 3.058500289916992}\n",
            "{'epoch': 0, 'batch': 268, 'loss': 3.352694034576416}\n",
            "{'epoch': 0, 'batch': 269, 'loss': 3.0797359943389893}\n",
            "{'epoch': 0, 'batch': 270, 'loss': 2.9727039337158203}\n",
            "{'epoch': 0, 'batch': 271, 'loss': 3.308130979537964}\n",
            "{'epoch': 0, 'batch': 272, 'loss': 3.1080820560455322}\n",
            "{'epoch': 0, 'batch': 273, 'loss': 3.20784330368042}\n",
            "{'epoch': 0, 'batch': 274, 'loss': 3.0678248405456543}\n",
            "{'epoch': 0, 'batch': 275, 'loss': 3.4942996501922607}\n",
            "{'epoch': 0, 'batch': 276, 'loss': 3.2836074829101562}\n",
            "{'epoch': 0, 'batch': 277, 'loss': 3.5872771739959717}\n",
            "{'epoch': 0, 'batch': 278, 'loss': 3.4709324836730957}\n",
            "{'epoch': 0, 'batch': 279, 'loss': 3.116812229156494}\n",
            "{'epoch': 0, 'batch': 280, 'loss': 3.5438685417175293}\n",
            "{'epoch': 0, 'batch': 281, 'loss': 3.139540672302246}\n",
            "{'epoch': 0, 'batch': 282, 'loss': 3.1801586151123047}\n",
            "{'epoch': 0, 'batch': 283, 'loss': 3.162944793701172}\n",
            "{'epoch': 0, 'batch': 284, 'loss': 3.396634340286255}\n",
            "{'epoch': 0, 'batch': 285, 'loss': 3.1169238090515137}\n",
            "{'epoch': 0, 'batch': 286, 'loss': 3.2790400981903076}\n",
            "{'epoch': 0, 'batch': 287, 'loss': 3.217212677001953}\n",
            "{'epoch': 0, 'batch': 288, 'loss': 3.102128505706787}\n",
            "{'epoch': 0, 'batch': 289, 'loss': 3.231372356414795}\n",
            "{'epoch': 0, 'batch': 290, 'loss': 3.0967230796813965}\n",
            "{'epoch': 0, 'batch': 291, 'loss': 2.8898863792419434}\n",
            "{'epoch': 0, 'batch': 292, 'loss': 3.1149959564208984}\n",
            "{'epoch': 0, 'batch': 293, 'loss': 3.2381114959716797}\n",
            "{'epoch': 0, 'batch': 294, 'loss': 3.1642675399780273}\n",
            "{'epoch': 0, 'batch': 295, 'loss': 3.1892447471618652}\n",
            "{'epoch': 0, 'batch': 296, 'loss': 3.021289825439453}\n",
            "{'epoch': 0, 'batch': 297, 'loss': 2.979896068572998}\n",
            "{'epoch': 0, 'batch': 298, 'loss': 3.227476119995117}\n",
            "{'epoch': 0, 'batch': 299, 'loss': 3.0951321125030518}\n",
            "{'epoch': 0, 'batch': 300, 'loss': 2.989278554916382}\n",
            "{'epoch': 0, 'batch': 301, 'loss': 2.934069871902466}\n",
            "{'epoch': 0, 'batch': 302, 'loss': 3.174088478088379}\n",
            "{'epoch': 0, 'batch': 303, 'loss': 3.0075697898864746}\n",
            "{'epoch': 0, 'batch': 304, 'loss': 2.904576063156128}\n",
            "{'epoch': 0, 'batch': 305, 'loss': 3.043635129928589}\n",
            "{'epoch': 0, 'batch': 306, 'loss': 3.036027669906616}\n",
            "{'epoch': 0, 'batch': 307, 'loss': 2.7401883602142334}\n",
            "{'epoch': 0, 'batch': 308, 'loss': 3.2091851234436035}\n",
            "{'epoch': 0, 'batch': 309, 'loss': 3.07357120513916}\n",
            "{'epoch': 0, 'batch': 310, 'loss': 2.989290475845337}\n",
            "{'epoch': 0, 'batch': 311, 'loss': 2.947425365447998}\n",
            "{'epoch': 0, 'batch': 312, 'loss': 2.883716106414795}\n",
            "{'epoch': 0, 'batch': 313, 'loss': 3.035240650177002}\n",
            "{'epoch': 0, 'batch': 314, 'loss': 3.1090915203094482}\n",
            "{'epoch': 0, 'batch': 315, 'loss': 3.1075997352600098}\n",
            "{'epoch': 0, 'batch': 316, 'loss': 3.3436474800109863}\n",
            "{'epoch': 0, 'batch': 317, 'loss': 2.913177013397217}\n",
            "{'epoch': 0, 'batch': 318, 'loss': 3.2003493309020996}\n",
            "{'epoch': 0, 'batch': 319, 'loss': 3.03787899017334}\n",
            "{'epoch': 0, 'batch': 320, 'loss': 3.1982216835021973}\n",
            "{'epoch': 0, 'batch': 321, 'loss': 3.239436626434326}\n",
            "{'epoch': 0, 'batch': 322, 'loss': 3.3592796325683594}\n",
            "{'epoch': 0, 'batch': 323, 'loss': 3.3965420722961426}\n",
            "{'epoch': 0, 'batch': 324, 'loss': 3.0148231983184814}\n",
            "{'epoch': 0, 'batch': 325, 'loss': 3.0830283164978027}\n",
            "{'epoch': 0, 'batch': 326, 'loss': 3.002838134765625}\n",
            "{'epoch': 0, 'batch': 327, 'loss': 2.9370851516723633}\n",
            "{'epoch': 0, 'batch': 328, 'loss': 3.0511510372161865}\n",
            "{'epoch': 0, 'batch': 329, 'loss': 3.175358772277832}\n",
            "{'epoch': 0, 'batch': 330, 'loss': 3.1284916400909424}\n",
            "{'epoch': 0, 'batch': 331, 'loss': 3.326967239379883}\n",
            "{'epoch': 0, 'batch': 332, 'loss': 3.151975154876709}\n",
            "{'epoch': 0, 'batch': 333, 'loss': 3.1676290035247803}\n",
            "{'epoch': 0, 'batch': 334, 'loss': 3.5253117084503174}\n",
            "{'epoch': 0, 'batch': 335, 'loss': 3.2088234424591064}\n",
            "{'epoch': 0, 'batch': 336, 'loss': 3.359245777130127}\n",
            "{'epoch': 0, 'batch': 337, 'loss': 3.290235996246338}\n",
            "{'epoch': 0, 'batch': 338, 'loss': 3.4634158611297607}\n",
            "{'epoch': 0, 'batch': 339, 'loss': 3.23406982421875}\n",
            "{'epoch': 0, 'batch': 340, 'loss': 3.1642162799835205}\n",
            "{'epoch': 0, 'batch': 341, 'loss': 3.45234751701355}\n",
            "{'epoch': 0, 'batch': 342, 'loss': 2.981940746307373}\n",
            "{'epoch': 0, 'batch': 343, 'loss': 3.4929187297821045}\n",
            "{'epoch': 0, 'batch': 344, 'loss': 3.236193895339966}\n",
            "{'epoch': 0, 'batch': 345, 'loss': 3.164879322052002}\n",
            "{'epoch': 0, 'batch': 346, 'loss': 3.132000684738159}\n",
            "{'epoch': 0, 'batch': 347, 'loss': 3.094229221343994}\n",
            "{'epoch': 0, 'batch': 348, 'loss': 3.2899811267852783}\n",
            "{'epoch': 0, 'batch': 349, 'loss': 3.6110711097717285}\n",
            "{'epoch': 0, 'batch': 350, 'loss': 3.470917224884033}\n",
            "{'epoch': 0, 'batch': 351, 'loss': 3.3429198265075684}\n",
            "{'epoch': 0, 'batch': 352, 'loss': 3.279282331466675}\n",
            "{'epoch': 0, 'batch': 353, 'loss': 3.2166571617126465}\n",
            "{'epoch': 0, 'batch': 354, 'loss': 3.242241382598877}\n",
            "{'epoch': 0, 'batch': 355, 'loss': 3.107466220855713}\n",
            "{'epoch': 0, 'batch': 356, 'loss': 3.3195571899414062}\n",
            "{'epoch': 0, 'batch': 357, 'loss': 3.1793267726898193}\n",
            "{'epoch': 0, 'batch': 358, 'loss': 3.0076756477355957}\n",
            "{'epoch': 0, 'batch': 359, 'loss': 3.041684865951538}\n",
            "{'epoch': 0, 'batch': 360, 'loss': 3.1547024250030518}\n",
            "{'epoch': 0, 'batch': 361, 'loss': 2.910665988922119}\n",
            "{'epoch': 0, 'batch': 362, 'loss': 2.993582010269165}\n",
            "{'epoch': 0, 'batch': 363, 'loss': 3.1790072917938232}\n",
            "{'epoch': 0, 'batch': 364, 'loss': 3.086426258087158}\n",
            "{'epoch': 0, 'batch': 365, 'loss': 3.202955961227417}\n",
            "{'epoch': 0, 'batch': 366, 'loss': 3.2980709075927734}\n",
            "{'epoch': 0, 'batch': 367, 'loss': 2.928588390350342}\n",
            "{'epoch': 0, 'batch': 368, 'loss': 3.26690673828125}\n",
            "{'epoch': 0, 'batch': 369, 'loss': 3.070918083190918}\n",
            "{'epoch': 0, 'batch': 370, 'loss': 3.175105571746826}\n",
            "{'epoch': 0, 'batch': 371, 'loss': 3.3500397205352783}\n",
            "{'epoch': 0, 'batch': 372, 'loss': 3.3675217628479004}\n",
            "{'epoch': 0, 'batch': 373, 'loss': 2.9959774017333984}\n",
            "{'epoch': 0, 'batch': 374, 'loss': 3.270479679107666}\n",
            "{'epoch': 0, 'batch': 375, 'loss': 3.1071436405181885}\n",
            "{'epoch': 0, 'batch': 376, 'loss': 2.9378459453582764}\n",
            "{'epoch': 0, 'batch': 377, 'loss': 3.0608906745910645}\n",
            "{'epoch': 0, 'batch': 378, 'loss': 3.2609057426452637}\n",
            "{'epoch': 0, 'batch': 379, 'loss': 2.9354054927825928}\n",
            "{'epoch': 0, 'batch': 380, 'loss': 3.0004818439483643}\n",
            "{'epoch': 0, 'batch': 381, 'loss': 3.191694736480713}\n",
            "{'epoch': 0, 'batch': 382, 'loss': 3.3479480743408203}\n",
            "{'epoch': 0, 'batch': 383, 'loss': 3.2163054943084717}\n",
            "{'epoch': 0, 'batch': 384, 'loss': 2.968060255050659}\n",
            "{'epoch': 0, 'batch': 385, 'loss': 3.2945632934570312}\n",
            "{'epoch': 0, 'batch': 386, 'loss': 2.9246318340301514}\n",
            "{'epoch': 0, 'batch': 387, 'loss': 3.2922263145446777}\n",
            "{'epoch': 0, 'batch': 388, 'loss': 3.173236131668091}\n",
            "{'epoch': 0, 'batch': 389, 'loss': 3.1051645278930664}\n",
            "{'epoch': 0, 'batch': 390, 'loss': 3.4030261039733887}\n",
            "{'epoch': 0, 'batch': 391, 'loss': 3.1759517192840576}\n",
            "{'epoch': 0, 'batch': 392, 'loss': 3.094294309616089}\n",
            "{'epoch': 0, 'batch': 393, 'loss': 3.0610175132751465}\n",
            "{'epoch': 0, 'batch': 394, 'loss': 2.9808695316314697}\n",
            "{'epoch': 0, 'batch': 395, 'loss': 3.1464788913726807}\n",
            "{'epoch': 0, 'batch': 396, 'loss': 3.0393545627593994}\n",
            "{'epoch': 0, 'batch': 397, 'loss': 3.1706604957580566}\n",
            "{'epoch': 0, 'batch': 398, 'loss': 3.1839146614074707}\n",
            "{'epoch': 0, 'batch': 399, 'loss': 3.2084012031555176}\n",
            "{'epoch': 0, 'batch': 400, 'loss': 3.132676601409912}\n",
            "{'epoch': 0, 'batch': 401, 'loss': 3.327368974685669}\n",
            "{'epoch': 0, 'batch': 402, 'loss': 3.091301441192627}\n",
            "{'epoch': 0, 'batch': 403, 'loss': 2.970557451248169}\n",
            "{'epoch': 0, 'batch': 404, 'loss': 3.1092050075531006}\n",
            "{'epoch': 0, 'batch': 405, 'loss': 3.25679087638855}\n",
            "{'epoch': 0, 'batch': 406, 'loss': 3.3523261547088623}\n",
            "{'epoch': 0, 'batch': 407, 'loss': 3.3369498252868652}\n",
            "{'epoch': 0, 'batch': 408, 'loss': 3.3540968894958496}\n",
            "{'epoch': 0, 'batch': 409, 'loss': 3.1046628952026367}\n",
            "{'epoch': 0, 'batch': 410, 'loss': 3.563002347946167}\n",
            "{'epoch': 0, 'batch': 411, 'loss': 3.5203697681427}\n",
            "{'epoch': 0, 'batch': 412, 'loss': 3.3524882793426514}\n",
            "{'epoch': 0, 'batch': 413, 'loss': 3.365177631378174}\n",
            "{'epoch': 0, 'batch': 414, 'loss': 3.235731601715088}\n",
            "{'epoch': 0, 'batch': 415, 'loss': 3.190068483352661}\n",
            "{'epoch': 0, 'batch': 416, 'loss': 2.949082851409912}\n",
            "{'epoch': 0, 'batch': 417, 'loss': 3.0557515621185303}\n",
            "{'epoch': 0, 'batch': 418, 'loss': 3.2329368591308594}\n",
            "{'epoch': 0, 'batch': 419, 'loss': 3.0665061473846436}\n",
            "{'epoch': 0, 'batch': 420, 'loss': 3.273327589035034}\n",
            "{'epoch': 0, 'batch': 421, 'loss': 2.916105031967163}\n",
            "{'epoch': 0, 'batch': 422, 'loss': 3.15657639503479}\n",
            "{'epoch': 0, 'batch': 423, 'loss': 3.1297314167022705}\n",
            "{'epoch': 0, 'batch': 424, 'loss': 3.1067428588867188}\n",
            "{'epoch': 0, 'batch': 425, 'loss': 3.309502124786377}\n",
            "{'epoch': 0, 'batch': 426, 'loss': 3.1473422050476074}\n",
            "{'epoch': 0, 'batch': 427, 'loss': 2.995361804962158}\n",
            "{'epoch': 0, 'batch': 428, 'loss': 2.803295612335205}\n",
            "{'epoch': 0, 'batch': 429, 'loss': 3.244899034500122}\n",
            "{'epoch': 0, 'batch': 430, 'loss': 3.076704502105713}\n",
            "{'epoch': 0, 'batch': 431, 'loss': 3.1990838050842285}\n",
            "{'epoch': 0, 'batch': 432, 'loss': 3.405785322189331}\n",
            "{'epoch': 0, 'batch': 433, 'loss': 3.701380491256714}\n",
            "{'epoch': 0, 'batch': 434, 'loss': 3.093964099884033}\n",
            "{'epoch': 0, 'batch': 435, 'loss': 3.4228515625}\n",
            "{'epoch': 0, 'batch': 436, 'loss': 3.242736339569092}\n",
            "{'epoch': 0, 'batch': 437, 'loss': 3.0946006774902344}\n",
            "{'epoch': 0, 'batch': 438, 'loss': 3.6788604259490967}\n",
            "{'epoch': 0, 'batch': 439, 'loss': 3.0397887229919434}\n",
            "{'epoch': 0, 'batch': 440, 'loss': 3.124399185180664}\n",
            "{'epoch': 0, 'batch': 441, 'loss': 3.238463878631592}\n",
            "{'epoch': 0, 'batch': 442, 'loss': 3.0039572715759277}\n",
            "{'epoch': 0, 'batch': 443, 'loss': 3.1553502082824707}\n",
            "{'epoch': 0, 'batch': 444, 'loss': 3.212949752807617}\n",
            "{'epoch': 0, 'batch': 445, 'loss': 3.084383964538574}\n",
            "{'epoch': 0, 'batch': 446, 'loss': 2.97751784324646}\n",
            "{'epoch': 0, 'batch': 447, 'loss': 3.224123477935791}\n",
            "{'epoch': 0, 'batch': 448, 'loss': 3.0844459533691406}\n",
            "{'epoch': 0, 'batch': 449, 'loss': 3.2891433238983154}\n",
            "{'epoch': 0, 'batch': 450, 'loss': 3.1201653480529785}\n",
            "{'epoch': 0, 'batch': 451, 'loss': 3.1793875694274902}\n",
            "{'epoch': 0, 'batch': 452, 'loss': 3.4594790935516357}\n",
            "{'epoch': 0, 'batch': 453, 'loss': 3.1632676124572754}\n",
            "{'epoch': 0, 'batch': 454, 'loss': 3.128781795501709}\n",
            "{'epoch': 0, 'batch': 455, 'loss': 3.3659045696258545}\n",
            "{'epoch': 0, 'batch': 456, 'loss': 3.1424689292907715}\n",
            "{'epoch': 0, 'batch': 457, 'loss': 3.213118314743042}\n",
            "{'epoch': 0, 'batch': 458, 'loss': 2.706820011138916}\n",
            "{'epoch': 0, 'batch': 459, 'loss': 2.9196982383728027}\n",
            "{'epoch': 0, 'batch': 460, 'loss': 3.0870354175567627}\n",
            "{'epoch': 0, 'batch': 461, 'loss': 2.7999918460845947}\n",
            "{'epoch': 0, 'batch': 462, 'loss': 2.9888079166412354}\n",
            "{'epoch': 0, 'batch': 463, 'loss': 2.9595389366149902}\n",
            "{'epoch': 0, 'batch': 464, 'loss': 3.21586275100708}\n",
            "{'epoch': 0, 'batch': 465, 'loss': 3.1401419639587402}\n",
            "{'epoch': 0, 'batch': 466, 'loss': 3.1027259826660156}\n",
            "{'epoch': 0, 'batch': 467, 'loss': 3.0118160247802734}\n",
            "{'epoch': 0, 'batch': 468, 'loss': 3.0488522052764893}\n",
            "{'epoch': 0, 'batch': 469, 'loss': 3.1876349449157715}\n",
            "{'epoch': 0, 'batch': 470, 'loss': 3.066333770751953}\n",
            "{'epoch': 0, 'batch': 471, 'loss': 3.1672768592834473}\n",
            "{'epoch': 0, 'batch': 472, 'loss': 3.0867905616760254}\n",
            "{'epoch': 0, 'batch': 473, 'loss': 2.9301419258117676}\n",
            "{'epoch': 0, 'batch': 474, 'loss': 2.9695773124694824}\n",
            "{'epoch': 0, 'batch': 475, 'loss': 3.4226059913635254}\n",
            "{'epoch': 0, 'batch': 476, 'loss': 3.116367816925049}\n",
            "{'epoch': 0, 'batch': 477, 'loss': 3.1107258796691895}\n",
            "{'epoch': 0, 'batch': 478, 'loss': 3.3416690826416016}\n",
            "{'epoch': 0, 'batch': 479, 'loss': 2.9199676513671875}\n",
            "{'epoch': 0, 'batch': 480, 'loss': 3.174229145050049}\n",
            "{'epoch': 0, 'batch': 481, 'loss': 3.0661423206329346}\n",
            "{'epoch': 0, 'batch': 482, 'loss': 3.2027435302734375}\n",
            "{'epoch': 0, 'batch': 483, 'loss': 3.2324938774108887}\n",
            "{'epoch': 0, 'batch': 484, 'loss': 3.1161587238311768}\n",
            "{'epoch': 0, 'batch': 485, 'loss': 3.040104389190674}\n",
            "{'epoch': 0, 'batch': 486, 'loss': 3.357306718826294}\n",
            "{'epoch': 0, 'batch': 487, 'loss': 3.0266590118408203}\n",
            "{'epoch': 0, 'batch': 488, 'loss': 3.563610792160034}\n",
            "{'epoch': 0, 'batch': 489, 'loss': 3.1472082138061523}\n",
            "{'epoch': 0, 'batch': 490, 'loss': 3.1849772930145264}\n",
            "{'epoch': 0, 'batch': 491, 'loss': 3.4248223304748535}\n",
            "{'epoch': 0, 'batch': 492, 'loss': 3.379260540008545}\n",
            "{'epoch': 0, 'batch': 493, 'loss': 3.3018805980682373}\n",
            "{'epoch': 0, 'batch': 494, 'loss': 3.284416675567627}\n",
            "{'epoch': 0, 'batch': 495, 'loss': 2.9078621864318848}\n",
            "{'epoch': 0, 'batch': 496, 'loss': 3.31984281539917}\n",
            "{'epoch': 0, 'batch': 497, 'loss': 2.9945712089538574}\n",
            "{'epoch': 0, 'batch': 498, 'loss': 3.1259782314300537}\n",
            "{'epoch': 0, 'batch': 499, 'loss': 3.08232045173645}\n",
            "{'epoch': 0, 'batch': 500, 'loss': 3.0322368144989014}\n",
            "{'epoch': 0, 'batch': 501, 'loss': 3.2453536987304688}\n",
            "{'epoch': 0, 'batch': 502, 'loss': 3.138619899749756}\n",
            "{'epoch': 0, 'batch': 503, 'loss': 3.6415927410125732}\n",
            "{'epoch': 0, 'batch': 504, 'loss': 3.6283366680145264}\n",
            "{'epoch': 0, 'batch': 505, 'loss': 3.5486228466033936}\n",
            "{'epoch': 0, 'batch': 506, 'loss': 3.255706310272217}\n",
            "{'epoch': 0, 'batch': 507, 'loss': 3.2876782417297363}\n",
            "{'epoch': 0, 'batch': 508, 'loss': 3.0508370399475098}\n",
            "{'epoch': 0, 'batch': 509, 'loss': 3.0709972381591797}\n",
            "{'epoch': 0, 'batch': 510, 'loss': 3.097088575363159}\n",
            "{'epoch': 0, 'batch': 511, 'loss': 3.033724308013916}\n",
            "{'epoch': 0, 'batch': 512, 'loss': 3.089049816131592}\n",
            "{'epoch': 0, 'batch': 513, 'loss': 3.2130603790283203}\n",
            "{'epoch': 0, 'batch': 514, 'loss': 2.969416856765747}\n",
            "{'epoch': 0, 'batch': 515, 'loss': 3.159984588623047}\n",
            "{'epoch': 0, 'batch': 516, 'loss': 3.1634912490844727}\n",
            "{'epoch': 0, 'batch': 517, 'loss': 3.3691952228546143}\n",
            "{'epoch': 0, 'batch': 518, 'loss': 3.359753131866455}\n",
            "{'epoch': 0, 'batch': 519, 'loss': 3.0441927909851074}\n",
            "{'epoch': 0, 'batch': 520, 'loss': 3.1309094429016113}\n",
            "{'epoch': 0, 'batch': 521, 'loss': 3.3295745849609375}\n",
            "{'epoch': 0, 'batch': 522, 'loss': 3.4594223499298096}\n",
            "{'epoch': 0, 'batch': 523, 'loss': 3.2293429374694824}\n",
            "{'epoch': 0, 'batch': 524, 'loss': 3.392911911010742}\n",
            "{'epoch': 0, 'batch': 525, 'loss': 3.113870620727539}\n",
            "{'epoch': 0, 'batch': 526, 'loss': 2.9821274280548096}\n",
            "{'epoch': 0, 'batch': 527, 'loss': 3.308422088623047}\n",
            "{'epoch': 0, 'batch': 528, 'loss': 3.252988338470459}\n",
            "{'epoch': 0, 'batch': 529, 'loss': 3.3943047523498535}\n",
            "{'epoch': 0, 'batch': 530, 'loss': 3.1595587730407715}\n",
            "{'epoch': 0, 'batch': 531, 'loss': 3.137547492980957}\n",
            "{'epoch': 0, 'batch': 532, 'loss': 3.246610641479492}\n",
            "{'epoch': 0, 'batch': 533, 'loss': 2.8804168701171875}\n",
            "{'epoch': 0, 'batch': 534, 'loss': 3.275365114212036}\n",
            "{'epoch': 0, 'batch': 535, 'loss': 3.262774705886841}\n",
            "{'epoch': 0, 'batch': 536, 'loss': 3.3516337871551514}\n",
            "{'epoch': 0, 'batch': 537, 'loss': 3.3955554962158203}\n",
            "{'epoch': 0, 'batch': 538, 'loss': 3.1179914474487305}\n",
            "{'epoch': 0, 'batch': 539, 'loss': 3.3495585918426514}\n",
            "{'epoch': 0, 'batch': 540, 'loss': 3.5197243690490723}\n",
            "{'epoch': 0, 'batch': 541, 'loss': 3.197840929031372}\n",
            "{'epoch': 0, 'batch': 542, 'loss': 3.0878517627716064}\n",
            "{'epoch': 0, 'batch': 543, 'loss': 3.488065004348755}\n",
            "{'epoch': 0, 'batch': 544, 'loss': 3.1491312980651855}\n",
            "{'epoch': 0, 'batch': 545, 'loss': 3.5667014122009277}\n",
            "{'epoch': 0, 'batch': 546, 'loss': 3.27197265625}\n",
            "{'epoch': 0, 'batch': 547, 'loss': 3.2284960746765137}\n",
            "{'epoch': 0, 'batch': 548, 'loss': 3.320369243621826}\n",
            "{'epoch': 0, 'batch': 549, 'loss': 3.3195700645446777}\n",
            "{'epoch': 0, 'batch': 550, 'loss': 3.3804595470428467}\n",
            "{'epoch': 0, 'batch': 551, 'loss': 2.957995653152466}\n",
            "{'epoch': 0, 'batch': 552, 'loss': 3.227527141571045}\n",
            "{'epoch': 0, 'batch': 553, 'loss': 3.287980556488037}\n",
            "{'epoch': 0, 'batch': 554, 'loss': 3.1722865104675293}\n",
            "{'epoch': 0, 'batch': 555, 'loss': 3.1134657859802246}\n",
            "{'epoch': 0, 'batch': 556, 'loss': 3.122736930847168}\n",
            "{'epoch': 0, 'batch': 557, 'loss': 3.097362518310547}\n",
            "{'epoch': 0, 'batch': 558, 'loss': 3.6699652671813965}\n",
            "{'epoch': 0, 'batch': 559, 'loss': 3.1561856269836426}\n",
            "{'epoch': 0, 'batch': 560, 'loss': 2.8245368003845215}\n",
            "{'epoch': 0, 'batch': 561, 'loss': 3.0536715984344482}\n",
            "{'epoch': 0, 'batch': 562, 'loss': 3.127312183380127}\n",
            "{'epoch': 0, 'batch': 563, 'loss': 3.0026867389678955}\n",
            "{'epoch': 0, 'batch': 564, 'loss': 3.0677287578582764}\n",
            "{'epoch': 0, 'batch': 565, 'loss': 3.0597217082977295}\n",
            "{'epoch': 0, 'batch': 566, 'loss': 2.9498093128204346}\n",
            "{'epoch': 0, 'batch': 567, 'loss': 3.2137503623962402}\n",
            "{'epoch': 0, 'batch': 568, 'loss': 3.2221152782440186}\n",
            "{'epoch': 0, 'batch': 569, 'loss': 2.954423189163208}\n",
            "{'epoch': 0, 'batch': 570, 'loss': 2.7132277488708496}\n",
            "{'epoch': 0, 'batch': 571, 'loss': 2.76585054397583}\n",
            "{'epoch': 0, 'batch': 572, 'loss': 3.1310369968414307}\n",
            "{'epoch': 0, 'batch': 573, 'loss': 2.9327681064605713}\n",
            "{'epoch': 0, 'batch': 574, 'loss': 2.941722869873047}\n",
            "{'epoch': 0, 'batch': 575, 'loss': 2.8479814529418945}\n",
            "{'epoch': 0, 'batch': 576, 'loss': 2.968430519104004}\n",
            "{'epoch': 0, 'batch': 577, 'loss': 3.0059826374053955}\n",
            "{'epoch': 0, 'batch': 578, 'loss': 3.0454673767089844}\n",
            "{'epoch': 0, 'batch': 579, 'loss': 3.1055543422698975}\n",
            "{'epoch': 0, 'batch': 580, 'loss': 2.9593820571899414}\n",
            "{'epoch': 0, 'batch': 581, 'loss': 3.16078519821167}\n",
            "{'epoch': 0, 'batch': 582, 'loss': 3.55949068069458}\n",
            "{'epoch': 0, 'batch': 583, 'loss': 2.9707157611846924}\n",
            "{'epoch': 0, 'batch': 584, 'loss': 3.2805144786834717}\n",
            "{'epoch': 0, 'batch': 585, 'loss': 3.078143835067749}\n",
            "{'epoch': 0, 'batch': 586, 'loss': 3.1902129650115967}\n",
            "{'epoch': 0, 'batch': 587, 'loss': 3.407167434692383}\n",
            "{'epoch': 0, 'batch': 588, 'loss': 3.477337598800659}\n",
            "{'epoch': 0, 'batch': 589, 'loss': 3.023834466934204}\n",
            "{'epoch': 0, 'batch': 590, 'loss': 3.3998446464538574}\n",
            "{'epoch': 0, 'batch': 591, 'loss': 2.959221601486206}\n",
            "{'epoch': 0, 'batch': 592, 'loss': 3.178222179412842}\n",
            "{'epoch': 0, 'batch': 593, 'loss': 3.0672085285186768}\n",
            "{'epoch': 0, 'batch': 594, 'loss': 3.110898494720459}\n",
            "{'epoch': 0, 'batch': 595, 'loss': 3.06144380569458}\n",
            "{'epoch': 0, 'batch': 596, 'loss': 3.025078058242798}\n",
            "{'epoch': 0, 'batch': 597, 'loss': 3.10544753074646}\n",
            "{'epoch': 0, 'batch': 598, 'loss': 3.180436611175537}\n",
            "{'epoch': 0, 'batch': 599, 'loss': 2.951380968093872}\n",
            "{'epoch': 0, 'batch': 600, 'loss': 3.3314273357391357}\n",
            "{'epoch': 0, 'batch': 601, 'loss': 3.330953598022461}\n",
            "{'epoch': 0, 'batch': 602, 'loss': 3.4744467735290527}\n",
            "{'epoch': 0, 'batch': 603, 'loss': 3.081019163131714}\n",
            "{'epoch': 0, 'batch': 604, 'loss': 2.9330265522003174}\n",
            "{'epoch': 0, 'batch': 605, 'loss': 3.0683388710021973}\n",
            "{'epoch': 0, 'batch': 606, 'loss': 3.061553955078125}\n",
            "{'epoch': 0, 'batch': 607, 'loss': 3.110506534576416}\n",
            "{'epoch': 0, 'batch': 608, 'loss': 3.3911120891571045}\n",
            "{'epoch': 0, 'batch': 609, 'loss': 3.4512221813201904}\n",
            "{'epoch': 0, 'batch': 610, 'loss': 3.4888668060302734}\n",
            "{'epoch': 0, 'batch': 611, 'loss': 3.095003843307495}\n",
            "{'epoch': 0, 'batch': 612, 'loss': 3.098233461380005}\n",
            "{'epoch': 0, 'batch': 613, 'loss': 2.9103405475616455}\n",
            "{'epoch': 0, 'batch': 614, 'loss': 2.6826231479644775}\n",
            "{'epoch': 0, 'batch': 615, 'loss': 3.0370726585388184}\n",
            "{'epoch': 0, 'batch': 616, 'loss': 3.2099273204803467}\n",
            "{'epoch': 0, 'batch': 617, 'loss': 3.1115241050720215}\n",
            "{'epoch': 0, 'batch': 618, 'loss': 2.9169812202453613}\n",
            "{'epoch': 0, 'batch': 619, 'loss': 3.0618250370025635}\n",
            "{'epoch': 0, 'batch': 620, 'loss': 3.383185863494873}\n",
            "{'epoch': 0, 'batch': 621, 'loss': 3.137850046157837}\n",
            "{'epoch': 0, 'batch': 622, 'loss': 3.1292576789855957}\n",
            "{'epoch': 0, 'batch': 623, 'loss': 2.933972120285034}\n",
            "{'epoch': 0, 'batch': 624, 'loss': 3.262089490890503}\n",
            "{'epoch': 0, 'batch': 625, 'loss': 3.2173125743865967}\n",
            "{'epoch': 0, 'batch': 626, 'loss': 2.821504592895508}\n",
            "{'epoch': 0, 'batch': 627, 'loss': 3.089913845062256}\n",
            "{'epoch': 0, 'batch': 628, 'loss': 3.6494014263153076}\n",
            "{'epoch': 0, 'batch': 629, 'loss': 2.9506168365478516}\n",
            "{'epoch': 0, 'batch': 630, 'loss': 2.4130051136016846}\n",
            "{'epoch': 0, 'batch': 631, 'loss': 2.598231792449951}\n",
            "{'epoch': 0, 'batch': 632, 'loss': 3.091555595397949}\n",
            "{'epoch': 0, 'batch': 633, 'loss': 3.0689752101898193}\n",
            "{'epoch': 0, 'batch': 634, 'loss': 3.2510242462158203}\n",
            "{'epoch': 0, 'batch': 635, 'loss': 3.133329153060913}\n",
            "{'epoch': 0, 'batch': 636, 'loss': 3.029179096221924}\n",
            "{'epoch': 0, 'batch': 637, 'loss': 3.459230899810791}\n",
            "{'epoch': 0, 'batch': 638, 'loss': 3.310117244720459}\n",
            "{'epoch': 0, 'batch': 639, 'loss': 3.2420315742492676}\n",
            "{'epoch': 0, 'batch': 640, 'loss': 3.255718946456909}\n",
            "{'epoch': 0, 'batch': 641, 'loss': 3.537851333618164}\n",
            "{'epoch': 0, 'batch': 642, 'loss': 2.934408187866211}\n",
            "{'epoch': 0, 'batch': 643, 'loss': 3.188231945037842}\n",
            "{'epoch': 0, 'batch': 644, 'loss': 2.9706647396087646}\n",
            "{'epoch': 0, 'batch': 645, 'loss': 2.9671285152435303}\n",
            "{'epoch': 0, 'batch': 646, 'loss': 3.087599754333496}\n",
            "{'epoch': 0, 'batch': 647, 'loss': 2.9445786476135254}\n",
            "{'epoch': 0, 'batch': 648, 'loss': 3.3065173625946045}\n",
            "{'epoch': 0, 'batch': 649, 'loss': 3.493252992630005}\n",
            "{'epoch': 0, 'batch': 650, 'loss': 2.7810897827148438}\n",
            "{'epoch': 0, 'batch': 651, 'loss': 3.3184497356414795}\n",
            "{'epoch': 0, 'batch': 652, 'loss': 3.4625251293182373}\n",
            "{'epoch': 0, 'batch': 653, 'loss': 3.4636502265930176}\n",
            "{'epoch': 0, 'batch': 654, 'loss': 3.4192264080047607}\n",
            "{'epoch': 0, 'batch': 655, 'loss': 3.5590484142303467}\n",
            "{'epoch': 0, 'batch': 656, 'loss': 3.17478609085083}\n",
            "{'epoch': 0, 'batch': 657, 'loss': 3.2285313606262207}\n",
            "{'epoch': 0, 'batch': 658, 'loss': 3.4750428199768066}\n",
            "{'epoch': 0, 'batch': 659, 'loss': 3.3846256732940674}\n",
            "{'epoch': 0, 'batch': 660, 'loss': 3.081073045730591}\n",
            "{'epoch': 0, 'batch': 661, 'loss': 3.1373727321624756}\n",
            "{'epoch': 0, 'batch': 662, 'loss': 3.203667163848877}\n",
            "{'epoch': 0, 'batch': 663, 'loss': 3.1751012802124023}\n",
            "{'epoch': 0, 'batch': 664, 'loss': 3.228034496307373}\n",
            "{'epoch': 0, 'batch': 665, 'loss': 3.339181423187256}\n",
            "{'epoch': 0, 'batch': 666, 'loss': 3.1537046432495117}\n",
            "{'epoch': 0, 'batch': 667, 'loss': 3.265626907348633}\n",
            "{'epoch': 0, 'batch': 668, 'loss': 3.355412006378174}\n",
            "{'epoch': 0, 'batch': 669, 'loss': 3.3650543689727783}\n",
            "{'epoch': 0, 'batch': 670, 'loss': 3.6668262481689453}\n",
            "{'epoch': 0, 'batch': 671, 'loss': 3.513110637664795}\n",
            "{'epoch': 0, 'batch': 672, 'loss': 3.5245299339294434}\n",
            "{'epoch': 0, 'batch': 673, 'loss': 3.2386717796325684}\n",
            "{'epoch': 0, 'batch': 674, 'loss': 3.2226390838623047}\n",
            "{'epoch': 0, 'batch': 675, 'loss': 3.272303342819214}\n",
            "{'epoch': 0, 'batch': 676, 'loss': 2.8762025833129883}\n",
            "{'epoch': 0, 'batch': 677, 'loss': 3.609973192214966}\n",
            "{'epoch': 0, 'batch': 678, 'loss': 3.314154863357544}\n",
            "{'epoch': 0, 'batch': 679, 'loss': 3.017151355743408}\n",
            "{'epoch': 0, 'batch': 680, 'loss': 3.2411580085754395}\n",
            "{'epoch': 0, 'batch': 681, 'loss': 3.0608205795288086}\n",
            "{'epoch': 0, 'batch': 682, 'loss': 3.434018611907959}\n",
            "{'epoch': 0, 'batch': 683, 'loss': 2.89951229095459}\n",
            "{'epoch': 0, 'batch': 684, 'loss': 3.230135440826416}\n",
            "{'epoch': 0, 'batch': 685, 'loss': 3.3780930042266846}\n",
            "{'epoch': 0, 'batch': 686, 'loss': 3.1856958866119385}\n",
            "{'epoch': 0, 'batch': 687, 'loss': 3.22735857963562}\n",
            "{'epoch': 0, 'batch': 688, 'loss': 3.3505489826202393}\n",
            "{'epoch': 0, 'batch': 689, 'loss': 2.965651273727417}\n",
            "{'epoch': 0, 'batch': 690, 'loss': 3.337134838104248}\n",
            "{'epoch': 0, 'batch': 691, 'loss': 3.032292604446411}\n",
            "{'epoch': 0, 'batch': 692, 'loss': 2.977280616760254}\n",
            "{'epoch': 0, 'batch': 693, 'loss': 3.161970853805542}\n",
            "{'epoch': 0, 'batch': 694, 'loss': 3.076223611831665}\n",
            "{'epoch': 0, 'batch': 695, 'loss': 3.252556562423706}\n",
            "{'epoch': 0, 'batch': 696, 'loss': 3.0791544914245605}\n",
            "{'epoch': 0, 'batch': 697, 'loss': 3.277067184448242}\n",
            "{'epoch': 0, 'batch': 698, 'loss': 3.1986212730407715}\n",
            "{'epoch': 0, 'batch': 699, 'loss': 3.280057430267334}\n",
            "{'epoch': 0, 'batch': 700, 'loss': 3.2194461822509766}\n",
            "{'epoch': 0, 'batch': 701, 'loss': 3.2769863605499268}\n",
            "{'epoch': 0, 'batch': 702, 'loss': 2.740571975708008}\n",
            "{'epoch': 0, 'batch': 703, 'loss': 3.1477246284484863}\n",
            "{'epoch': 0, 'batch': 704, 'loss': 3.2223591804504395}\n",
            "{'epoch': 0, 'batch': 705, 'loss': 3.1006617546081543}\n",
            "{'epoch': 0, 'batch': 706, 'loss': 3.1129040718078613}\n",
            "{'epoch': 0, 'batch': 707, 'loss': 3.181452989578247}\n",
            "{'epoch': 0, 'batch': 708, 'loss': 3.2506909370422363}\n",
            "{'epoch': 0, 'batch': 709, 'loss': 3.4158236980438232}\n",
            "{'epoch': 0, 'batch': 710, 'loss': 3.4234073162078857}\n",
            "{'epoch': 0, 'batch': 711, 'loss': 3.1876492500305176}\n",
            "{'epoch': 0, 'batch': 712, 'loss': 3.0664892196655273}\n",
            "{'epoch': 0, 'batch': 713, 'loss': 3.234814167022705}\n",
            "{'epoch': 0, 'batch': 714, 'loss': 2.9859824180603027}\n",
            "{'epoch': 0, 'batch': 715, 'loss': 2.9273409843444824}\n",
            "{'epoch': 0, 'batch': 716, 'loss': 3.1720292568206787}\n",
            "{'epoch': 0, 'batch': 717, 'loss': 3.293250322341919}\n",
            "{'epoch': 0, 'batch': 718, 'loss': 3.0700759887695312}\n",
            "{'epoch': 0, 'batch': 719, 'loss': 2.92464542388916}\n",
            "{'epoch': 0, 'batch': 720, 'loss': 3.146571397781372}\n",
            "{'epoch': 0, 'batch': 721, 'loss': 3.287393569946289}\n",
            "{'epoch': 0, 'batch': 722, 'loss': 3.323889970779419}\n",
            "{'epoch': 0, 'batch': 723, 'loss': 3.2856833934783936}\n",
            "{'epoch': 0, 'batch': 724, 'loss': 3.12534761428833}\n",
            "{'epoch': 0, 'batch': 725, 'loss': 3.10744571685791}\n",
            "{'epoch': 0, 'batch': 726, 'loss': 3.076572895050049}\n",
            "{'epoch': 0, 'batch': 727, 'loss': 2.943613052368164}\n",
            "{'epoch': 0, 'batch': 728, 'loss': 3.0498108863830566}\n",
            "{'epoch': 0, 'batch': 729, 'loss': 3.0763919353485107}\n",
            "{'epoch': 0, 'batch': 730, 'loss': 3.189129590988159}\n",
            "{'epoch': 0, 'batch': 731, 'loss': 3.1433534622192383}\n",
            "{'epoch': 0, 'batch': 732, 'loss': 3.246860980987549}\n",
            "{'epoch': 0, 'batch': 733, 'loss': 3.167865037918091}\n",
            "{'epoch': 0, 'batch': 734, 'loss': 3.319749355316162}\n",
            "{'epoch': 0, 'batch': 735, 'loss': 3.3115322589874268}\n",
            "{'epoch': 0, 'batch': 736, 'loss': 2.970651149749756}\n",
            "{'epoch': 0, 'batch': 737, 'loss': 3.335416316986084}\n",
            "{'epoch': 0, 'batch': 738, 'loss': 2.965909481048584}\n",
            "{'epoch': 0, 'batch': 739, 'loss': 2.892094373703003}\n",
            "{'epoch': 0, 'batch': 740, 'loss': 3.273561477661133}\n",
            "{'epoch': 0, 'batch': 741, 'loss': 3.444903612136841}\n",
            "{'epoch': 0, 'batch': 742, 'loss': 3.266331434249878}\n",
            "{'epoch': 0, 'batch': 743, 'loss': 2.891437292098999}\n",
            "{'epoch': 0, 'batch': 744, 'loss': 3.167283535003662}\n",
            "{'epoch': 0, 'batch': 745, 'loss': 3.5030884742736816}\n",
            "{'epoch': 0, 'batch': 746, 'loss': 3.0695605278015137}\n",
            "{'epoch': 0, 'batch': 747, 'loss': 3.189119338989258}\n",
            "{'epoch': 0, 'batch': 748, 'loss': 3.019735097885132}\n",
            "{'epoch': 0, 'batch': 749, 'loss': 3.0571858882904053}\n",
            "{'epoch': 0, 'batch': 750, 'loss': 3.072718620300293}\n",
            "{'epoch': 0, 'batch': 751, 'loss': 3.1912131309509277}\n",
            "{'epoch': 0, 'batch': 752, 'loss': 2.9839773178100586}\n",
            "{'epoch': 0, 'batch': 753, 'loss': 3.0271100997924805}\n",
            "{'epoch': 0, 'batch': 754, 'loss': 3.156787395477295}\n",
            "{'epoch': 0, 'batch': 755, 'loss': 3.193732261657715}\n",
            "{'epoch': 0, 'batch': 756, 'loss': 3.1035032272338867}\n",
            "{'epoch': 0, 'batch': 757, 'loss': 3.2245564460754395}\n",
            "{'epoch': 0, 'batch': 758, 'loss': 2.9692258834838867}\n",
            "{'epoch': 0, 'batch': 759, 'loss': 3.1659486293792725}\n",
            "{'epoch': 0, 'batch': 760, 'loss': 3.1414337158203125}\n",
            "{'epoch': 0, 'batch': 761, 'loss': 3.2299811840057373}\n",
            "{'epoch': 0, 'batch': 762, 'loss': 3.231356143951416}\n",
            "{'epoch': 0, 'batch': 763, 'loss': 3.5337376594543457}\n",
            "{'epoch': 0, 'batch': 764, 'loss': 3.542778730392456}\n",
            "{'epoch': 0, 'batch': 765, 'loss': 2.934016704559326}\n",
            "{'epoch': 0, 'batch': 766, 'loss': 3.331151247024536}\n",
            "{'epoch': 0, 'batch': 767, 'loss': 3.1169064044952393}\n",
            "{'epoch': 0, 'batch': 768, 'loss': 3.124232292175293}\n",
            "{'epoch': 0, 'batch': 769, 'loss': 3.2483386993408203}\n",
            "{'epoch': 0, 'batch': 770, 'loss': 2.9338393211364746}\n",
            "{'epoch': 0, 'batch': 771, 'loss': 2.9334230422973633}\n",
            "{'epoch': 0, 'batch': 772, 'loss': 2.928478956222534}\n",
            "{'epoch': 0, 'batch': 773, 'loss': 3.1677184104919434}\n",
            "{'epoch': 0, 'batch': 774, 'loss': 3.0991625785827637}\n",
            "{'epoch': 0, 'batch': 775, 'loss': 3.1357767581939697}\n",
            "{'epoch': 0, 'batch': 776, 'loss': 3.0136938095092773}\n",
            "{'epoch': 0, 'batch': 777, 'loss': 3.0255684852600098}\n",
            "{'epoch': 0, 'batch': 778, 'loss': 2.9269213676452637}\n",
            "{'epoch': 0, 'batch': 779, 'loss': 3.2448508739471436}\n",
            "{'epoch': 0, 'batch': 780, 'loss': 2.9380297660827637}\n",
            "{'epoch': 0, 'batch': 781, 'loss': 2.854116201400757}\n",
            "{'epoch': 0, 'batch': 782, 'loss': 3.1400842666625977}\n",
            "{'epoch': 0, 'batch': 783, 'loss': 3.0248634815216064}\n",
            "{'epoch': 0, 'batch': 784, 'loss': 2.8138628005981445}\n",
            "{'epoch': 0, 'batch': 785, 'loss': 3.10459566116333}\n",
            "{'epoch': 0, 'batch': 786, 'loss': 3.182281970977783}\n",
            "{'epoch': 0, 'batch': 787, 'loss': 2.7917869091033936}\n",
            "{'epoch': 0, 'batch': 788, 'loss': 3.0033254623413086}\n",
            "{'epoch': 0, 'batch': 789, 'loss': 3.1677463054656982}\n",
            "{'epoch': 0, 'batch': 790, 'loss': 3.0099339485168457}\n",
            "{'epoch': 0, 'batch': 791, 'loss': 3.4102959632873535}\n",
            "{'epoch': 0, 'batch': 792, 'loss': 3.54167103767395}\n",
            "{'epoch': 0, 'batch': 793, 'loss': 3.394346237182617}\n",
            "{'epoch': 0, 'batch': 794, 'loss': 3.099440336227417}\n",
            "{'epoch': 0, 'batch': 795, 'loss': 3.095634937286377}\n",
            "{'epoch': 0, 'batch': 796, 'loss': 3.485766649246216}\n",
            "{'epoch': 0, 'batch': 797, 'loss': 3.0874135494232178}\n",
            "{'epoch': 0, 'batch': 798, 'loss': 3.1421070098876953}\n",
            "{'epoch': 0, 'batch': 799, 'loss': 2.987091541290283}\n",
            "{'epoch': 0, 'batch': 800, 'loss': 3.04420804977417}\n",
            "{'epoch': 0, 'batch': 801, 'loss': 3.523850202560425}\n",
            "{'epoch': 0, 'batch': 802, 'loss': 3.3279170989990234}\n",
            "{'epoch': 0, 'batch': 803, 'loss': 3.3290793895721436}\n",
            "{'epoch': 0, 'batch': 804, 'loss': 3.2272133827209473}\n",
            "{'epoch': 0, 'batch': 805, 'loss': 3.107581377029419}\n",
            "{'epoch': 0, 'batch': 806, 'loss': 3.229163408279419}\n",
            "{'epoch': 0, 'batch': 807, 'loss': 3.027296781539917}\n",
            "{'epoch': 0, 'batch': 808, 'loss': 3.271466016769409}\n",
            "{'epoch': 0, 'batch': 809, 'loss': 3.486351728439331}\n",
            "{'epoch': 0, 'batch': 810, 'loss': 3.0475525856018066}\n",
            "{'epoch': 0, 'batch': 811, 'loss': 2.934398889541626}\n",
            "{'epoch': 0, 'batch': 812, 'loss': 3.2164015769958496}\n",
            "{'epoch': 0, 'batch': 813, 'loss': 3.190859317779541}\n",
            "{'epoch': 0, 'batch': 814, 'loss': 3.113614797592163}\n",
            "{'epoch': 0, 'batch': 815, 'loss': 3.515634536743164}\n",
            "{'epoch': 0, 'batch': 816, 'loss': 3.102102279663086}\n",
            "{'epoch': 0, 'batch': 817, 'loss': 2.998908519744873}\n",
            "{'epoch': 0, 'batch': 818, 'loss': 3.2917587757110596}\n",
            "{'epoch': 0, 'batch': 819, 'loss': 3.0829944610595703}\n",
            "{'epoch': 0, 'batch': 820, 'loss': 3.2711453437805176}\n",
            "{'epoch': 0, 'batch': 821, 'loss': 2.931532144546509}\n",
            "{'epoch': 0, 'batch': 822, 'loss': 2.901624917984009}\n",
            "{'epoch': 0, 'batch': 823, 'loss': 3.2980055809020996}\n",
            "{'epoch': 0, 'batch': 824, 'loss': 3.326815366744995}\n",
            "{'epoch': 0, 'batch': 825, 'loss': 3.2565174102783203}\n",
            "{'epoch': 0, 'batch': 826, 'loss': 3.181382656097412}\n",
            "{'epoch': 0, 'batch': 827, 'loss': 2.935213565826416}\n",
            "{'epoch': 0, 'batch': 828, 'loss': 3.0361530780792236}\n",
            "{'epoch': 0, 'batch': 829, 'loss': 3.023319721221924}\n",
            "{'epoch': 0, 'batch': 830, 'loss': 3.1699633598327637}\n",
            "{'epoch': 0, 'batch': 831, 'loss': 3.148348093032837}\n",
            "{'epoch': 0, 'batch': 832, 'loss': 3.2590739727020264}\n",
            "{'epoch': 0, 'batch': 833, 'loss': 3.1359825134277344}\n",
            "{'epoch': 0, 'batch': 834, 'loss': 3.270012378692627}\n",
            "{'epoch': 0, 'batch': 835, 'loss': 3.0528106689453125}\n",
            "{'epoch': 0, 'batch': 836, 'loss': 3.003636598587036}\n",
            "{'epoch': 0, 'batch': 837, 'loss': 3.2994110584259033}\n",
            "{'epoch': 0, 'batch': 838, 'loss': 3.0798919200897217}\n",
            "{'epoch': 0, 'batch': 839, 'loss': 2.881465196609497}\n",
            "{'epoch': 0, 'batch': 840, 'loss': 3.1817970275878906}\n",
            "{'epoch': 0, 'batch': 841, 'loss': 3.1114439964294434}\n",
            "{'epoch': 0, 'batch': 842, 'loss': 2.9239304065704346}\n",
            "{'epoch': 0, 'batch': 843, 'loss': 3.1254537105560303}\n",
            "{'epoch': 0, 'batch': 844, 'loss': 2.9572293758392334}\n",
            "{'epoch': 0, 'batch': 845, 'loss': 3.0089199542999268}\n",
            "{'epoch': 0, 'batch': 846, 'loss': 3.158252239227295}\n",
            "{'epoch': 0, 'batch': 847, 'loss': 3.074584722518921}\n",
            "{'epoch': 0, 'batch': 848, 'loss': 2.986635446548462}\n",
            "{'epoch': 0, 'batch': 849, 'loss': 3.2524783611297607}\n",
            "{'epoch': 0, 'batch': 850, 'loss': 2.893441915512085}\n",
            "{'epoch': 0, 'batch': 851, 'loss': 3.1776328086853027}\n",
            "{'epoch': 0, 'batch': 852, 'loss': 2.806762218475342}\n",
            "{'epoch': 0, 'batch': 853, 'loss': 2.8713715076446533}\n",
            "{'epoch': 0, 'batch': 854, 'loss': 3.0308518409729004}\n",
            "{'epoch': 0, 'batch': 855, 'loss': 2.926459789276123}\n",
            "{'epoch': 0, 'batch': 856, 'loss': 2.5997376441955566}\n",
            "{'epoch': 0, 'batch': 857, 'loss': 2.9226338863372803}\n",
            "{'epoch': 0, 'batch': 858, 'loss': 3.2929885387420654}\n",
            "{'epoch': 0, 'batch': 859, 'loss': 3.230846881866455}\n",
            "{'epoch': 0, 'batch': 860, 'loss': 3.3736348152160645}\n",
            "{'epoch': 0, 'batch': 861, 'loss': 2.97411847114563}\n",
            "{'epoch': 0, 'batch': 862, 'loss': 3.0423038005828857}\n",
            "{'epoch': 0, 'batch': 863, 'loss': 3.169503688812256}\n",
            "{'epoch': 0, 'batch': 864, 'loss': 3.0700523853302}\n",
            "{'epoch': 0, 'batch': 865, 'loss': 3.1463589668273926}\n",
            "{'epoch': 0, 'batch': 866, 'loss': 3.269514799118042}\n",
            "{'epoch': 0, 'batch': 867, 'loss': 2.9944889545440674}\n",
            "{'epoch': 0, 'batch': 868, 'loss': 2.8973779678344727}\n",
            "{'epoch': 0, 'batch': 869, 'loss': 3.0698704719543457}\n",
            "{'epoch': 0, 'batch': 870, 'loss': 2.9310085773468018}\n",
            "{'epoch': 0, 'batch': 871, 'loss': 3.0208308696746826}\n",
            "{'epoch': 0, 'batch': 872, 'loss': 2.9451980590820312}\n",
            "{'epoch': 0, 'batch': 873, 'loss': 3.1119627952575684}\n",
            "{'epoch': 0, 'batch': 874, 'loss': 3.2886815071105957}\n",
            "{'epoch': 0, 'batch': 875, 'loss': 3.228940486907959}\n",
            "{'epoch': 0, 'batch': 876, 'loss': 3.262498378753662}\n",
            "{'epoch': 0, 'batch': 877, 'loss': 3.1623406410217285}\n",
            "{'epoch': 0, 'batch': 878, 'loss': 2.943380355834961}\n",
            "{'epoch': 0, 'batch': 879, 'loss': 3.210881471633911}\n",
            "{'epoch': 0, 'batch': 880, 'loss': 2.9157729148864746}\n",
            "{'epoch': 0, 'batch': 881, 'loss': 2.7735755443573}\n",
            "{'epoch': 0, 'batch': 882, 'loss': 3.0198419094085693}\n",
            "{'epoch': 0, 'batch': 883, 'loss': 3.0046420097351074}\n",
            "{'epoch': 0, 'batch': 884, 'loss': 3.5525660514831543}\n",
            "{'epoch': 0, 'batch': 885, 'loss': 3.434006452560425}\n",
            "{'epoch': 0, 'batch': 886, 'loss': 3.611043930053711}\n",
            "{'epoch': 0, 'batch': 887, 'loss': 3.445852279663086}\n",
            "{'epoch': 0, 'batch': 888, 'loss': 3.7753303050994873}\n",
            "{'epoch': 0, 'batch': 889, 'loss': 3.256542921066284}\n",
            "{'epoch': 0, 'batch': 890, 'loss': 3.247685194015503}\n",
            "{'epoch': 0, 'batch': 891, 'loss': 3.300835132598877}\n",
            "{'epoch': 0, 'batch': 892, 'loss': 3.146306037902832}\n",
            "{'epoch': 0, 'batch': 893, 'loss': 3.2949137687683105}\n",
            "{'epoch': 0, 'batch': 894, 'loss': 3.435056686401367}\n",
            "{'epoch': 0, 'batch': 895, 'loss': 3.5447921752929688}\n",
            "{'epoch': 0, 'batch': 896, 'loss': 3.449946165084839}\n",
            "{'epoch': 0, 'batch': 897, 'loss': 3.2316055297851562}\n",
            "{'epoch': 0, 'batch': 898, 'loss': 3.6249146461486816}\n",
            "{'epoch': 0, 'batch': 899, 'loss': 3.2665469646453857}\n",
            "{'epoch': 0, 'batch': 900, 'loss': 3.180176258087158}\n",
            "{'epoch': 0, 'batch': 901, 'loss': 3.2124664783477783}\n",
            "{'epoch': 0, 'batch': 902, 'loss': 3.5388519763946533}\n",
            "{'epoch': 0, 'batch': 903, 'loss': 3.2331337928771973}\n",
            "{'epoch': 0, 'batch': 904, 'loss': 3.4833824634552}\n",
            "{'epoch': 0, 'batch': 905, 'loss': 3.4657866954803467}\n",
            "{'epoch': 0, 'batch': 906, 'loss': 3.514324188232422}\n",
            "{'epoch': 0, 'batch': 907, 'loss': 3.4448294639587402}\n",
            "{'epoch': 0, 'batch': 908, 'loss': 3.4515411853790283}\n",
            "{'epoch': 0, 'batch': 909, 'loss': 3.4906368255615234}\n",
            "{'epoch': 0, 'batch': 910, 'loss': 3.4633803367614746}\n",
            "{'epoch': 0, 'batch': 911, 'loss': 3.454869031906128}\n",
            "{'epoch': 0, 'batch': 912, 'loss': 3.372955322265625}\n",
            "{'epoch': 0, 'batch': 913, 'loss': 3.374133348464966}\n",
            "{'epoch': 0, 'batch': 914, 'loss': 3.357456684112549}\n",
            "{'epoch': 0, 'batch': 915, 'loss': 3.255772829055786}\n",
            "{'epoch': 0, 'batch': 916, 'loss': 3.2217185497283936}\n",
            "{'epoch': 0, 'batch': 917, 'loss': 3.530937910079956}\n",
            "{'epoch': 0, 'batch': 918, 'loss': 3.3011856079101562}\n",
            "{'epoch': 0, 'batch': 919, 'loss': 3.0621209144592285}\n",
            "{'epoch': 0, 'batch': 920, 'loss': 3.220862627029419}\n",
            "{'epoch': 0, 'batch': 921, 'loss': 3.27557373046875}\n",
            "{'epoch': 0, 'batch': 922, 'loss': 3.2256579399108887}\n",
            "{'epoch': 0, 'batch': 923, 'loss': 3.1448230743408203}\n",
            "{'epoch': 0, 'batch': 924, 'loss': 3.1457440853118896}\n",
            "{'epoch': 0, 'batch': 925, 'loss': 3.1610541343688965}\n",
            "{'epoch': 0, 'batch': 926, 'loss': 3.3058764934539795}\n",
            "{'epoch': 0, 'batch': 927, 'loss': 2.9977285861968994}\n",
            "{'epoch': 0, 'batch': 928, 'loss': 3.0869522094726562}\n",
            "{'epoch': 0, 'batch': 929, 'loss': 3.446383237838745}\n",
            "{'epoch': 0, 'batch': 930, 'loss': 3.3137125968933105}\n",
            "{'epoch': 0, 'batch': 931, 'loss': 2.9698164463043213}\n",
            "{'epoch': 0, 'batch': 932, 'loss': 3.025111675262451}\n",
            "{'epoch': 0, 'batch': 933, 'loss': 2.843590497970581}\n",
            "{'epoch': 0, 'batch': 934, 'loss': 3.1557154655456543}\n",
            "{'epoch': 0, 'batch': 935, 'loss': 2.814365863800049}\n",
            "{'epoch': 0, 'batch': 936, 'loss': 2.9536263942718506}\n",
            "{'epoch': 0, 'batch': 937, 'loss': 3.1761088371276855}\n",
            "{'epoch': 0, 'batch': 938, 'loss': 3.0763537883758545}\n",
            "{'epoch': 0, 'batch': 939, 'loss': 3.0509793758392334}\n",
            "{'epoch': 0, 'batch': 940, 'loss': 3.4565348625183105}\n",
            "{'epoch': 0, 'batch': 941, 'loss': 3.362877368927002}\n",
            "{'epoch': 0, 'batch': 942, 'loss': 2.931352376937866}\n",
            "{'epoch': 0, 'batch': 943, 'loss': 3.1005988121032715}\n",
            "{'epoch': 0, 'batch': 944, 'loss': 2.993497848510742}\n",
            "{'epoch': 0, 'batch': 945, 'loss': 2.9822325706481934}\n",
            "{'epoch': 0, 'batch': 946, 'loss': 3.1939971446990967}\n",
            "{'epoch': 0, 'batch': 947, 'loss': 3.1162726879119873}\n",
            "{'epoch': 0, 'batch': 948, 'loss': 3.0965514183044434}\n",
            "{'epoch': 0, 'batch': 949, 'loss': 3.3003859519958496}\n",
            "{'epoch': 0, 'batch': 950, 'loss': 3.1887497901916504}\n",
            "{'epoch': 0, 'batch': 951, 'loss': 3.3141093254089355}\n",
            "{'epoch': 0, 'batch': 952, 'loss': 3.020228385925293}\n",
            "{'epoch': 0, 'batch': 953, 'loss': 3.3603172302246094}\n",
            "{'epoch': 0, 'batch': 954, 'loss': 3.184825897216797}\n",
            "{'epoch': 0, 'batch': 955, 'loss': 3.172253131866455}\n",
            "{'epoch': 0, 'batch': 956, 'loss': 3.0282301902770996}\n",
            "{'epoch': 0, 'batch': 957, 'loss': 3.281342029571533}\n",
            "{'epoch': 0, 'batch': 958, 'loss': 3.2640061378479004}\n",
            "{'epoch': 0, 'batch': 959, 'loss': 3.0002033710479736}\n",
            "{'epoch': 0, 'batch': 960, 'loss': 2.8883020877838135}\n",
            "{'epoch': 0, 'batch': 961, 'loss': 3.3696799278259277}\n",
            "{'epoch': 0, 'batch': 962, 'loss': 2.926640748977661}\n",
            "{'epoch': 0, 'batch': 963, 'loss': 3.0263912677764893}\n",
            "{'epoch': 0, 'batch': 964, 'loss': 2.9203362464904785}\n",
            "{'epoch': 0, 'batch': 965, 'loss': 3.1221601963043213}\n",
            "{'epoch': 0, 'batch': 966, 'loss': 3.057285785675049}\n",
            "{'epoch': 0, 'batch': 967, 'loss': 3.2901291847229004}\n",
            "{'epoch': 0, 'batch': 968, 'loss': 3.345332622528076}\n",
            "{'epoch': 0, 'batch': 969, 'loss': 3.2675375938415527}\n",
            "{'epoch': 0, 'batch': 970, 'loss': 3.2004592418670654}\n",
            "{'epoch': 0, 'batch': 971, 'loss': 3.1772618293762207}\n",
            "{'epoch': 0, 'batch': 972, 'loss': 2.7710554599761963}\n",
            "{'epoch': 0, 'batch': 973, 'loss': 2.96966552734375}\n",
            "{'epoch': 0, 'batch': 974, 'loss': 3.189882278442383}\n",
            "{'epoch': 0, 'batch': 975, 'loss': 2.8742828369140625}\n",
            "{'epoch': 0, 'batch': 976, 'loss': 3.2745566368103027}\n",
            "{'epoch': 0, 'batch': 977, 'loss': 3.3318400382995605}\n",
            "{'epoch': 0, 'batch': 978, 'loss': 3.6067728996276855}\n",
            "{'epoch': 0, 'batch': 979, 'loss': 3.0921518802642822}\n",
            "{'epoch': 0, 'batch': 980, 'loss': 3.305558681488037}\n",
            "{'epoch': 0, 'batch': 981, 'loss': 3.1249542236328125}\n",
            "{'epoch': 0, 'batch': 982, 'loss': 3.0180559158325195}\n",
            "{'epoch': 0, 'batch': 983, 'loss': 3.1211791038513184}\n",
            "{'epoch': 0, 'batch': 984, 'loss': 3.1290712356567383}\n",
            "{'epoch': 0, 'batch': 985, 'loss': 3.138946771621704}\n",
            "{'epoch': 0, 'batch': 986, 'loss': 3.316066026687622}\n",
            "{'epoch': 0, 'batch': 987, 'loss': 3.3823981285095215}\n",
            "{'epoch': 0, 'batch': 988, 'loss': 3.372997760772705}\n",
            "{'epoch': 0, 'batch': 989, 'loss': 3.359218120574951}\n",
            "{'epoch': 0, 'batch': 990, 'loss': 3.155391216278076}\n",
            "{'epoch': 0, 'batch': 991, 'loss': 3.2011260986328125}\n",
            "{'epoch': 0, 'batch': 992, 'loss': 3.3276290893554688}\n",
            "{'epoch': 0, 'batch': 993, 'loss': 3.113386631011963}\n",
            "{'epoch': 0, 'batch': 994, 'loss': 3.182631015777588}\n",
            "{'epoch': 0, 'batch': 995, 'loss': 3.2680516242980957}\n",
            "{'epoch': 0, 'batch': 996, 'loss': 3.1603033542633057}\n",
            "{'epoch': 0, 'batch': 997, 'loss': 3.1706643104553223}\n",
            "{'epoch': 0, 'batch': 998, 'loss': 3.007626533508301}\n",
            "{'epoch': 0, 'batch': 999, 'loss': 3.190300941467285}\n",
            "{'epoch': 0, 'batch': 1000, 'loss': 3.054542064666748}\n",
            "{'epoch': 0, 'batch': 1001, 'loss': 3.19148850440979}\n",
            "{'epoch': 0, 'batch': 1002, 'loss': 3.3013503551483154}\n",
            "{'epoch': 0, 'batch': 1003, 'loss': 3.2611191272735596}\n",
            "{'epoch': 0, 'batch': 1004, 'loss': 3.1822171211242676}\n",
            "{'epoch': 0, 'batch': 1005, 'loss': 2.9158170223236084}\n",
            "{'epoch': 0, 'batch': 1006, 'loss': 3.04767107963562}\n",
            "{'epoch': 0, 'batch': 1007, 'loss': 3.183469533920288}\n",
            "{'epoch': 0, 'batch': 1008, 'loss': 3.579469680786133}\n",
            "{'epoch': 0, 'batch': 1009, 'loss': 3.3249351978302}\n",
            "{'epoch': 0, 'batch': 1010, 'loss': 3.497671127319336}\n",
            "{'epoch': 0, 'batch': 1011, 'loss': 3.1772608757019043}\n",
            "{'epoch': 0, 'batch': 1012, 'loss': 3.169471263885498}\n",
            "{'epoch': 0, 'batch': 1013, 'loss': 2.8195931911468506}\n",
            "{'epoch': 0, 'batch': 1014, 'loss': 3.0553841590881348}\n",
            "{'epoch': 0, 'batch': 1015, 'loss': 2.873260021209717}\n",
            "{'epoch': 0, 'batch': 1016, 'loss': 3.048398971557617}\n",
            "{'epoch': 0, 'batch': 1017, 'loss': 3.0798988342285156}\n",
            "{'epoch': 0, 'batch': 1018, 'loss': 3.1395645141601562}\n",
            "{'epoch': 0, 'batch': 1019, 'loss': 3.0699963569641113}\n",
            "{'epoch': 0, 'batch': 1020, 'loss': 3.113646984100342}\n",
            "{'epoch': 0, 'batch': 1021, 'loss': 3.1351959705352783}\n",
            "{'epoch': 0, 'batch': 1022, 'loss': 3.325482130050659}\n",
            "{'epoch': 0, 'batch': 1023, 'loss': 3.2552413940429688}\n",
            "{'epoch': 0, 'batch': 1024, 'loss': 3.1549458503723145}\n",
            "{'epoch': 0, 'batch': 1025, 'loss': 2.799860715866089}\n",
            "{'epoch': 0, 'batch': 1026, 'loss': 3.129335880279541}\n",
            "{'epoch': 0, 'batch': 1027, 'loss': 3.171572208404541}\n",
            "{'epoch': 0, 'batch': 1028, 'loss': 3.4994168281555176}\n",
            "{'epoch': 0, 'batch': 1029, 'loss': 3.4569485187530518}\n",
            "{'epoch': 0, 'batch': 1030, 'loss': 3.3195080757141113}\n",
            "{'epoch': 0, 'batch': 1031, 'loss': 3.2310078144073486}\n",
            "{'epoch': 0, 'batch': 1032, 'loss': 3.0757765769958496}\n",
            "{'epoch': 0, 'batch': 1033, 'loss': 3.285719633102417}\n",
            "{'epoch': 0, 'batch': 1034, 'loss': 3.6453728675842285}\n",
            "{'epoch': 0, 'batch': 1035, 'loss': 3.1414530277252197}\n",
            "{'epoch': 0, 'batch': 1036, 'loss': 3.474219799041748}\n",
            "{'epoch': 0, 'batch': 1037, 'loss': 3.370800495147705}\n",
            "{'epoch': 0, 'batch': 1038, 'loss': 3.3583598136901855}\n",
            "{'epoch': 0, 'batch': 1039, 'loss': 3.319817304611206}\n",
            "{'epoch': 0, 'batch': 1040, 'loss': 2.943272829055786}\n",
            "{'epoch': 0, 'batch': 1041, 'loss': 3.1972153186798096}\n",
            "{'epoch': 0, 'batch': 1042, 'loss': 3.2181363105773926}\n",
            "{'epoch': 0, 'batch': 1043, 'loss': 3.0746004581451416}\n",
            "{'epoch': 0, 'batch': 1044, 'loss': 3.194709539413452}\n",
            "{'epoch': 0, 'batch': 1045, 'loss': 3.1137328147888184}\n",
            "{'epoch': 0, 'batch': 1046, 'loss': 3.068523406982422}\n",
            "{'epoch': 0, 'batch': 1047, 'loss': 3.074125289916992}\n",
            "{'epoch': 0, 'batch': 1048, 'loss': 3.2465243339538574}\n",
            "{'epoch': 0, 'batch': 1049, 'loss': 3.1128454208374023}\n",
            "{'epoch': 0, 'batch': 1050, 'loss': 2.969965696334839}\n",
            "{'epoch': 0, 'batch': 1051, 'loss': 3.2643113136291504}\n",
            "{'epoch': 0, 'batch': 1052, 'loss': 2.9317829608917236}\n",
            "{'epoch': 0, 'batch': 1053, 'loss': 3.269998073577881}\n",
            "{'epoch': 0, 'batch': 1054, 'loss': 3.097778797149658}\n",
            "{'epoch': 0, 'batch': 1055, 'loss': 3.0585713386535645}\n",
            "{'epoch': 0, 'batch': 1056, 'loss': 3.1341919898986816}\n",
            "{'epoch': 0, 'batch': 1057, 'loss': 3.441718339920044}\n",
            "{'epoch': 0, 'batch': 1058, 'loss': 3.183763027191162}\n",
            "{'epoch': 0, 'batch': 1059, 'loss': 3.1235737800598145}\n",
            "{'epoch': 0, 'batch': 1060, 'loss': 2.948380947113037}\n",
            "{'epoch': 0, 'batch': 1061, 'loss': 2.9608731269836426}\n",
            "{'epoch': 0, 'batch': 1062, 'loss': 3.143479824066162}\n",
            "{'epoch': 0, 'batch': 1063, 'loss': 3.162273406982422}\n",
            "{'epoch': 0, 'batch': 1064, 'loss': 3.1944596767425537}\n",
            "{'epoch': 0, 'batch': 1065, 'loss': 2.874009370803833}\n",
            "{'epoch': 0, 'batch': 1066, 'loss': 2.9412856101989746}\n",
            "{'epoch': 0, 'batch': 1067, 'loss': 3.3451266288757324}\n",
            "{'epoch': 0, 'batch': 1068, 'loss': 2.886465311050415}\n",
            "{'epoch': 0, 'batch': 1069, 'loss': 3.0162394046783447}\n",
            "{'epoch': 0, 'batch': 1070, 'loss': 3.1847329139709473}\n",
            "{'epoch': 0, 'batch': 1071, 'loss': 3.1066222190856934}\n",
            "{'epoch': 0, 'batch': 1072, 'loss': 3.122560739517212}\n",
            "{'epoch': 0, 'batch': 1073, 'loss': 2.9128670692443848}\n",
            "{'epoch': 0, 'batch': 1074, 'loss': 3.0316121578216553}\n",
            "{'epoch': 0, 'batch': 1075, 'loss': 3.0223724842071533}\n",
            "{'epoch': 0, 'batch': 1076, 'loss': 3.3205127716064453}\n",
            "{'epoch': 0, 'batch': 1077, 'loss': 3.2402985095977783}\n",
            "{'epoch': 0, 'batch': 1078, 'loss': 3.2113099098205566}\n",
            "{'epoch': 0, 'batch': 1079, 'loss': 3.1488804817199707}\n",
            "{'epoch': 0, 'batch': 1080, 'loss': 3.1914870738983154}\n",
            "{'epoch': 0, 'batch': 1081, 'loss': 3.129178285598755}\n",
            "{'epoch': 0, 'batch': 1082, 'loss': 3.253155469894409}\n",
            "{'epoch': 0, 'batch': 1083, 'loss': 3.2101492881774902}\n",
            "{'epoch': 0, 'batch': 1084, 'loss': 3.1641364097595215}\n",
            "{'epoch': 0, 'batch': 1085, 'loss': 3.0201783180236816}\n",
            "{'epoch': 0, 'batch': 1086, 'loss': 3.3998425006866455}\n",
            "{'epoch': 0, 'batch': 1087, 'loss': 3.132394313812256}\n",
            "{'epoch': 0, 'batch': 1088, 'loss': 2.9382615089416504}\n",
            "{'epoch': 0, 'batch': 1089, 'loss': 3.2269420623779297}\n",
            "{'epoch': 0, 'batch': 1090, 'loss': 3.329354763031006}\n",
            "{'epoch': 0, 'batch': 1091, 'loss': 3.266035556793213}\n",
            "{'epoch': 0, 'batch': 1092, 'loss': 3.4041755199432373}\n",
            "{'epoch': 0, 'batch': 1093, 'loss': 3.025928020477295}\n",
            "{'epoch': 0, 'batch': 1094, 'loss': 3.3348183631896973}\n",
            "{'epoch': 0, 'batch': 1095, 'loss': 3.2992446422576904}\n",
            "{'epoch': 0, 'batch': 1096, 'loss': 3.364396333694458}\n",
            "{'epoch': 0, 'batch': 1097, 'loss': 2.9817821979522705}\n",
            "{'epoch': 0, 'batch': 1098, 'loss': 3.056260347366333}\n",
            "{'epoch': 0, 'batch': 1099, 'loss': 3.3760948181152344}\n",
            "{'epoch': 0, 'batch': 1100, 'loss': 3.3149571418762207}\n",
            "{'epoch': 0, 'batch': 1101, 'loss': 3.053349494934082}\n",
            "{'epoch': 0, 'batch': 1102, 'loss': 3.1755568981170654}\n",
            "{'epoch': 0, 'batch': 1103, 'loss': 2.828451633453369}\n",
            "{'epoch': 0, 'batch': 1104, 'loss': 3.3528683185577393}\n",
            "{'epoch': 0, 'batch': 1105, 'loss': 3.30071759223938}\n",
            "{'epoch': 0, 'batch': 1106, 'loss': 3.430939197540283}\n",
            "{'epoch': 0, 'batch': 1107, 'loss': 3.5476112365722656}\n",
            "{'epoch': 0, 'batch': 1108, 'loss': 3.4670498371124268}\n",
            "{'epoch': 0, 'batch': 1109, 'loss': 3.4708220958709717}\n",
            "{'epoch': 0, 'batch': 1110, 'loss': 3.3764915466308594}\n",
            "{'epoch': 0, 'batch': 1111, 'loss': 2.9273717403411865}\n",
            "{'epoch': 0, 'batch': 1112, 'loss': 3.177781343460083}\n",
            "{'epoch': 0, 'batch': 1113, 'loss': 2.9807028770446777}\n",
            "{'epoch': 0, 'batch': 1114, 'loss': 3.064771890640259}\n",
            "{'epoch': 0, 'batch': 1115, 'loss': 3.023637056350708}\n",
            "{'epoch': 0, 'batch': 1116, 'loss': 3.228724718093872}\n",
            "{'epoch': 0, 'batch': 1117, 'loss': 3.4829940795898438}\n",
            "{'epoch': 0, 'batch': 1118, 'loss': 3.0220985412597656}\n",
            "{'epoch': 0, 'batch': 1119, 'loss': 3.1034934520721436}\n",
            "{'epoch': 0, 'batch': 1120, 'loss': 3.1201517581939697}\n",
            "{'epoch': 0, 'batch': 1121, 'loss': 3.2817516326904297}\n",
            "{'epoch': 0, 'batch': 1122, 'loss': 3.0048398971557617}\n",
            "{'epoch': 0, 'batch': 1123, 'loss': 2.9960246086120605}\n",
            "{'epoch': 0, 'batch': 1124, 'loss': 2.9260189533233643}\n",
            "{'epoch': 0, 'batch': 1125, 'loss': 3.361032485961914}\n",
            "{'epoch': 0, 'batch': 1126, 'loss': 3.1274914741516113}\n",
            "{'epoch': 0, 'batch': 1127, 'loss': 3.2818989753723145}\n",
            "{'epoch': 0, 'batch': 1128, 'loss': 3.136739492416382}\n",
            "{'epoch': 0, 'batch': 1129, 'loss': 3.0390236377716064}\n",
            "{'epoch': 0, 'batch': 1130, 'loss': 3.2209677696228027}\n",
            "{'epoch': 0, 'batch': 1131, 'loss': 3.2804038524627686}\n",
            "{'epoch': 0, 'batch': 1132, 'loss': 2.9981191158294678}\n",
            "{'epoch': 0, 'batch': 1133, 'loss': 3.279996395111084}\n",
            "{'epoch': 0, 'batch': 1134, 'loss': 3.303419589996338}\n",
            "{'epoch': 0, 'batch': 1135, 'loss': 3.2612392902374268}\n",
            "{'epoch': 0, 'batch': 1136, 'loss': 3.1155154705047607}\n",
            "{'epoch': 0, 'batch': 1137, 'loss': 3.1137118339538574}\n",
            "{'epoch': 0, 'batch': 1138, 'loss': 2.9584507942199707}\n",
            "{'epoch': 0, 'batch': 1139, 'loss': 3.3923542499542236}\n",
            "{'epoch': 0, 'batch': 1140, 'loss': 3.235046863555908}\n",
            "{'epoch': 0, 'batch': 1141, 'loss': 3.2031733989715576}\n",
            "{'epoch': 0, 'batch': 1142, 'loss': 3.0511927604675293}\n",
            "{'epoch': 0, 'batch': 1143, 'loss': 2.9387407302856445}\n",
            "{'epoch': 0, 'batch': 1144, 'loss': 3.338160753250122}\n",
            "{'epoch': 0, 'batch': 1145, 'loss': 2.685241937637329}\n",
            "{'epoch': 0, 'batch': 1146, 'loss': 2.8304429054260254}\n",
            "{'epoch': 0, 'batch': 1147, 'loss': 2.9607129096984863}\n",
            "{'epoch': 0, 'batch': 1148, 'loss': 2.9116718769073486}\n",
            "{'epoch': 0, 'batch': 1149, 'loss': 2.782963275909424}\n",
            "{'epoch': 0, 'batch': 1150, 'loss': 3.1121950149536133}\n",
            "{'epoch': 0, 'batch': 1151, 'loss': 3.0530316829681396}\n",
            "{'epoch': 0, 'batch': 1152, 'loss': 3.0194616317749023}\n",
            "{'epoch': 0, 'batch': 1153, 'loss': 3.2281901836395264}\n",
            "{'epoch': 0, 'batch': 1154, 'loss': 3.177706003189087}\n",
            "{'epoch': 0, 'batch': 1155, 'loss': 3.239983320236206}\n",
            "{'epoch': 0, 'batch': 1156, 'loss': 2.9635045528411865}\n",
            "{'epoch': 0, 'batch': 1157, 'loss': 3.1738009452819824}\n",
            "{'epoch': 0, 'batch': 1158, 'loss': 2.9460604190826416}\n",
            "{'epoch': 0, 'batch': 1159, 'loss': 3.120283603668213}\n",
            "{'epoch': 0, 'batch': 1160, 'loss': 3.1733169555664062}\n",
            "{'epoch': 0, 'batch': 1161, 'loss': 3.2893404960632324}\n",
            "{'epoch': 0, 'batch': 1162, 'loss': 3.3464298248291016}\n",
            "{'epoch': 0, 'batch': 1163, 'loss': 3.1674325466156006}\n",
            "{'epoch': 0, 'batch': 1164, 'loss': 3.153238534927368}\n",
            "{'epoch': 0, 'batch': 1165, 'loss': 3.230710506439209}\n",
            "{'epoch': 0, 'batch': 1166, 'loss': 3.2365260124206543}\n",
            "{'epoch': 0, 'batch': 1167, 'loss': 3.021671772003174}\n",
            "{'epoch': 0, 'batch': 1168, 'loss': 2.952446937561035}\n",
            "{'epoch': 0, 'batch': 1169, 'loss': 3.3276054859161377}\n",
            "{'epoch': 0, 'batch': 1170, 'loss': 3.290959596633911}\n",
            "{'epoch': 0, 'batch': 1171, 'loss': 3.388371229171753}\n",
            "{'epoch': 0, 'batch': 1172, 'loss': 3.1744933128356934}\n",
            "{'epoch': 0, 'batch': 1173, 'loss': 3.4498181343078613}\n",
            "{'epoch': 0, 'batch': 1174, 'loss': 3.428419589996338}\n",
            "{'epoch': 0, 'batch': 1175, 'loss': 3.2553932666778564}\n",
            "{'epoch': 0, 'batch': 1176, 'loss': 3.022583246231079}\n",
            "{'epoch': 0, 'batch': 1177, 'loss': 3.50475811958313}\n",
            "{'epoch': 0, 'batch': 1178, 'loss': 3.028350591659546}\n",
            "{'epoch': 0, 'batch': 1179, 'loss': 3.135537624359131}\n",
            "{'epoch': 0, 'batch': 1180, 'loss': 2.8930723667144775}\n",
            "{'epoch': 0, 'batch': 1181, 'loss': 3.041811466217041}\n",
            "{'epoch': 0, 'batch': 1182, 'loss': 3.27508282661438}\n",
            "{'epoch': 0, 'batch': 1183, 'loss': 3.34649395942688}\n",
            "{'epoch': 0, 'batch': 1184, 'loss': 3.34771728515625}\n",
            "{'epoch': 0, 'batch': 1185, 'loss': 3.2580418586730957}\n",
            "{'epoch': 0, 'batch': 1186, 'loss': 3.158399820327759}\n",
            "{'epoch': 0, 'batch': 1187, 'loss': 3.192552089691162}\n",
            "{'epoch': 0, 'batch': 1188, 'loss': 2.9936091899871826}\n",
            "{'epoch': 0, 'batch': 1189, 'loss': 3.13761305809021}\n",
            "{'epoch': 0, 'batch': 1190, 'loss': 3.0763232707977295}\n",
            "{'epoch': 0, 'batch': 1191, 'loss': 3.2466022968292236}\n",
            "{'epoch': 0, 'batch': 1192, 'loss': 3.2608330249786377}\n",
            "{'epoch': 0, 'batch': 1193, 'loss': 3.050849437713623}\n",
            "{'epoch': 0, 'batch': 1194, 'loss': 3.2552542686462402}\n",
            "{'epoch': 0, 'batch': 1195, 'loss': 2.9493870735168457}\n",
            "{'epoch': 0, 'batch': 1196, 'loss': 2.881230115890503}\n",
            "{'epoch': 0, 'batch': 1197, 'loss': 2.8765029907226562}\n",
            "{'epoch': 0, 'batch': 1198, 'loss': 3.0391993522644043}\n",
            "{'epoch': 0, 'batch': 1199, 'loss': 3.0241858959198}\n",
            "{'epoch': 0, 'batch': 1200, 'loss': 3.1293749809265137}\n",
            "{'epoch': 0, 'batch': 1201, 'loss': 3.1485049724578857}\n",
            "{'epoch': 0, 'batch': 1202, 'loss': 3.260246992111206}\n",
            "{'epoch': 0, 'batch': 1203, 'loss': 3.022854804992676}\n",
            "{'epoch': 0, 'batch': 1204, 'loss': 2.8216938972473145}\n",
            "{'epoch': 0, 'batch': 1205, 'loss': 3.2804832458496094}\n",
            "{'epoch': 0, 'batch': 1206, 'loss': 3.1925313472747803}\n",
            "{'epoch': 0, 'batch': 1207, 'loss': 2.8599483966827393}\n",
            "{'epoch': 0, 'batch': 1208, 'loss': 3.0379440784454346}\n",
            "{'epoch': 0, 'batch': 1209, 'loss': 3.0891005992889404}\n",
            "{'epoch': 0, 'batch': 1210, 'loss': 3.026590585708618}\n",
            "{'epoch': 0, 'batch': 1211, 'loss': 3.169084072113037}\n",
            "{'epoch': 0, 'batch': 1212, 'loss': 2.8628287315368652}\n",
            "{'epoch': 0, 'batch': 1213, 'loss': 3.0061373710632324}\n",
            "{'epoch': 0, 'batch': 1214, 'loss': 3.025465488433838}\n",
            "{'epoch': 0, 'batch': 1215, 'loss': 3.6214592456817627}\n",
            "{'epoch': 0, 'batch': 1216, 'loss': 3.140277147293091}\n",
            "{'epoch': 0, 'batch': 1217, 'loss': 2.832489013671875}\n",
            "{'epoch': 0, 'batch': 1218, 'loss': 2.842522144317627}\n",
            "{'epoch': 0, 'batch': 1219, 'loss': 2.815612316131592}\n",
            "{'epoch': 0, 'batch': 1220, 'loss': 3.128812789916992}\n",
            "{'epoch': 0, 'batch': 1221, 'loss': 3.0457568168640137}\n",
            "{'epoch': 0, 'batch': 1222, 'loss': 3.0733754634857178}\n",
            "{'epoch': 0, 'batch': 1223, 'loss': 3.21362566947937}\n",
            "{'epoch': 0, 'batch': 1224, 'loss': 3.046607494354248}\n",
            "{'epoch': 0, 'batch': 1225, 'loss': 3.1494405269622803}\n",
            "{'epoch': 0, 'batch': 1226, 'loss': 3.261704683303833}\n",
            "{'epoch': 0, 'batch': 1227, 'loss': 3.212223768234253}\n",
            "{'epoch': 0, 'batch': 1228, 'loss': 3.360551118850708}\n",
            "{'epoch': 0, 'batch': 1229, 'loss': 3.3550541400909424}\n",
            "{'epoch': 0, 'batch': 1230, 'loss': 3.3930294513702393}\n",
            "{'epoch': 0, 'batch': 1231, 'loss': 3.3056321144104004}\n",
            "{'epoch': 0, 'batch': 1232, 'loss': 3.154818534851074}\n",
            "{'epoch': 0, 'batch': 1233, 'loss': 3.3609180450439453}\n",
            "{'epoch': 0, 'batch': 1234, 'loss': 3.054332733154297}\n",
            "{'epoch': 0, 'batch': 1235, 'loss': 3.137578248977661}\n",
            "{'epoch': 0, 'batch': 1236, 'loss': 3.0773186683654785}\n",
            "{'epoch': 0, 'batch': 1237, 'loss': 2.6353845596313477}\n",
            "{'epoch': 0, 'batch': 1238, 'loss': 2.7966959476470947}\n",
            "{'epoch': 0, 'batch': 1239, 'loss': 2.9657070636749268}\n",
            "{'epoch': 0, 'batch': 1240, 'loss': 3.3697993755340576}\n",
            "{'epoch': 0, 'batch': 1241, 'loss': 3.0262484550476074}\n",
            "{'epoch': 0, 'batch': 1242, 'loss': 2.905384063720703}\n",
            "{'epoch': 0, 'batch': 1243, 'loss': 3.227167844772339}\n",
            "{'epoch': 0, 'batch': 1244, 'loss': 3.2018275260925293}\n",
            "{'epoch': 0, 'batch': 1245, 'loss': 2.953448534011841}\n",
            "{'epoch': 0, 'batch': 1246, 'loss': 2.9290552139282227}\n",
            "{'epoch': 0, 'batch': 1247, 'loss': 3.1421709060668945}\n",
            "{'epoch': 0, 'batch': 1248, 'loss': 3.2159667015075684}\n",
            "{'epoch': 0, 'batch': 1249, 'loss': 2.9033169746398926}\n",
            "{'epoch': 0, 'batch': 1250, 'loss': 2.95279860496521}\n",
            "{'epoch': 0, 'batch': 1251, 'loss': 3.0882372856140137}\n",
            "{'epoch': 0, 'batch': 1252, 'loss': 3.1740803718566895}\n",
            "{'epoch': 0, 'batch': 1253, 'loss': 3.110450029373169}\n",
            "{'epoch': 0, 'batch': 1254, 'loss': 3.2388076782226562}\n",
            "{'epoch': 0, 'batch': 1255, 'loss': 3.1793415546417236}\n",
            "{'epoch': 0, 'batch': 1256, 'loss': 3.1109426021575928}\n",
            "{'epoch': 0, 'batch': 1257, 'loss': 3.153783082962036}\n",
            "{'epoch': 0, 'batch': 1258, 'loss': 3.010162353515625}\n",
            "{'epoch': 0, 'batch': 1259, 'loss': 3.004913091659546}\n",
            "{'epoch': 0, 'batch': 1260, 'loss': 3.171252727508545}\n",
            "{'epoch': 0, 'batch': 1261, 'loss': 3.2513504028320312}\n",
            "{'epoch': 0, 'batch': 1262, 'loss': 2.7427268028259277}\n",
            "{'epoch': 0, 'batch': 1263, 'loss': 2.8737568855285645}\n",
            "{'epoch': 0, 'batch': 1264, 'loss': 3.0893232822418213}\n",
            "{'epoch': 0, 'batch': 1265, 'loss': 3.1450843811035156}\n",
            "{'epoch': 0, 'batch': 1266, 'loss': 2.9496874809265137}\n",
            "{'epoch': 0, 'batch': 1267, 'loss': 3.2585361003875732}\n",
            "{'epoch': 0, 'batch': 1268, 'loss': 3.060518503189087}\n",
            "{'epoch': 0, 'batch': 1269, 'loss': 3.3145790100097656}\n",
            "{'epoch': 0, 'batch': 1270, 'loss': 3.237546920776367}\n",
            "{'epoch': 0, 'batch': 1271, 'loss': 2.877704381942749}\n",
            "{'epoch': 0, 'batch': 1272, 'loss': 3.293067216873169}\n",
            "{'epoch': 0, 'batch': 1273, 'loss': 3.2262375354766846}\n",
            "{'epoch': 0, 'batch': 1274, 'loss': 3.372166872024536}\n",
            "{'epoch': 0, 'batch': 1275, 'loss': 3.211956024169922}\n",
            "{'epoch': 0, 'batch': 1276, 'loss': 3.1121304035186768}\n",
            "{'epoch': 0, 'batch': 1277, 'loss': 3.3905105590820312}\n",
            "{'epoch': 0, 'batch': 1278, 'loss': 3.2853646278381348}\n",
            "{'epoch': 0, 'batch': 1279, 'loss': 3.0735175609588623}\n",
            "{'epoch': 0, 'batch': 1280, 'loss': 3.2701416015625}\n",
            "{'epoch': 0, 'batch': 1281, 'loss': 2.9700121879577637}\n",
            "{'epoch': 0, 'batch': 1282, 'loss': 3.138265371322632}\n",
            "{'epoch': 0, 'batch': 1283, 'loss': 3.271315097808838}\n",
            "{'epoch': 0, 'batch': 1284, 'loss': 3.2808563709259033}\n",
            "{'epoch': 0, 'batch': 1285, 'loss': 3.054572343826294}\n",
            "{'epoch': 0, 'batch': 1286, 'loss': 3.316873073577881}\n",
            "{'epoch': 0, 'batch': 1287, 'loss': 3.001650333404541}\n",
            "{'epoch': 0, 'batch': 1288, 'loss': 3.3729472160339355}\n",
            "{'epoch': 0, 'batch': 1289, 'loss': 3.442676544189453}\n",
            "{'epoch': 0, 'batch': 1290, 'loss': 3.187124013900757}\n",
            "{'epoch': 0, 'batch': 1291, 'loss': 3.073615789413452}\n",
            "{'epoch': 0, 'batch': 1292, 'loss': 3.3573620319366455}\n",
            "{'epoch': 0, 'batch': 1293, 'loss': 3.160611629486084}\n",
            "{'epoch': 0, 'batch': 1294, 'loss': 3.076152801513672}\n",
            "{'epoch': 0, 'batch': 1295, 'loss': 3.5288498401641846}\n",
            "{'epoch': 0, 'batch': 1296, 'loss': 3.116885185241699}\n",
            "{'epoch': 0, 'batch': 1297, 'loss': 3.3054022789001465}\n",
            "{'epoch': 0, 'batch': 1298, 'loss': 3.2287139892578125}\n",
            "{'epoch': 0, 'batch': 1299, 'loss': 2.886497974395752}\n",
            "{'epoch': 0, 'batch': 1300, 'loss': 2.8728253841400146}\n",
            "{'epoch': 0, 'batch': 1301, 'loss': 3.103907585144043}\n",
            "{'epoch': 0, 'batch': 1302, 'loss': 3.2067997455596924}\n",
            "{'epoch': 0, 'batch': 1303, 'loss': 3.2470688819885254}\n",
            "{'epoch': 0, 'batch': 1304, 'loss': 3.097229480743408}\n",
            "{'epoch': 0, 'batch': 1305, 'loss': 3.301922559738159}\n",
            "{'epoch': 0, 'batch': 1306, 'loss': 3.382451295852661}\n",
            "{'epoch': 0, 'batch': 1307, 'loss': 3.1475374698638916}\n",
            "{'epoch': 0, 'batch': 1308, 'loss': 3.338120698928833}\n",
            "{'epoch': 0, 'batch': 1309, 'loss': 3.0643439292907715}\n",
            "{'epoch': 0, 'batch': 1310, 'loss': 3.33166766166687}\n",
            "{'epoch': 0, 'batch': 1311, 'loss': 2.8866355419158936}\n",
            "{'epoch': 0, 'batch': 1312, 'loss': 3.0539958477020264}\n",
            "{'epoch': 0, 'batch': 1313, 'loss': 3.0592589378356934}\n",
            "{'epoch': 0, 'batch': 1314, 'loss': 3.135258436203003}\n",
            "{'epoch': 0, 'batch': 1315, 'loss': 3.0367484092712402}\n",
            "{'epoch': 0, 'batch': 1316, 'loss': 3.2851364612579346}\n",
            "{'epoch': 0, 'batch': 1317, 'loss': 2.9968323707580566}\n",
            "{'epoch': 0, 'batch': 1318, 'loss': 3.0966100692749023}\n",
            "{'epoch': 0, 'batch': 1319, 'loss': 2.857924461364746}\n",
            "{'epoch': 0, 'batch': 1320, 'loss': 2.8700520992279053}\n",
            "{'epoch': 0, 'batch': 1321, 'loss': 2.6435489654541016}\n",
            "{'epoch': 0, 'batch': 1322, 'loss': 3.2679595947265625}\n",
            "{'epoch': 0, 'batch': 1323, 'loss': 2.9557089805603027}\n",
            "{'epoch': 0, 'batch': 1324, 'loss': 2.8588473796844482}\n",
            "{'epoch': 0, 'batch': 1325, 'loss': 2.8685290813446045}\n",
            "{'epoch': 0, 'batch': 1326, 'loss': 2.9121456146240234}\n",
            "{'epoch': 0, 'batch': 1327, 'loss': 3.0757663249969482}\n",
            "{'epoch': 0, 'batch': 1328, 'loss': 2.819502353668213}\n",
            "{'epoch': 0, 'batch': 1329, 'loss': 3.1574342250823975}\n",
            "{'epoch': 0, 'batch': 1330, 'loss': 3.586658477783203}\n",
            "{'epoch': 0, 'batch': 1331, 'loss': 3.6887474060058594}\n",
            "{'epoch': 0, 'batch': 1332, 'loss': 3.4941916465759277}\n",
            "{'epoch': 0, 'batch': 1333, 'loss': 3.550502300262451}\n",
            "{'epoch': 0, 'batch': 1334, 'loss': 3.519411563873291}\n",
            "{'epoch': 0, 'batch': 1335, 'loss': 3.385606050491333}\n",
            "{'epoch': 0, 'batch': 1336, 'loss': 3.4600181579589844}\n",
            "{'epoch': 0, 'batch': 1337, 'loss': 3.5011162757873535}\n",
            "{'epoch': 0, 'batch': 1338, 'loss': 3.5451457500457764}\n",
            "{'epoch': 0, 'batch': 1339, 'loss': 3.442286729812622}\n",
            "{'epoch': 0, 'batch': 1340, 'loss': 3.3398005962371826}\n",
            "{'epoch': 0, 'batch': 1341, 'loss': 3.540790557861328}\n",
            "{'epoch': 0, 'batch': 1342, 'loss': 3.366150379180908}\n",
            "{'epoch': 0, 'batch': 1343, 'loss': 3.4199771881103516}\n",
            "{'epoch': 0, 'batch': 1344, 'loss': 3.118770122528076}\n",
            "{'epoch': 0, 'batch': 1345, 'loss': 3.334362745285034}\n",
            "{'epoch': 0, 'batch': 1346, 'loss': 3.2477221488952637}\n",
            "{'epoch': 0, 'batch': 1347, 'loss': 3.4708595275878906}\n",
            "{'epoch': 0, 'batch': 1348, 'loss': 3.533510208129883}\n",
            "{'epoch': 0, 'batch': 1349, 'loss': 3.5074286460876465}\n",
            "{'epoch': 0, 'batch': 1350, 'loss': 3.6705849170684814}\n",
            "{'epoch': 0, 'batch': 1351, 'loss': 3.4557571411132812}\n",
            "{'epoch': 0, 'batch': 1352, 'loss': 3.402941942214966}\n",
            "{'epoch': 0, 'batch': 1353, 'loss': 3.2831242084503174}\n",
            "{'epoch': 0, 'batch': 1354, 'loss': 3.2221016883850098}\n",
            "{'epoch': 0, 'batch': 1355, 'loss': 3.4207069873809814}\n",
            "{'epoch': 0, 'batch': 1356, 'loss': 3.3505139350891113}\n",
            "{'epoch': 0, 'batch': 1357, 'loss': 3.4511616230010986}\n",
            "{'epoch': 0, 'batch': 1358, 'loss': 3.2967216968536377}\n",
            "{'epoch': 0, 'batch': 1359, 'loss': 3.004849910736084}\n",
            "{'epoch': 0, 'batch': 1360, 'loss': 3.079103946685791}\n",
            "{'epoch': 0, 'batch': 1361, 'loss': 3.540337324142456}\n",
            "{'epoch': 0, 'batch': 1362, 'loss': 3.0485763549804688}\n",
            "{'epoch': 0, 'batch': 1363, 'loss': 3.2628257274627686}\n",
            "{'epoch': 0, 'batch': 1364, 'loss': 3.032036066055298}\n",
            "{'epoch': 0, 'batch': 1365, 'loss': 3.3616092205047607}\n",
            "{'epoch': 0, 'batch': 1366, 'loss': 3.232271909713745}\n",
            "{'epoch': 0, 'batch': 1367, 'loss': 3.3957912921905518}\n",
            "{'epoch': 0, 'batch': 1368, 'loss': 3.160696506500244}\n",
            "{'epoch': 0, 'batch': 1369, 'loss': 3.299100875854492}\n",
            "{'epoch': 0, 'batch': 1370, 'loss': 3.2649712562561035}\n",
            "{'epoch': 0, 'batch': 1371, 'loss': 3.2921881675720215}\n",
            "{'epoch': 0, 'batch': 1372, 'loss': 3.065868854522705}\n",
            "{'epoch': 0, 'batch': 1373, 'loss': 3.1867153644561768}\n",
            "{'epoch': 0, 'batch': 1374, 'loss': 3.2308990955352783}\n",
            "{'epoch': 0, 'batch': 1375, 'loss': 3.4390125274658203}\n",
            "{'epoch': 0, 'batch': 1376, 'loss': 3.1883349418640137}\n",
            "{'epoch': 0, 'batch': 1377, 'loss': 3.59161376953125}\n",
            "{'epoch': 0, 'batch': 1378, 'loss': 3.495824098587036}\n",
            "{'epoch': 0, 'batch': 1379, 'loss': 3.4296417236328125}\n",
            "{'epoch': 0, 'batch': 1380, 'loss': 3.108121156692505}\n",
            "{'epoch': 0, 'batch': 1381, 'loss': 3.177457332611084}\n",
            "{'epoch': 0, 'batch': 1382, 'loss': 3.636307954788208}\n",
            "{'epoch': 0, 'batch': 1383, 'loss': 3.4493916034698486}\n",
            "{'epoch': 0, 'batch': 1384, 'loss': 3.3118042945861816}\n",
            "{'epoch': 0, 'batch': 1385, 'loss': 3.4787755012512207}\n",
            "{'epoch': 0, 'batch': 1386, 'loss': 3.612316608428955}\n",
            "{'epoch': 0, 'batch': 1387, 'loss': 3.679901123046875}\n",
            "{'epoch': 0, 'batch': 1388, 'loss': 3.320056915283203}\n",
            "{'epoch': 0, 'batch': 1389, 'loss': 2.925097942352295}\n",
            "{'epoch': 0, 'batch': 1390, 'loss': 3.44364595413208}\n",
            "{'epoch': 0, 'batch': 1391, 'loss': 3.3715736865997314}\n",
            "{'epoch': 0, 'batch': 1392, 'loss': 3.0166401863098145}\n",
            "{'epoch': 0, 'batch': 1393, 'loss': 3.0043559074401855}\n",
            "{'epoch': 0, 'batch': 1394, 'loss': 3.120333194732666}\n",
            "{'epoch': 0, 'batch': 1395, 'loss': 2.731489896774292}\n",
            "{'epoch': 0, 'batch': 1396, 'loss': 3.3009445667266846}\n",
            "{'epoch': 0, 'batch': 1397, 'loss': 3.0523502826690674}\n",
            "{'epoch': 0, 'batch': 1398, 'loss': 3.1807825565338135}\n",
            "{'epoch': 0, 'batch': 1399, 'loss': 3.180398464202881}\n",
            "{'epoch': 0, 'batch': 1400, 'loss': 2.9741930961608887}\n",
            "{'epoch': 0, 'batch': 1401, 'loss': 3.0457193851470947}\n",
            "{'epoch': 0, 'batch': 1402, 'loss': 3.1981427669525146}\n",
            "{'epoch': 0, 'batch': 1403, 'loss': 2.9654061794281006}\n",
            "{'epoch': 0, 'batch': 1404, 'loss': 3.265498638153076}\n",
            "{'epoch': 0, 'batch': 1405, 'loss': 2.9300312995910645}\n",
            "{'epoch': 0, 'batch': 1406, 'loss': 2.9883065223693848}\n",
            "{'epoch': 0, 'batch': 1407, 'loss': 3.031430721282959}\n",
            "{'epoch': 0, 'batch': 1408, 'loss': 2.9433300495147705}\n",
            "{'epoch': 0, 'batch': 1409, 'loss': 2.841468095779419}\n",
            "{'epoch': 0, 'batch': 1410, 'loss': 3.0083119869232178}\n",
            "{'epoch': 0, 'batch': 1411, 'loss': 2.9455995559692383}\n",
            "{'epoch': 0, 'batch': 1412, 'loss': 3.137319803237915}\n",
            "{'epoch': 0, 'batch': 1413, 'loss': 3.0191903114318848}\n",
            "{'epoch': 0, 'batch': 1414, 'loss': 2.940613269805908}\n",
            "{'epoch': 0, 'batch': 1415, 'loss': 3.411259412765503}\n",
            "{'epoch': 0, 'batch': 1416, 'loss': 3.055588722229004}\n",
            "{'epoch': 0, 'batch': 1417, 'loss': 3.428072452545166}\n",
            "{'epoch': 0, 'batch': 1418, 'loss': 3.0964608192443848}\n",
            "{'epoch': 0, 'batch': 1419, 'loss': 3.059185266494751}\n",
            "{'epoch': 0, 'batch': 1420, 'loss': 3.27003812789917}\n",
            "{'epoch': 0, 'batch': 1421, 'loss': 3.038248300552368}\n",
            "{'epoch': 0, 'batch': 1422, 'loss': 3.2309036254882812}\n",
            "{'epoch': 0, 'batch': 1423, 'loss': 3.0986621379852295}\n",
            "{'epoch': 0, 'batch': 1424, 'loss': 3.2463786602020264}\n",
            "{'epoch': 0, 'batch': 1425, 'loss': 3.100820541381836}\n",
            "{'epoch': 0, 'batch': 1426, 'loss': 3.3047924041748047}\n",
            "{'epoch': 0, 'batch': 1427, 'loss': 3.3371284008026123}\n",
            "{'epoch': 0, 'batch': 1428, 'loss': 3.3223063945770264}\n",
            "{'epoch': 0, 'batch': 1429, 'loss': 3.139289140701294}\n",
            "{'epoch': 0, 'batch': 1430, 'loss': 3.1357474327087402}\n",
            "{'epoch': 0, 'batch': 1431, 'loss': 3.1112751960754395}\n",
            "{'epoch': 0, 'batch': 1432, 'loss': 3.4793899059295654}\n",
            "{'epoch': 0, 'batch': 1433, 'loss': 3.2350189685821533}\n",
            "{'epoch': 0, 'batch': 1434, 'loss': 3.114825963973999}\n",
            "{'epoch': 0, 'batch': 1435, 'loss': 3.2575268745422363}\n",
            "{'epoch': 0, 'batch': 1436, 'loss': 3.314608097076416}\n",
            "{'epoch': 0, 'batch': 1437, 'loss': 3.236401319503784}\n",
            "{'epoch': 0, 'batch': 1438, 'loss': 3.1646690368652344}\n",
            "{'epoch': 0, 'batch': 1439, 'loss': 3.067880630493164}\n",
            "{'epoch': 0, 'batch': 1440, 'loss': 3.2730236053466797}\n",
            "{'epoch': 0, 'batch': 1441, 'loss': 3.425549030303955}\n",
            "{'epoch': 0, 'batch': 1442, 'loss': 3.119795083999634}\n",
            "{'epoch': 0, 'batch': 1443, 'loss': 3.347496509552002}\n",
            "{'epoch': 0, 'batch': 1444, 'loss': 3.144651412963867}\n",
            "{'epoch': 0, 'batch': 1445, 'loss': 3.0900511741638184}\n",
            "{'epoch': 0, 'batch': 1446, 'loss': 3.235996723175049}\n",
            "{'epoch': 0, 'batch': 1447, 'loss': 3.2257354259490967}\n",
            "{'epoch': 0, 'batch': 1448, 'loss': 3.1281332969665527}\n",
            "{'epoch': 0, 'batch': 1449, 'loss': 3.076084613800049}\n",
            "{'epoch': 0, 'batch': 1450, 'loss': 3.178628921508789}\n",
            "{'epoch': 0, 'batch': 1451, 'loss': 3.101973056793213}\n",
            "{'epoch': 0, 'batch': 1452, 'loss': 3.1623215675354004}\n",
            "{'epoch': 0, 'batch': 1453, 'loss': 2.986557722091675}\n",
            "{'epoch': 0, 'batch': 1454, 'loss': 3.1695008277893066}\n",
            "{'epoch': 0, 'batch': 1455, 'loss': 3.0012056827545166}\n",
            "{'epoch': 0, 'batch': 1456, 'loss': 3.1601710319519043}\n",
            "{'epoch': 0, 'batch': 1457, 'loss': 3.002307176589966}\n",
            "{'epoch': 0, 'batch': 1458, 'loss': 3.304203748703003}\n",
            "{'epoch': 0, 'batch': 1459, 'loss': 3.213156223297119}\n",
            "{'epoch': 0, 'batch': 1460, 'loss': 3.2868905067443848}\n",
            "{'epoch': 0, 'batch': 1461, 'loss': 2.9603793621063232}\n",
            "{'epoch': 0, 'batch': 1462, 'loss': 3.1635286808013916}\n",
            "{'epoch': 0, 'batch': 1463, 'loss': 3.4490749835968018}\n",
            "{'epoch': 0, 'batch': 1464, 'loss': 2.9644641876220703}\n",
            "{'epoch': 0, 'batch': 1465, 'loss': 3.1219263076782227}\n",
            "{'epoch': 0, 'batch': 1466, 'loss': 3.167365074157715}\n",
            "{'epoch': 0, 'batch': 1467, 'loss': 3.3130030632019043}\n",
            "{'epoch': 0, 'batch': 1468, 'loss': 3.3988499641418457}\n",
            "{'epoch': 0, 'batch': 1469, 'loss': 3.1388802528381348}\n",
            "{'epoch': 0, 'batch': 1470, 'loss': 3.133815288543701}\n",
            "{'epoch': 0, 'batch': 1471, 'loss': 3.269850492477417}\n",
            "{'epoch': 0, 'batch': 1472, 'loss': 2.899777889251709}\n",
            "{'epoch': 0, 'batch': 1473, 'loss': 3.4057765007019043}\n",
            "{'epoch': 0, 'batch': 1474, 'loss': 3.3309662342071533}\n",
            "{'epoch': 0, 'batch': 1475, 'loss': 3.198991298675537}\n",
            "{'epoch': 0, 'batch': 1476, 'loss': 3.1881184577941895}\n",
            "{'epoch': 0, 'batch': 1477, 'loss': 3.055022954940796}\n",
            "{'epoch': 0, 'batch': 1478, 'loss': 3.2474045753479004}\n",
            "{'epoch': 0, 'batch': 1479, 'loss': 3.18929386138916}\n",
            "{'epoch': 0, 'batch': 1480, 'loss': 3.035492420196533}\n",
            "{'epoch': 0, 'batch': 1481, 'loss': 2.94494366645813}\n",
            "{'epoch': 0, 'batch': 1482, 'loss': 3.3487391471862793}\n",
            "{'epoch': 0, 'batch': 1483, 'loss': 2.859957218170166}\n",
            "{'epoch': 0, 'batch': 1484, 'loss': 3.4935379028320312}\n",
            "{'epoch': 0, 'batch': 1485, 'loss': 3.205530881881714}\n",
            "{'epoch': 0, 'batch': 1486, 'loss': 3.430607318878174}\n",
            "{'epoch': 0, 'batch': 1487, 'loss': 3.3382904529571533}\n",
            "{'epoch': 0, 'batch': 1488, 'loss': 3.350346803665161}\n",
            "{'epoch': 0, 'batch': 1489, 'loss': 3.05769681930542}\n",
            "{'epoch': 0, 'batch': 1490, 'loss': 3.0717930793762207}\n",
            "{'epoch': 0, 'batch': 1491, 'loss': 2.982374906539917}\n",
            "{'epoch': 0, 'batch': 1492, 'loss': 3.0499279499053955}\n",
            "{'epoch': 0, 'batch': 1493, 'loss': 3.3570556640625}\n",
            "{'epoch': 0, 'batch': 1494, 'loss': 2.9496965408325195}\n",
            "{'epoch': 0, 'batch': 1495, 'loss': 3.278984546661377}\n",
            "{'epoch': 0, 'batch': 1496, 'loss': 3.0716209411621094}\n",
            "{'epoch': 0, 'batch': 1497, 'loss': 3.075469970703125}\n",
            "{'epoch': 0, 'batch': 1498, 'loss': 3.330134630203247}\n",
            "{'epoch': 0, 'batch': 1499, 'loss': 3.151719808578491}\n",
            "{'epoch': 0, 'batch': 1500, 'loss': 3.3632495403289795}\n",
            "{'epoch': 0, 'batch': 1501, 'loss': 3.4291234016418457}\n",
            "{'epoch': 0, 'batch': 1502, 'loss': 3.124159574508667}\n",
            "{'epoch': 0, 'batch': 1503, 'loss': 3.1338868141174316}\n",
            "{'epoch': 0, 'batch': 1504, 'loss': 3.2831547260284424}\n",
            "{'epoch': 0, 'batch': 1505, 'loss': 3.3233273029327393}\n",
            "{'epoch': 0, 'batch': 1506, 'loss': 3.414288282394409}\n",
            "{'epoch': 0, 'batch': 1507, 'loss': 3.289379596710205}\n",
            "{'epoch': 0, 'batch': 1508, 'loss': 3.08036470413208}\n",
            "{'epoch': 0, 'batch': 1509, 'loss': 3.046005964279175}\n",
            "{'epoch': 0, 'batch': 1510, 'loss': 3.175771713256836}\n",
            "{'epoch': 0, 'batch': 1511, 'loss': 3.1494364738464355}\n",
            "{'epoch': 0, 'batch': 1512, 'loss': 3.1491591930389404}\n",
            "{'epoch': 0, 'batch': 1513, 'loss': 3.209972858428955}\n",
            "{'epoch': 0, 'batch': 1514, 'loss': 3.397486925125122}\n",
            "{'epoch': 0, 'batch': 1515, 'loss': 3.2149555683135986}\n",
            "{'epoch': 0, 'batch': 1516, 'loss': 3.2825355529785156}\n",
            "{'epoch': 0, 'batch': 1517, 'loss': 2.9931092262268066}\n",
            "{'epoch': 0, 'batch': 1518, 'loss': 3.330357313156128}\n",
            "{'epoch': 0, 'batch': 1519, 'loss': 3.2070534229278564}\n",
            "{'epoch': 0, 'batch': 1520, 'loss': 3.1196348667144775}\n",
            "{'epoch': 0, 'batch': 1521, 'loss': 2.9968724250793457}\n",
            "{'epoch': 0, 'batch': 1522, 'loss': 3.038682699203491}\n",
            "{'epoch': 0, 'batch': 1523, 'loss': 3.28432035446167}\n",
            "{'epoch': 0, 'batch': 1524, 'loss': 3.0595078468322754}\n",
            "{'epoch': 0, 'batch': 1525, 'loss': 2.719639301300049}\n",
            "{'epoch': 0, 'batch': 1526, 'loss': 3.071329116821289}\n",
            "{'epoch': 0, 'batch': 1527, 'loss': 3.0824790000915527}\n",
            "{'epoch': 0, 'batch': 1528, 'loss': 3.1879029273986816}\n",
            "{'epoch': 0, 'batch': 1529, 'loss': 3.1859660148620605}\n",
            "{'epoch': 0, 'batch': 1530, 'loss': 2.9573264122009277}\n",
            "{'epoch': 0, 'batch': 1531, 'loss': 3.125225782394409}\n",
            "{'epoch': 0, 'batch': 1532, 'loss': 3.0979762077331543}\n",
            "{'epoch': 0, 'batch': 1533, 'loss': 3.552197217941284}\n",
            "{'epoch': 0, 'batch': 1534, 'loss': 3.149141311645508}\n",
            "{'epoch': 0, 'batch': 1535, 'loss': 3.255354642868042}\n",
            "{'epoch': 0, 'batch': 1536, 'loss': 3.152301549911499}\n",
            "{'epoch': 0, 'batch': 1537, 'loss': 3.198150157928467}\n",
            "{'epoch': 0, 'batch': 1538, 'loss': 3.063622236251831}\n",
            "{'epoch': 0, 'batch': 1539, 'loss': 3.213202953338623}\n",
            "{'epoch': 0, 'batch': 1540, 'loss': 3.5266273021698}\n",
            "{'epoch': 0, 'batch': 1541, 'loss': 3.1211538314819336}\n",
            "{'epoch': 0, 'batch': 1542, 'loss': 3.067023515701294}\n",
            "{'epoch': 0, 'batch': 1543, 'loss': 2.9776735305786133}\n",
            "{'epoch': 0, 'batch': 1544, 'loss': 3.168436288833618}\n",
            "{'epoch': 0, 'batch': 1545, 'loss': 3.163893938064575}\n",
            "{'epoch': 0, 'batch': 1546, 'loss': 2.9207892417907715}\n",
            "{'epoch': 0, 'batch': 1547, 'loss': 2.8880836963653564}\n",
            "{'epoch': 0, 'batch': 1548, 'loss': 3.181668281555176}\n",
            "{'epoch': 0, 'batch': 1549, 'loss': 3.3714332580566406}\n",
            "{'epoch': 0, 'batch': 1550, 'loss': 3.1073007583618164}\n",
            "{'epoch': 0, 'batch': 1551, 'loss': 3.0705270767211914}\n",
            "{'epoch': 0, 'batch': 1552, 'loss': 3.0306527614593506}\n",
            "{'epoch': 0, 'batch': 1553, 'loss': 3.3064472675323486}\n",
            "{'epoch': 0, 'batch': 1554, 'loss': 3.094026565551758}\n",
            "{'epoch': 0, 'batch': 1555, 'loss': 3.1613802909851074}\n",
            "{'epoch': 0, 'batch': 1556, 'loss': 3.0530810356140137}\n",
            "{'epoch': 0, 'batch': 1557, 'loss': 3.0803182125091553}\n",
            "{'epoch': 0, 'batch': 1558, 'loss': 2.917154550552368}\n",
            "{'epoch': 0, 'batch': 1559, 'loss': 3.327066421508789}\n",
            "{'epoch': 0, 'batch': 1560, 'loss': 3.227323055267334}\n",
            "{'epoch': 0, 'batch': 1561, 'loss': 3.211116075515747}\n",
            "{'epoch': 0, 'batch': 1562, 'loss': 3.1272099018096924}\n",
            "{'epoch': 0, 'batch': 1563, 'loss': 3.39664888381958}\n",
            "{'epoch': 0, 'batch': 1564, 'loss': 2.891655683517456}\n",
            "{'epoch': 0, 'batch': 1565, 'loss': 3.219346284866333}\n",
            "{'epoch': 0, 'batch': 1566, 'loss': 3.328092098236084}\n",
            "{'epoch': 0, 'batch': 1567, 'loss': 3.117183208465576}\n",
            "{'epoch': 0, 'batch': 1568, 'loss': 3.315045118331909}\n",
            "{'epoch': 0, 'batch': 1569, 'loss': 2.964233636856079}\n",
            "{'epoch': 0, 'batch': 1570, 'loss': 3.3766815662384033}\n",
            "{'epoch': 0, 'batch': 1571, 'loss': 3.2034945487976074}\n",
            "{'epoch': 0, 'batch': 1572, 'loss': 2.8837223052978516}\n",
            "{'epoch': 0, 'batch': 1573, 'loss': 3.318180799484253}\n",
            "{'epoch': 0, 'batch': 1574, 'loss': 3.21821665763855}\n",
            "{'epoch': 0, 'batch': 1575, 'loss': 2.9628725051879883}\n",
            "{'epoch': 0, 'batch': 1576, 'loss': 3.053150177001953}\n",
            "{'epoch': 0, 'batch': 1577, 'loss': 3.3287556171417236}\n",
            "{'epoch': 0, 'batch': 1578, 'loss': 3.1585214138031006}\n",
            "{'epoch': 0, 'batch': 1579, 'loss': 3.046377182006836}\n",
            "{'epoch': 0, 'batch': 1580, 'loss': 3.1281538009643555}\n",
            "{'epoch': 0, 'batch': 1581, 'loss': 2.833832263946533}\n",
            "{'epoch': 0, 'batch': 1582, 'loss': 2.934269428253174}\n",
            "{'epoch': 0, 'batch': 1583, 'loss': 2.8377671241760254}\n",
            "{'epoch': 0, 'batch': 1584, 'loss': 3.2153003215789795}\n",
            "{'epoch': 0, 'batch': 1585, 'loss': 3.0120787620544434}\n",
            "{'epoch': 0, 'batch': 1586, 'loss': 3.0091633796691895}\n",
            "{'epoch': 0, 'batch': 1587, 'loss': 3.2804195880889893}\n",
            "{'epoch': 0, 'batch': 1588, 'loss': 3.01646089553833}\n",
            "{'epoch': 0, 'batch': 1589, 'loss': 3.111788272857666}\n",
            "{'epoch': 0, 'batch': 1590, 'loss': 3.0579283237457275}\n",
            "{'epoch': 0, 'batch': 1591, 'loss': 3.17118763923645}\n",
            "{'epoch': 0, 'batch': 1592, 'loss': 3.58586049079895}\n",
            "{'epoch': 0, 'batch': 1593, 'loss': 3.4367668628692627}\n",
            "{'epoch': 0, 'batch': 1594, 'loss': 3.2170796394348145}\n",
            "{'epoch': 0, 'batch': 1595, 'loss': 3.589010238647461}\n",
            "{'epoch': 0, 'batch': 1596, 'loss': 3.386427402496338}\n",
            "{'epoch': 0, 'batch': 1597, 'loss': 3.2013072967529297}\n",
            "{'epoch': 0, 'batch': 1598, 'loss': 3.0834667682647705}\n",
            "{'epoch': 0, 'batch': 1599, 'loss': 3.378448486328125}\n",
            "{'epoch': 0, 'batch': 1600, 'loss': 3.0845537185668945}\n",
            "{'epoch': 0, 'batch': 1601, 'loss': 3.1367404460906982}\n",
            "{'epoch': 0, 'batch': 1602, 'loss': 2.8050713539123535}\n",
            "{'epoch': 0, 'batch': 1603, 'loss': 3.2011725902557373}\n",
            "{'epoch': 0, 'batch': 1604, 'loss': 3.2389183044433594}\n",
            "{'epoch': 0, 'batch': 1605, 'loss': 3.2372047901153564}\n",
            "{'epoch': 0, 'batch': 1606, 'loss': 2.9981937408447266}\n",
            "{'epoch': 0, 'batch': 1607, 'loss': 3.098438262939453}\n",
            "{'epoch': 0, 'batch': 1608, 'loss': 3.1442601680755615}\n",
            "{'epoch': 0, 'batch': 1609, 'loss': 2.932408332824707}\n",
            "{'epoch': 0, 'batch': 1610, 'loss': 3.1220693588256836}\n",
            "{'epoch': 0, 'batch': 1611, 'loss': 2.879946708679199}\n",
            "{'epoch': 0, 'batch': 1612, 'loss': 3.0346083641052246}\n",
            "{'epoch': 0, 'batch': 1613, 'loss': 3.1234402656555176}\n",
            "{'epoch': 0, 'batch': 1614, 'loss': 3.3134796619415283}\n",
            "{'epoch': 0, 'batch': 1615, 'loss': 3.7305476665496826}\n",
            "{'epoch': 0, 'batch': 1616, 'loss': 3.2236056327819824}\n",
            "{'epoch': 0, 'batch': 1617, 'loss': 2.7450339794158936}\n",
            "{'epoch': 0, 'batch': 1618, 'loss': 3.1693968772888184}\n",
            "{'epoch': 0, 'batch': 1619, 'loss': 2.8959641456604004}\n",
            "{'epoch': 0, 'batch': 1620, 'loss': 2.858271360397339}\n",
            "{'epoch': 0, 'batch': 1621, 'loss': 2.987041473388672}\n",
            "{'epoch': 0, 'batch': 1622, 'loss': 3.035661220550537}\n",
            "{'epoch': 0, 'batch': 1623, 'loss': 2.8043630123138428}\n",
            "{'epoch': 0, 'batch': 1624, 'loss': 3.089529275894165}\n",
            "{'epoch': 0, 'batch': 1625, 'loss': 2.810209035873413}\n",
            "{'epoch': 0, 'batch': 1626, 'loss': 2.872178554534912}\n",
            "{'epoch': 0, 'batch': 1627, 'loss': 2.984048366546631}\n",
            "{'epoch': 0, 'batch': 1628, 'loss': 2.988368034362793}\n",
            "{'epoch': 0, 'batch': 1629, 'loss': 3.041741371154785}\n",
            "{'epoch': 0, 'batch': 1630, 'loss': 3.040321111679077}\n",
            "{'epoch': 0, 'batch': 1631, 'loss': 2.79502010345459}\n",
            "{'epoch': 0, 'batch': 1632, 'loss': 3.0667648315429688}\n",
            "{'epoch': 0, 'batch': 1633, 'loss': 2.6772379875183105}\n",
            "{'epoch': 0, 'batch': 1634, 'loss': 3.0732836723327637}\n",
            "{'epoch': 0, 'batch': 1635, 'loss': 3.0272974967956543}\n",
            "{'epoch': 0, 'batch': 1636, 'loss': 3.132791042327881}\n",
            "{'epoch': 0, 'batch': 1637, 'loss': 3.4449028968811035}\n",
            "{'epoch': 0, 'batch': 1638, 'loss': 2.9092040061950684}\n",
            "{'epoch': 0, 'batch': 1639, 'loss': 3.2532505989074707}\n",
            "{'epoch': 0, 'batch': 1640, 'loss': 3.212070941925049}\n",
            "{'epoch': 0, 'batch': 1641, 'loss': 3.33186674118042}\n",
            "{'epoch': 0, 'batch': 1642, 'loss': 2.8337345123291016}\n",
            "{'epoch': 0, 'batch': 1643, 'loss': 3.3082358837127686}\n",
            "{'epoch': 0, 'batch': 1644, 'loss': 3.024411678314209}\n",
            "{'epoch': 0, 'batch': 1645, 'loss': 3.163208484649658}\n",
            "{'epoch': 0, 'batch': 1646, 'loss': 3.142526388168335}\n",
            "{'epoch': 0, 'batch': 1647, 'loss': 2.6778361797332764}\n"
          ]
        }
      ],
      "source": [
        "model_ferdousi = copy.deepcopy(model)\n",
        "dataset.poet = 'ferdousi'\n",
        "run_name = 'ferdousi_fine_tune'\n",
        "if wandb_active:\n",
        "    wandb.init(project=project_name, name=run_name, reinit=True)\n",
        "train(dataset, model_ferdousi, config, checkpoint_path=checkpoints_dir, max_epochs=3)\n",
        "if wandb_active:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfw9vMfqt5Vt"
      },
      "outputs": [],
      "source": [
        "model_hafez = copy.deepcopy(model)\n",
        "dataset.poet = 'hafez'\n",
        "run_name = 'hafez_fine_tune'\n",
        "if wandb_active:\n",
        "    wandb.init(project=project_name, name=run_name, reinit=True)\n",
        "train(dataset, model_hafez, config, checkpoint_path=checkpoints_dir, max_epochs=10)\n",
        "if wandb_active:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro_AuceslEJF"
      },
      "outputs": [],
      "source": [
        "model_moulavi = copy.deepcopy(model)\n",
        "dataset.poet = 'moulavi'\n",
        "run_name = 'moulavi_fine_tune'\n",
        "if wandb_active:\n",
        "    wandb.init(project=project_name, name=run_name, reinit=True)\n",
        "train(dataset, model_moulavi, config, checkpoint_path=checkpoints_dir, max_epochs=3)\n",
        "if wandb_active:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "برای بدست آوردن مصرع دوم هر بیت کافی است مصرع اول را به تابع\n",
        "get_next_mesra_lstm\n",
        "بدهید. خروجی مورد نظر پرینت خواهد شد.\n",
        "این تابع بر اساس وجود داشتن یا نداشتن قافیه یک جدا کننده ی مصرع مخصوص انتخاب کرده و به اول و اخر مصراع اضافه می‌کند. سپس آن را به مدل ایجاد شده داده و خروجی را پرینت می‌کند \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_next_mesra_lstm(first_mesra, have_ryhme):\n",
        "    model = Model(config, device)\n",
        "    chechkpoint = torch.load('./NLP Class/checkpoints/all_poem_train_checkpoint_9_1654559078.2024975.pt',\n",
        "                            map_location=torch.device('cpu'))\n",
        "    print(chechkpoint['epoch'])\n",
        "    model.load_state_dict(chechkpoint['model_state_dict'])\n",
        "    if have_ryhme:\n",
        "        mesra_diff = \"[BOM_ferdousi]\"\n",
        "    else:\n",
        "        mesra_diff = \"[BOM_hafez]\"\n",
        "    first_mesra = f\"{mesra_diff} {first_mesra} {mesra_diff}\"\n",
        "    print('\\n'.join(predict(dataset, model, text=first_mesra, have_ryhme=have_ryhme)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ryhmes match!!\n",
            "[BOM_hafez] توانا بود هر که دانا بود [BOM_hafez] [BOM_moulavi] اسرار که جزو جان نه که همیشه منزل است [EOS]\n"
          ]
        }
      ],
      "source": [
        "get_next_mesra_lstm(\"توانا بود هر که دانا بود\", False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvNJf16WM74u"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "    <h3> 3. مدل بر پایه مکانیسم توجه </h3>\n",
        "    ابتدا به کمک کلاس SampleDataset پیش‌پردازش‌های لازم را انجام می‌دهیم که شامل خواندن متن و افزودن عبارات اول و پایان مصراع‌ها می‌باشد. هم‌چنین این کلاس تابعی برای بررسی قافیه‌دار بودن یک بیت دارد، بدین ترتیب که کلمات آخر دو مصراع آن را بررسی می‌کند و در صورتیکه دو حرف آخر یکسان داشته باشند، هم‌قافیه‌اند. <br>در تابع __getitem__ با دریافت ایندکس هر بیت، نتیجه‌ی encode شده‌ی آن بیت خروجی داده می‌شود که ورودی مناسب مدل است.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zXLEI0iJM74u"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\n",
        "\n",
        "base_path =  \"./data\"\n",
        "\n",
        "class SampleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            tokenizer,\n",
        "            base_path,\n",
        "            train_path,\n",
        "            max_epochs = 20,\n",
        "            batch_size = 256,\n",
        "            sequence_length = 6,\n",
        "            log_interval = 10\n",
        "    ): \n",
        "        self.start_mesra = '[BOM] '\n",
        "        self.end_mesra = '[EOM]'\n",
        "        self.start_beyt = ''\n",
        "        self.end_beyt = ' [EOS]'\n",
        "        self.base_path = base_path\n",
        "        self.train_path = train_path\n",
        "        self.sequence_length = sequence_length\n",
        "        self.beyts = self.load_beyts()\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def load_prepared_beyts(self):\n",
        "        with open(os.path.join(self.base_path, self.train_path)) as fp:\n",
        "            return fp.readlines()\n",
        "\n",
        "    def load_beyts(self):\n",
        "\n",
        "        beyt_file = []\n",
        "        with open(os.path.join(self.base_path, self.train_path)) as fp:\n",
        "            lines = fp.readlines()\n",
        "            for i in tqdm(range(0, len(lines) - 1, 2)):\n",
        "                mesra1 = self.start_mesra + lines[i].strip() + self.end_mesra\n",
        "                mesra2 = self.start_mesra + lines[i + 1].strip() + self.end_mesra\n",
        "                b = self.start_beyt + mesra1.strip() + ' ' + mesra2.strip() + self.end_beyt\n",
        "                beyt_file.append(b)\n",
        "        return beyt_file\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.beyts)\n",
        "\n",
        "    def does_ryhme(self, beyt):\n",
        "        mesras = beyt.split(self.end_mesra)\n",
        "        mesras = [x for x in filter(lambda x: len(x)>0, mesras)]\n",
        "        first_ghafie = [x for x in filter(lambda x: len(x)>0, mesras[0].split(\" \"))][-1]\n",
        "        second_ghafie = [x for x in filter(lambda x: len(x)>0, mesras[1].split(\" \"))][-1]\n",
        "        min_len = min(len(first_ghafie), len(second_ghafie))\n",
        "\n",
        "        for level in range(-1, -min_len-1, -1):\n",
        "            if not first_ghafie[level:] == second_ghafie[level:]:\n",
        "                break\n",
        "            if level < -1:\n",
        "                break\n",
        "        return level!=-1\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        current_beyt = self.beyts[index]\n",
        "        mesras = current_beyt.split(self.end_mesra)\n",
        "        mesras = [x for x in filter(lambda x: len(x)>0, mesras)]\n",
        "        first_token = self.tokenizer.encode(mesras[0])\n",
        "        second_token = self.tokenizer.encode(mesras[1])\n",
        "        # first_token.append(self.does_ryhme(current_beyt))\n",
        "        # second_token.append(self.does_ryhme(current_beyt))\n",
        "        tensors = (\n",
        "            first_token,\n",
        "            second_token\n",
        "        )\n",
        "        return self.tokenizer.encode(current_beyt.replace(self.end_mesra, \"\")).append()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLs4AvCZfYiT"
      },
      "outputs": [],
      "source": [
        "train_path = \"train.txt\"\n",
        "test_path = \"test.txt\"\n",
        "base_path = \"./data\"\n",
        "dataset = SampleDataset(AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian'), base_path, train_path)\n",
        "val_dataset = SampleDataset(AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian'), base_path, test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZmoED15M74w"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "     برای ساخت مدل بر پایه مکانیسم توجه، از مدل GPT2 بر پایه <a href=\"https://huggingface.co/bolbolzaban/gpt2-persian\">مدل pre_trained بلبل‌زبان</a> استفاده کردیم. توضیحات این مدل و دیتای مورد استفاده‌ی آن در <a href=\"https://khashei.medium.com/a-not-so-dangerous-ai-in-the-persian-language-39172a641c84\">این لینک</a> قابل مشاهده است. این مدل را بر اساس داده‌های مورد استفاده‌ی خودمان fine tune کردیم.<br> ابتدا این مدل گرفته می‌شود و متغیرهای لایه‌های درونی آن freeze می‌گردند، سپس داده‌ی اشعار پیش‌پردازش شده tokenize می‌شود و به دو بخش train و test تقسیم می‌گردد. برای train کردن، مدل بلبل‌زبان را بر اساس این داده fine tune می‌کنیم.<br>خروجی این مدل یک generator است که برای ساخت مصراع دوم از pipeline استفاده می‌کند که ورودی (مصراع اول) را به ساختاری مناسب ورودی دادن به مدل (با پیش‌پردازش و encoding) تبدیل کرده و به کمک مدل train شده، مصراع دوم را ساخته و decode می‌کند و بدین ترتیب بیت را می‌سازد.<br>کیفیت خروجی به تعداد epochها و سایز batchها بستگی خواهد داشت که افزایش آنها باعث بهبود نتیجه و کاهش سرعت training (بسته به سخت‌افزار سیستم) می‌گردد. ما پس از چندین آزمون و خطا با در نظر گرفتن مقدار 10 برای این دو متغیر به نتایج نسبتاً مناسب در زمان مطلوب رسیدیم.<br>کد این بخش روی gpu اجرا شده و در صورت نبودن gpu در سیستم، بخش مربوط به device در آن تغییر می‌یابد. مدل نهایی این بخش در <a href=\"https://drive.google.com/drive/folders/1UKqNs67gdAJgNwLtrQd4f2MtsvA4VCGc?usp=sharing\">اینجا</a> قرار گرفته و قابل دانلود است.<br>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9KPNRiafh19"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho5qoJduM74x"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    TextDataset,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    AutoModelWithLMHead,\n",
        "    BertModel, \n",
        "    GPT2LMHeadModel,\n",
        "    pipeline\n",
        ")\n",
        "import torch\n",
        "import os\n",
        "\n",
        "\n",
        "class MesraModel:\n",
        "    def __init__(self, train_path, test_path, model_dir=\"./model\"):\n",
        "        self.base_path = \"./data\"\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.generator = None\n",
        "        self.train_path = train_path\n",
        "        self.test_path = test_path\n",
        "        self.model_dir = model_dir\n",
        "        self.trainer = None\n",
        "        # self.cleaner = Cleaner()\n",
        "\n",
        "    def read_data(self, tokenizer, train_path=None, test_path=None):\n",
        "        train_path = train_path if train_path is not None else self.train_path\n",
        "        test_path = test_path if test_path is not None else self.test_path\n",
        "        train_dataset = SampleDataset(AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian'), base_path, train_path)\n",
        "        test_dataset = SampleDataset(AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian'), base_path, test_path)\n",
        "        # train_dataset = TextDataset(\n",
        "        #     tokenizer=tokenizer, file_path=os.path.join(self.base_path, train_path), block_size=128)\n",
        "        \n",
        "        # test_dataset = TextDataset(\n",
        "        #     tokenizer=tokenizer, file_path=os.path.join(self.base_path, test_path), block_size=128)\n",
        "        \n",
        "        data_collator = DataCollatorForLanguageModeling(\n",
        "            tokenizer=tokenizer,\n",
        "            mlm=False,\n",
        "        )\n",
        "        return train_dataset, test_dataset, data_collator\n",
        "\n",
        "    def read_model(self, model_type='bolbolzaban/gpt2-persian'):\n",
        "        self.model = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "        # self.tokenizer.add_tokens(['[EOM]', '[BOM]', '[EOS]'], special_tokens=True)\n",
        "        return self.model, self.tokenizer\n",
        "\n",
        "\n",
        "    def freeze_lower_layers(self):\n",
        "        for param in self.model.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        for param in (\n",
        "            self.model.base_model.h[23].parameters() or self.model.base_model.h[22].parameters()\n",
        "        ):\n",
        "            param.requires_grad = True\n",
        "            \n",
        "    def fine_tune_model(self, model, train_texts, val_texts, data_collator):\n",
        "        training_args = TrainingArguments(\n",
        "        output_dir=self.model_dir,\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=12,\n",
        "        # Set the batch size to a maximum value that could fit into GPU memory,\n",
        "        # for example 12 is the largest batch size that could work on a 6gb GPU when training the last to layers\n",
        "        per_device_train_batch_size=12,\n",
        "        per_device_eval_batch_size=12,\n",
        "        eval_steps=1000,\n",
        "        save_steps=1000,\n",
        "        warmup_steps=500)\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            data_collator=data_collator,\n",
        "            train_dataset=train_texts,\n",
        "            eval_dataset=val_texts,\n",
        "        )\n",
        "        trainer.train()\n",
        "        self.trainer = trainer \n",
        "        return trainer\n",
        "    \n",
        "    def load_model(self):\n",
        "        model, tokenizer = self.read_model(self.model_dir)\n",
        "        generator = pipeline('text-generation', model, tokenizer=tokenizer, config={'max_length':256}, device=0)\n",
        "        self.generator = generator\n",
        "        return generator\n",
        "        \n",
        "    def init_generator(self, used_pretrained=False):      \n",
        "        if used_pretrained:\n",
        "            print(\"in init generator\")\n",
        "            model, tokenizer = self.read_model(self.model_dir)\n",
        "            print(\"read model successfully\")\n",
        "            model.to(torch.device(\"cuda\"))\n",
        "            print(\"convert model to cuda\")\n",
        "        else:\n",
        "            model, tokenizer = self.read_model()\n",
        "            \n",
        "        self.freeze_lower_layers()\n",
        "        train_texts, val_texts, data_collator = self.read_data(tokenizer)\n",
        "        trainer = self.fine_tune_model(model, train_texts, val_texts, data_collator)\n",
        "        model = trainer.model\n",
        "    \n",
        "        generator = pipeline('text-generation', model, tokenizer=tokenizer, config={'max_length':256}, device=0)\n",
        "        self.generator = generator\n",
        "        return generator\n",
        "\n",
        "    def save_model(self, dir=None):\n",
        "        dir = dir if dir is not None else self.model_dir\n",
        "        self.trainer.save_model(output_dir=dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjCiXtPEhr1P"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "برای اعمال رعایت یا عدم رعایت قافیه در این بخش، دو مدل مجزا از هم روی دو نمونه شعر با قافیه (شاهنامه و مثنوی مولوی) و بدون قافیه (غزلیات حافظ و عراقی) train می‌شوند و با توجه به ورودی قافیه، نتیجه مدل مربوطه به عنوان خروجی نمایش داده می‌شود.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4N1R1XXgCei"
      },
      "outputs": [],
      "source": [
        "class MesraGenerator:\n",
        "    def __init__(self):\n",
        "        self.notryhme_poets = [\"hafez\", \"eraghi\"]\n",
        "        self.ryhme_poets = [\"ferdousi\", \"moulavi\"]\n",
        "        self.ryhme_model, self.notryhme_model = self.init_model()\n",
        "\n",
        "    def init_model(self):\n",
        "        mesra_model = MesraModel(\"train_path\", \"test_path\", model_dir=\"./notryhme_model\")\n",
        "        not_ryhme_generator = mesra_model.load_model()\n",
        "\n",
        "        mesra_model = MesraModel(\"train_path\", \"test_path\", model_dir=\"./model\")\n",
        "        ryhme_generator = mesra_model.load_model()\n",
        "        \n",
        "        return ryhme_generator, not_ryhme_generator\n",
        "\n",
        "    def train_all_poets(self):\n",
        "        ryhme_generator = None\n",
        "        not_ryhme_generator = None\n",
        "        for index, poet in enumerate(self.notryhme_poets):\n",
        "            train_path = f\"./data/{poet}_train.txt\"\n",
        "            test_path = f\"./data/{poet}_test.txt\"\n",
        "            mesra_model = MesraModel(train_path, test_path, model_dir=\"./notryhme_model\")\n",
        "            not_ryhme_generator = mesra_model.init_generator(used_pretrained=index!=0)\n",
        "            mesra_model.save_model(\"./notryhme_model\")\n",
        "\n",
        "        for index, poet in enumerate(self.ryhme_poets):\n",
        "            train_path = f\"./data/{poet}_train.txt\"\n",
        "            test_path = f\"./data/{poet}_test.txt\"\n",
        "            mesra_model = MesraModel(train_path, test_path, model_dir=\"./ryhme_model\")\n",
        "            ryhme_generator = mesra_model.init_generator(used_pretrained=index!=0)\n",
        "            mesra_model.save_model(\"./ryhme_model\")\n",
        "        return ryhme_generator, not_ryhme_generator \n",
        "    \n",
        "    def generate_mesra(self, first_mesra: str, has_ghafie: bool=True):\n",
        "        first_mesra = f\"[BOM] {first_mesra} [BOM]\"\n",
        "        if has_ghafie:\n",
        "            result = self.ryhme_model(first_mesra)\n",
        "        else:\n",
        "            result = self.notryhme_model(first_mesra)\n",
        "\n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "بنابراین برای صدا زدن تابع کافی است یک \n",
        "MesraGenerator \n",
        "ساخته و سپس تابع\n",
        "generate_mesra\n",
        "با مصرع مورد نظر صدا زده شود.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:9 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': '[BOM] [BOM]کاشت طره مولوی را در دل شب بی بهانه [BOM] [BOM] با دل مجروح ما کرد آشنا با یک بهانه'}]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "mesra_generator = MesraGenerator()\n",
        "mesra_generator.generate_mesra(\"اشت طره مولوی را در دل شب بی بهانه \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB8d3czgHpBj"
      },
      "source": [
        "<div dir=\"rtl\"  style ='font-family: \"B Nazanin\";'>\n",
        "از توابع زیر برای پیش‌پردازش و بازنویسی داده‌های train و test استفاده می‌گردد. هم‌چنین تابع save_not_ryhme_beyts می‌تواند فقط ابیاتی که قافیه ندارند را بیابد و ذخیره کند. این ابیات در ساخت مدل بر پایه ابیات بدون قافیه به ما کمک می‌کنند.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns58_MmeM74z"
      },
      "outputs": [],
      "source": [
        "def does_ryhme(first_mesra, sec_mesra):\n",
        "    first_ghafie = [x for x in filter(lambda x: len(x)>0, first_mesra.split(\" \"))][-1]\n",
        "    second_ghafie = [x for x in filter(lambda x: len(x)>0, sec_mesra.split(\" \"))][-1]\n",
        "    min_len = min(len(first_ghafie), len(second_ghafie))\n",
        "\n",
        "    for level in range(-1, -min_len-1, -1):\n",
        "        if not first_ghafie[level:] == second_ghafie[level:]:\n",
        "            break\n",
        "        if level < -1:\n",
        "            break\n",
        "    return level!=-1\n",
        "\n",
        "    \n",
        "def write_to_file(lines, path):\n",
        "    with open(path, \"w\") as write_f:\n",
        "        for line in lines:\n",
        "            if len(line) > 1:\n",
        "                write_f.write(line)\n",
        "\n",
        "def save_not_ryhme_beyts(path):\n",
        "    out_path = \".\"+path.split(\".\")[-2]+\"_not_ryhme.txt\"\n",
        "    not_ryhme_lines = list()\n",
        "    with open(path) as f:\n",
        "        lines = f.readlines()\n",
        "        lines = list(filter(lambda x: len(x.strip())>1, lines))\n",
        "        for i in tqdm(range(0, len(lines) - 1, 2)):\n",
        "            mesra1 = lines[i].strip()\n",
        "            mesra2 = lines[i + 1].strip()\n",
        "            if not does_ryhme(mesra1, mesra2):\n",
        "                not_ryhme_lines.append(mesra1+os.linesep)\n",
        "                not_ryhme_lines.append(mesra2+os.linesep)\n",
        "    write_to_file(not_ryhme_lines, out_path)\n",
        "\n",
        "\n",
        "def split_filt_to_trian_test():\n",
        "    file_path = \"./data/eraghi_norm_not_ryhme.txt\"\n",
        "    train_perc = 0.8\n",
        "    with open(file_path) as f:\n",
        "        lines = f.readlines()\n",
        "        train_index = math.floor(len(lines)*train_perc)\n",
        "        train_index = train_index - (train_index%2)\n",
        "        train_lines = lines[:train_index]\n",
        "        test_lines = lines[train_index:]\n",
        "    write_to_file(train_lines, \"./data/eraghi_train.txt\")\n",
        "    write_to_file(test_lines, \"./data/eraghi_test.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_C7kZgcnM741"
      },
      "outputs": [],
      "source": [
        "split_filt_to_trian_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIlFYC9hIHFU"
      },
      "outputs": [],
      "source": [
        "save_not_ryhme_beyts(\"./data/eraghi_norm.txt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of HW3.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b04b67f68733743fa4bd20e2b208bd3fb17523e8f420adf77b7736387b23b0f8"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
